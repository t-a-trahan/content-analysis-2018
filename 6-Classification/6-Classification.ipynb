{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 6 - Classification\n",
    "\n",
    "This week, we shift from gathering human textual classifications through crowdsourcing, to using machine learning models and algorithms that train on those human classifications and extend them to documents far too numerous to read. If you recall, *clustering* allows us to stably partition text data (e.g., documents, turns of conversation) according to all patterns of covariation among available text features. *Classification*, by contrast, partitions text data according to only those features and their variation that enable us to mimic and extrapolate human annotations.\n",
    "\n",
    "In this notebook, we will show how to use a variety of classification methods, including Na√Øve Bayes, Logistic regression, K-nearest neighbor, decision trees and random forests, support vector machines and even a simple neural network, the perceptron. We will also demonstrate ensemble techniques that can link several such methods into a single, more accurate, classification pipeline. We will finally learn to use conventions and metrics to evaluate classifier performance on out-of-sample data. \n",
    "\n",
    "For this notebook we will be using the following packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\computation\\Anaconda3\\lib\\site-packages\\gensim\\utils.py:860: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n"
     ]
    }
   ],
   "source": [
    "#Special module written for this class\n",
    "#This provides access to data and to helper functions from previous weeks\n",
    "#Make sure you update it before starting this notebook\n",
    "import lucem_illud #pip install -U git+git://github.com/Computational-Content-Analysis-2018/lucem_illud.git\n",
    "\n",
    "#All these packages need to be installed from pip\n",
    "#For ML\n",
    "import sklearn\n",
    "import sklearn.naive_bayes\n",
    "import sklearn.tree\n",
    "import sklearn.ensemble\n",
    "import sklearn.neural_network\n",
    "import sklearn.decomposition\n",
    "\n",
    "import nltk #For tokenizing and normalizing\n",
    "import numpy as np #arrays\n",
    "import matplotlib.pyplot as plt #Plots\n",
    "import matplotlib.colors # For nice colours\n",
    "import seaborn #Makes plots look nice, also heatmaps\n",
    "import scipy as sp #for interp\n",
    "\n",
    "#These are from the standard library\n",
    "import collections\n",
    "import os\n",
    "import os.path\n",
    "import random\n",
    "import re\n",
    "import glob\n",
    "import pandas\n",
    "import requests\n",
    "import json\n",
    "import math\n",
    "\n",
    "#This 'magic' command makes the plots work better\n",
    "#in the notebook, don't use it outside of a notebook.\n",
    "#Also you can ignore the warning\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple Simulated Examples\n",
    "\n",
    "Here we create a sandbox for you to explore different types of classified data and how different statistical classifiers perform on each type."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating example data\n",
    "\n",
    "We start by loading one of the \"cartoon\" or simplified data sets and then dividing it into training and testing sets. To maximize our ability to visualize, each dataset involves two classes, colored yellow and blue, arrayed along two two dimensions (`x` and `y`). \n",
    "\n",
    "The four data patterns include: \n",
    "+ `random` in which the two classes are randomly distributed across both dimensions\n",
    "+ `andSplit` in which the two classes are linearly split along one of two dimensions (e.g., men like Adidas)\n",
    "+ `xorSplit` in which the two classes are split, oppositely, along each dimension (e.g., old ladies and young men like Nikes)\n",
    "+ `targetSplit` in which one class is nested within the other in two dimensions (e.g., middle aged, middle income people like vintage Mustangs)\n",
    "+ `multiBlobs` in which 5 classes are placed as bivariate Gaussians at random locations\n",
    "\n",
    "`noise` is a variable [0-1] that ranges from no noise in the prescribed pattern [0] to complete noise/randomness [1].\n",
    "\n",
    "Uncomment (remove the # in front of) each dataset, one at a time, and then run the cell and subsequent cells to examine how each machine learning approach captures each pattern."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below, I create 5 distinct datasets, then classify each one with all methods.\n",
    "\n",
    "Although the Exercise technically calls for ten distinct sets, in the interest of time I have limited myself to five."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# five distinct datasets\n",
    "\n",
    "noise = .2\n",
    "\n",
    "dfTrain, dfTest = lucem_illud.trainTestSplit(lucem_illud.random())\n",
    "dfTrain1, dfTest1 = lucem_illud.trainTestSplit(lucem_illud.andSplit(noise))\n",
    "dfTrain2, dfTest2 = lucem_illud.trainTestSplit(lucem_illud.xorSplit(noise))\n",
    "dfTrain3, dfTest3 = lucem_illud.trainTestSplit(lucem_illud.targetSplit(noise))\n",
    "dfTrain4, dfTest4 = lucem_illud.trainTestSplit(lucem_illud.multiBlobs(noise))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Available methods - copy/pasted from below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Bayes\n",
    "clfBayes = sklearn.naive_bayes.GaussianNB()\n",
    "\n",
    "#Analogizes\n",
    "clfLinear = sklearn.svm.SVC(kernel = 'linear', probability = True) #slow, set probability = False to speed up\n",
    "clfKernel = sklearn.svm.SVC(kernel = 'poly', degree = 3, probability = True) #slower\n",
    "clfKNeighbors = sklearn.neighbors.KNeighborsClassifier(5, weights='distance')# k, 'distance' or 'uniform'\n",
    "\n",
    "#Classical Regression\n",
    "clfReg = sklearn.linear_model.LogisticRegression()\n",
    "\n",
    "#Symbolists\n",
    "clfTree = sklearn.tree.DecisionTreeClassifier()\n",
    "clfForest = sklearn.ensemble.RandomForestClassifier()\n",
    "\n",
    "#Connectionists\n",
    "clfNN = sklearn.neural_network.MLPClassifier()\n",
    "\n",
    "#Ensemble\n",
    "clfEnsem = sklearn.ensemble.GradientBoostingClassifier()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To make things easy, I am only going to run each through the evaluateClassifier function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bayes\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AUC</th>\n",
       "      <th>Average_Precision</th>\n",
       "      <th>Error_Rate</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Category</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.464896</td>\n",
       "      <td>0.488646</td>\n",
       "      <td>0.535</td>\n",
       "      <td>0.470588</td>\n",
       "      <td>0.475248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.464896</td>\n",
       "      <td>0.478720</td>\n",
       "      <td>0.535</td>\n",
       "      <td>0.459184</td>\n",
       "      <td>0.454545</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               AUC  Average_Precision  Error_Rate  Precision    Recall\n",
       "Category                                                              \n",
       "0         0.464896           0.488646       0.535   0.470588  0.475248\n",
       "1         0.464896           0.478720       0.535   0.459184  0.454545"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AUC</th>\n",
       "      <th>Average_Precision</th>\n",
       "      <th>Error_Rate</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Category</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.545405</td>\n",
       "      <td>0.529918</td>\n",
       "      <td>0.455</td>\n",
       "      <td>0.554348</td>\n",
       "      <td>0.504950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.545405</td>\n",
       "      <td>0.519628</td>\n",
       "      <td>0.455</td>\n",
       "      <td>0.537037</td>\n",
       "      <td>0.585859</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               AUC  Average_Precision  Error_Rate  Precision    Recall\n",
       "Category                                                              \n",
       "0         0.545405           0.529918       0.455   0.554348  0.504950\n",
       "1         0.545405           0.519628       0.455   0.537037  0.585859"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multi\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AUC</th>\n",
       "      <th>Average_Precision</th>\n",
       "      <th>Error_Rate</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Category</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.494799</td>\n",
       "      <td>0.502426</td>\n",
       "      <td>0.505</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.514851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.494799</td>\n",
       "      <td>0.492428</td>\n",
       "      <td>0.505</td>\n",
       "      <td>0.489583</td>\n",
       "      <td>0.474747</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               AUC  Average_Precision  Error_Rate  Precision    Recall\n",
       "Category                                                              \n",
       "0         0.494799           0.502426       0.505   0.500000  0.514851\n",
       "1         0.494799           0.492428       0.505   0.489583  0.474747"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k-neighbores\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AUC</th>\n",
       "      <th>Average_Precision</th>\n",
       "      <th>Error_Rate</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Category</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.435194</td>\n",
       "      <td>0.476931</td>\n",
       "      <td>0.565</td>\n",
       "      <td>0.437500</td>\n",
       "      <td>0.415842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.435194</td>\n",
       "      <td>0.466678</td>\n",
       "      <td>0.565</td>\n",
       "      <td>0.432692</td>\n",
       "      <td>0.454545</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               AUC  Average_Precision  Error_Rate  Precision    Recall\n",
       "Category                                                              \n",
       "0         0.435194           0.476931       0.565   0.437500  0.415842\n",
       "1         0.435194           0.466678       0.565   0.432692  0.454545"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "regression\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AUC</th>\n",
       "      <th>Average_Precision</th>\n",
       "      <th>Error_Rate</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Category</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.535704</td>\n",
       "      <td>0.524317</td>\n",
       "      <td>0.465</td>\n",
       "      <td>0.546512</td>\n",
       "      <td>0.465347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.535704</td>\n",
       "      <td>0.513979</td>\n",
       "      <td>0.465</td>\n",
       "      <td>0.526316</td>\n",
       "      <td>0.606061</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               AUC  Average_Precision  Error_Rate  Precision    Recall\n",
       "Category                                                              \n",
       "0         0.535704           0.524317       0.465   0.546512  0.465347\n",
       "1         0.535704           0.513979       0.465   0.526316  0.606061"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tree\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AUC</th>\n",
       "      <th>Average_Precision</th>\n",
       "      <th>Error_Rate</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Category</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.425093</td>\n",
       "      <td>0.473218</td>\n",
       "      <td>0.575</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.415842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.425093</td>\n",
       "      <td>0.463106</td>\n",
       "      <td>0.575</td>\n",
       "      <td>0.421569</td>\n",
       "      <td>0.434343</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               AUC  Average_Precision  Error_Rate  Precision    Recall\n",
       "Category                                                              \n",
       "0         0.425093           0.473218       0.575   0.428571  0.415842\n",
       "1         0.425093           0.463106       0.575   0.421569  0.434343"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "forest\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AUC</th>\n",
       "      <th>Average_Precision</th>\n",
       "      <th>Error_Rate</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Category</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.454895</td>\n",
       "      <td>0.484424</td>\n",
       "      <td>0.545</td>\n",
       "      <td>0.460784</td>\n",
       "      <td>0.465347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.454895</td>\n",
       "      <td>0.474546</td>\n",
       "      <td>0.545</td>\n",
       "      <td>0.448980</td>\n",
       "      <td>0.444444</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               AUC  Average_Precision  Error_Rate  Precision    Recall\n",
       "Category                                                              \n",
       "0         0.454895           0.484424       0.545   0.460784  0.465347\n",
       "1         0.454895           0.474546       0.545   0.448980  0.444444"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "neural net\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AUC</th>\n",
       "      <th>Average_Precision</th>\n",
       "      <th>Error_Rate</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Category</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.515502</td>\n",
       "      <td>0.513014</td>\n",
       "      <td>0.485</td>\n",
       "      <td>0.522222</td>\n",
       "      <td>0.465347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.515502</td>\n",
       "      <td>0.502971</td>\n",
       "      <td>0.485</td>\n",
       "      <td>0.509091</td>\n",
       "      <td>0.565657</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               AUC  Average_Precision  Error_Rate  Precision    Recall\n",
       "Category                                                              \n",
       "0         0.515502           0.513014       0.485   0.522222  0.465347\n",
       "1         0.515502           0.502971       0.485   0.509091  0.565657"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ensemble\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AUC</th>\n",
       "      <th>Average_Precision</th>\n",
       "      <th>Error_Rate</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Category</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.480048</td>\n",
       "      <td>0.495423</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.484848</td>\n",
       "      <td>0.475248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.480048</td>\n",
       "      <td>0.485423</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.475248</td>\n",
       "      <td>0.484848</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               AUC  Average_Precision  Error_Rate  Precision    Recall\n",
       "Category                                                              \n",
       "0         0.480048           0.495423        0.52   0.484848  0.475248\n",
       "1         0.480048           0.485423        0.52   0.475248  0.484848"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#dataset 1 - random!\n",
    "\n",
    "clfBayes.fit(np.stack(dfTrain['vect'], axis=0), dfTrain['category'])\n",
    "clfLinear.fit(np.stack(dfTrain['vect'], axis=0), dfTrain['category'])\n",
    "clfKernel.fit(np.stack(dfTrain['vect'], axis=0), dfTrain['category'])\n",
    "clfKNeighbors.fit(np.stack(dfTrain['vect'], axis=0), dfTrain['category'])\n",
    "clfReg.fit(np.stack(dfTrain['vect'], axis=0), dfTrain['category'])\n",
    "clfTree.fit(np.stack(dfTrain['vect'], axis=0), dfTrain['category'])\n",
    "clfForest.fit(np.stack(dfTrain['vect'], axis=0), dfTrain['category'])\n",
    "clfNN.fit(np.stack(dfTrain['vect'], axis=0), dfTrain['category'])\n",
    "clfEnsem.fit(np.stack(dfTrain['vect'], axis=0), dfTrain['category'])\n",
    "\n",
    "print(\"Bayes\")\n",
    "display(lucem_illud.evaluateClassifier(clfBayes, dfTest))\n",
    "print(\"Linear\")\n",
    "display(lucem_illud.evaluateClassifier(clfLinear, dfTest))\n",
    "print(\"Multi\")\n",
    "display(lucem_illud.evaluateClassifier(clfKernel, dfTest))\n",
    "print(\"k-neighbores\")\n",
    "display(lucem_illud.evaluateClassifier(clfKNeighbors, dfTest))\n",
    "print(\"regression\")\n",
    "display(lucem_illud.evaluateClassifier(clfReg, dfTest))\n",
    "print(\"tree\")\n",
    "display(lucem_illud.evaluateClassifier(clfTree, dfTest))\n",
    "print(\"forest\")\n",
    "display(lucem_illud.evaluateClassifier(clfForest, dfTest))\n",
    "print(\"neural net\")\n",
    "display(lucem_illud.evaluateClassifier(clfNN, dfTest))\n",
    "print(\"ensemble\")\n",
    "display(lucem_illud.evaluateClassifier(clfEnsem, dfTest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bayes\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AUC</th>\n",
       "      <th>Average_Precision</th>\n",
       "      <th>Error_Rate</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Category</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.889</td>\n",
       "      <td>0.855031</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.90566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.889</td>\n",
       "      <td>0.837521</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.891304</td>\n",
       "      <td>0.87234</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            AUC  Average_Precision  Error_Rate  Precision   Recall\n",
       "Category                                                          \n",
       "0         0.889           0.855031        0.11   0.888889  0.90566\n",
       "1         0.889           0.837521        0.11   0.891304  0.87234"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AUC</th>\n",
       "      <th>Average_Precision</th>\n",
       "      <th>Error_Rate</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Category</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.878362</td>\n",
       "      <td>0.840395</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.872727</td>\n",
       "      <td>0.905660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.878362</td>\n",
       "      <td>0.826501</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.851064</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               AUC  Average_Precision  Error_Rate  Precision    Recall\n",
       "Category                                                              \n",
       "0         0.878362           0.840395        0.12   0.872727  0.905660\n",
       "1         0.878362           0.826501        0.12   0.888889  0.851064"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multi\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AUC</th>\n",
       "      <th>Average_Precision</th>\n",
       "      <th>Error_Rate</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Category</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.889603</td>\n",
       "      <td>0.858222</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.896226</td>\n",
       "      <td>0.896226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.889603</td>\n",
       "      <td>0.834651</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.882979</td>\n",
       "      <td>0.882979</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               AUC  Average_Precision  Error_Rate  Precision    Recall\n",
       "Category                                                              \n",
       "0         0.889603           0.858222        0.11   0.896226  0.896226\n",
       "1         0.889603           0.834651        0.11   0.882979  0.882979"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k-neighbores\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AUC</th>\n",
       "      <th>Average_Precision</th>\n",
       "      <th>Error_Rate</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Category</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.904958</td>\n",
       "      <td>0.878032</td>\n",
       "      <td>0.095</td>\n",
       "      <td>0.914286</td>\n",
       "      <td>0.905660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.904958</td>\n",
       "      <td>0.854071</td>\n",
       "      <td>0.095</td>\n",
       "      <td>0.894737</td>\n",
       "      <td>0.904255</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               AUC  Average_Precision  Error_Rate  Precision    Recall\n",
       "Category                                                              \n",
       "0         0.904958           0.878032       0.095   0.914286  0.905660\n",
       "1         0.904958           0.854071       0.095   0.894737  0.904255"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "regression\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AUC</th>\n",
       "      <th>Average_Precision</th>\n",
       "      <th>Error_Rate</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Category</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.889</td>\n",
       "      <td>0.855031</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.90566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.889</td>\n",
       "      <td>0.837521</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.891304</td>\n",
       "      <td>0.87234</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            AUC  Average_Precision  Error_Rate  Precision   Recall\n",
       "Category                                                          \n",
       "0         0.889           0.855031        0.11   0.888889  0.90566\n",
       "1         0.889           0.837521        0.11   0.891304  0.87234"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tree\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AUC</th>\n",
       "      <th>Average_Precision</th>\n",
       "      <th>Error_Rate</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Category</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.874849</td>\n",
       "      <td>0.842089</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.885714</td>\n",
       "      <td>0.877358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.874849</td>\n",
       "      <td>0.812968</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.863158</td>\n",
       "      <td>0.872340</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               AUC  Average_Precision  Error_Rate  Precision    Recall\n",
       "Category                                                              \n",
       "0         0.874849           0.842089       0.125   0.885714  0.877358\n",
       "1         0.874849           0.812968       0.125   0.863158  0.872340"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "forest\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AUC</th>\n",
       "      <th>Average_Precision</th>\n",
       "      <th>Error_Rate</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Category</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.903754</td>\n",
       "      <td>0.871227</td>\n",
       "      <td>0.095</td>\n",
       "      <td>0.899083</td>\n",
       "      <td>0.924528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.903754</td>\n",
       "      <td>0.860354</td>\n",
       "      <td>0.095</td>\n",
       "      <td>0.912088</td>\n",
       "      <td>0.882979</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               AUC  Average_Precision  Error_Rate  Precision    Recall\n",
       "Category                                                              \n",
       "0         0.903754           0.871227       0.095   0.899083  0.924528\n",
       "1         0.903754           0.860354       0.095   0.912088  0.882979"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "neural net\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AUC</th>\n",
       "      <th>Average_Precision</th>\n",
       "      <th>Error_Rate</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Category</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.889</td>\n",
       "      <td>0.855031</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.90566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.889</td>\n",
       "      <td>0.837521</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.891304</td>\n",
       "      <td>0.87234</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            AUC  Average_Precision  Error_Rate  Precision   Recall\n",
       "Category                                                          \n",
       "0         0.889           0.855031        0.11   0.888889  0.90566\n",
       "1         0.889           0.837521        0.11   0.891304  0.87234"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ensemble\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AUC</th>\n",
       "      <th>Average_Precision</th>\n",
       "      <th>Error_Rate</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Category</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.887796</td>\n",
       "      <td>0.848962</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.924528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.887796</td>\n",
       "      <td>0.843694</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.851064</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               AUC  Average_Precision  Error_Rate  Precision    Recall\n",
       "Category                                                              \n",
       "0         0.887796           0.848962        0.11   0.875000  0.924528\n",
       "1         0.887796           0.843694        0.11   0.909091  0.851064"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#dataset 2 - andSplit\n",
    "\n",
    "clfBayes.fit(np.stack(dfTrain1['vect'], axis=0), dfTrain1['category'])\n",
    "clfLinear.fit(np.stack(dfTrain1['vect'], axis=0), dfTrain1['category'])\n",
    "clfKernel.fit(np.stack(dfTrain1['vect'], axis=0), dfTrain1['category'])\n",
    "clfKNeighbors.fit(np.stack(dfTrain1['vect'], axis=0), dfTrain1['category'])\n",
    "clfReg.fit(np.stack(dfTrain1['vect'], axis=0), dfTrain1['category'])\n",
    "clfTree.fit(np.stack(dfTrain1['vect'], axis=0), dfTrain1['category'])\n",
    "clfForest.fit(np.stack(dfTrain1['vect'], axis=0), dfTrain1['category'])\n",
    "clfNN.fit(np.stack(dfTrain1['vect'], axis=0), dfTrain1['category'])\n",
    "clfEnsem.fit(np.stack(dfTrain1['vect'], axis=0), dfTrain1['category'])\n",
    "\n",
    "print(\"Bayes\")\n",
    "display(lucem_illud.evaluateClassifier(clfBayes, dfTest1))\n",
    "print(\"Linear\")\n",
    "display(lucem_illud.evaluateClassifier(clfLinear, dfTest1))\n",
    "print(\"Multi\")\n",
    "display(lucem_illud.evaluateClassifier(clfKernel, dfTest1))\n",
    "print(\"k-neighbores\")\n",
    "display(lucem_illud.evaluateClassifier(clfKNeighbors, dfTest1))\n",
    "print(\"regression\")\n",
    "display(lucem_illud.evaluateClassifier(clfReg, dfTest1))\n",
    "print(\"tree\")\n",
    "display(lucem_illud.evaluateClassifier(clfTree, dfTest1))\n",
    "print(\"forest\")\n",
    "display(lucem_illud.evaluateClassifier(clfForest, dfTest1))\n",
    "print(\"neural net\")\n",
    "display(lucem_illud.evaluateClassifier(clfNN, dfTest1))\n",
    "print(\"ensemble\")\n",
    "display(lucem_illud.evaluateClassifier(clfEnsem, dfTest1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\computation\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AUC</th>\n",
       "      <th>Average_Precision</th>\n",
       "      <th>Error_Rate</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Category</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.518607</td>\n",
       "      <td>0.499710</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.511628</td>\n",
       "      <td>0.448980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.518607</td>\n",
       "      <td>0.519598</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.526316</td>\n",
       "      <td>0.588235</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               AUC  Average_Precision  Error_Rate  Precision    Recall\n",
       "Category                                                              \n",
       "0         0.518607           0.499710        0.48   0.511628  0.448980\n",
       "1         0.518607           0.519598        0.48   0.526316  0.588235"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AUC</th>\n",
       "      <th>Average_Precision</th>\n",
       "      <th>Error_Rate</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Category</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.55082</td>\n",
       "      <td>0.517838</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.537037</td>\n",
       "      <td>0.591837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.55082</td>\n",
       "      <td>0.538150</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.565217</td>\n",
       "      <td>0.509804</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              AUC  Average_Precision  Error_Rate  Precision    Recall\n",
       "Category                                                             \n",
       "0         0.55082           0.517838        0.45   0.537037  0.591837\n",
       "1         0.55082           0.538150        0.45   0.565217  0.509804"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AUC</th>\n",
       "      <th>Average_Precision</th>\n",
       "      <th>Error_Rate</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Category</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.685274</td>\n",
       "      <td>0.649906</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.846154</td>\n",
       "      <td>0.448980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.685274</td>\n",
       "      <td>0.625321</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.635135</td>\n",
       "      <td>0.921569</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               AUC  Average_Precision  Error_Rate  Precision    Recall\n",
       "Category                                                              \n",
       "0         0.685274           0.649906        0.31   0.846154  0.448980\n",
       "1         0.685274           0.625321        0.31   0.635135  0.921569"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AUC</th>\n",
       "      <th>Average_Precision</th>\n",
       "      <th>Error_Rate</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Category</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.895458</td>\n",
       "      <td>0.842457</td>\n",
       "      <td>0.105</td>\n",
       "      <td>0.873786</td>\n",
       "      <td>0.918367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.895458</td>\n",
       "      <td>0.865586</td>\n",
       "      <td>0.105</td>\n",
       "      <td>0.917526</td>\n",
       "      <td>0.872549</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               AUC  Average_Precision  Error_Rate  Precision    Recall\n",
       "Category                                                              \n",
       "0         0.895458           0.842457       0.105   0.873786  0.918367\n",
       "1         0.895458           0.865586       0.105   0.917526  0.872549"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AUC</th>\n",
       "      <th>Average_Precision</th>\n",
       "      <th>Error_Rate</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Category</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.509804</td>\n",
       "      <td>0.495000</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.509804</td>\n",
       "      <td>0.514992</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.519608</td>\n",
       "      <td>0.519608</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               AUC  Average_Precision  Error_Rate  Precision    Recall\n",
       "Category                                                              \n",
       "0         0.509804           0.495000        0.49   0.500000  0.500000\n",
       "1         0.509804           0.514992        0.49   0.519608  0.519608"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AUC</th>\n",
       "      <th>Average_Precision</th>\n",
       "      <th>Error_Rate</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Category</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.880152</td>\n",
       "      <td>0.827347</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.887755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.880152</td>\n",
       "      <td>0.841569</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.872549</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               AUC  Average_Precision  Error_Rate  Precision    Recall\n",
       "Category                                                              \n",
       "0         0.880152           0.827347        0.12       0.87  0.887755\n",
       "1         0.880152           0.841569        0.12       0.89  0.872549"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AUC</th>\n",
       "      <th>Average_Precision</th>\n",
       "      <th>Error_Rate</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Category</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.885654</td>\n",
       "      <td>0.827172</td>\n",
       "      <td>0.115</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.918367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.885654</td>\n",
       "      <td>0.856115</td>\n",
       "      <td>0.115</td>\n",
       "      <td>0.915789</td>\n",
       "      <td>0.852941</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               AUC  Average_Precision  Error_Rate  Precision    Recall\n",
       "Category                                                              \n",
       "0         0.885654           0.827172       0.115   0.857143  0.918367\n",
       "1         0.885654           0.856115       0.115   0.915789  0.852941"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AUC</th>\n",
       "      <th>Average_Precision</th>\n",
       "      <th>Error_Rate</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Category</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.90016</td>\n",
       "      <td>0.853265</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.908163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.90016</td>\n",
       "      <td>0.866863</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.892157</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              AUC  Average_Precision  Error_Rate  Precision    Recall\n",
       "Category                                                             \n",
       "0         0.90016           0.853265         0.1       0.89  0.908163\n",
       "1         0.90016           0.866863         0.1       0.91  0.892157"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AUC</th>\n",
       "      <th>Average_Precision</th>\n",
       "      <th>Error_Rate</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Category</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.880352</td>\n",
       "      <td>0.82471</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.862745</td>\n",
       "      <td>0.897959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.880352</td>\n",
       "      <td>0.84471</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.897959</td>\n",
       "      <td>0.862745</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               AUC  Average_Precision  Error_Rate  Precision    Recall\n",
       "Category                                                              \n",
       "0         0.880352            0.82471        0.12   0.862745  0.897959\n",
       "1         0.880352            0.84471        0.12   0.897959  0.862745"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#dataset 3 - xorsplit!\n",
    "\n",
    "clfBayes.fit(np.stack(dfTrain2['vect'], axis=0), dfTrain2['category'])\n",
    "clfLinear.fit(np.stack(dfTrain2['vect'], axis=0), dfTrain2['category'])\n",
    "clfKernel.fit(np.stack(dfTrain2['vect'], axis=0), dfTrain2['category'])\n",
    "clfKNeighbors.fit(np.stack(dfTrain2['vect'], axis=0), dfTrain2['category'])\n",
    "clfReg.fit(np.stack(dfTrain2['vect'], axis=0), dfTrain2['category'])\n",
    "clfTree.fit(np.stack(dfTrain2['vect'], axis=0), dfTrain2['category'])\n",
    "clfForest.fit(np.stack(dfTrain2['vect'], axis=0), dfTrain2['category'])\n",
    "clfNN.fit(np.stack(dfTrain2['vect'], axis=0), dfTrain2['category'])\n",
    "clfEnsem.fit(np.stack(dfTrain2['vect'], axis=0), dfTrain2['category'])\n",
    "\n",
    "display(lucem_illud.evaluateClassifier(clfBayes, dfTest2))\n",
    "display(lucem_illud.evaluateClassifier(clfLinear, dfTest2))\n",
    "display(lucem_illud.evaluateClassifier(clfKernel, dfTest2))\n",
    "display(lucem_illud.evaluateClassifier(clfKNeighbors, dfTest2))\n",
    "display(lucem_illud.evaluateClassifier(clfReg, dfTest2))\n",
    "display(lucem_illud.evaluateClassifier(clfTree, dfTest2))\n",
    "display(lucem_illud.evaluateClassifier(clfForest, dfTest2))\n",
    "display(lucem_illud.evaluateClassifier(clfNN, dfTest2))\n",
    "display(lucem_illud.evaluateClassifier(clfEnsem, dfTest2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\computation\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AUC</th>\n",
       "      <th>Average_Precision</th>\n",
       "      <th>Error_Rate</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Category</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.909105</td>\n",
       "      <td>0.836668</td>\n",
       "      <td>0.095</td>\n",
       "      <td>0.849057</td>\n",
       "      <td>0.967742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.909105</td>\n",
       "      <td>0.903325</td>\n",
       "      <td>0.095</td>\n",
       "      <td>0.968085</td>\n",
       "      <td>0.850467</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               AUC  Average_Precision  Error_Rate  Precision    Recall\n",
       "Category                                                              \n",
       "0         0.909105           0.836668       0.095   0.849057  0.967742\n",
       "1         0.909105           0.903325       0.095   0.968085  0.850467"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AUC</th>\n",
       "      <th>Average_Precision</th>\n",
       "      <th>Error_Rate</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Category</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.617978</td>\n",
       "      <td>0.532737</td>\n",
       "      <td>0.405</td>\n",
       "      <td>0.536585</td>\n",
       "      <td>0.946237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.617978</td>\n",
       "      <td>0.629481</td>\n",
       "      <td>0.405</td>\n",
       "      <td>0.861111</td>\n",
       "      <td>0.289720</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               AUC  Average_Precision  Error_Rate  Precision    Recall\n",
       "Category                                                              \n",
       "0         0.617978           0.532737       0.405   0.536585  0.946237\n",
       "1         0.617978           0.629481       0.405   0.861111  0.289720"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\computation\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AUC</th>\n",
       "      <th>Average_Precision</th>\n",
       "      <th>Error_Rate</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Category</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.465</td>\n",
       "      <td>0.535</td>\n",
       "      <td>0.465</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.535</td>\n",
       "      <td>0.535</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          AUC  Average_Precision  Error_Rate  Precision  Recall\n",
       "Category                                                       \n",
       "0         0.5              0.465       0.535      0.465     1.0\n",
       "1         0.5              0.535       0.535      0.000     0.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AUC</th>\n",
       "      <th>Average_Precision</th>\n",
       "      <th>Error_Rate</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Category</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.868908</td>\n",
       "      <td>0.785254</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.811321</td>\n",
       "      <td>0.924731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.868908</td>\n",
       "      <td>0.852535</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.925532</td>\n",
       "      <td>0.813084</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               AUC  Average_Precision  Error_Rate  Precision    Recall\n",
       "Category                                                              \n",
       "0         0.868908           0.785254       0.135   0.811321  0.924731\n",
       "1         0.868908           0.852535       0.135   0.925532  0.813084"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AUC</th>\n",
       "      <th>Average_Precision</th>\n",
       "      <th>Error_Rate</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Category</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.586624</td>\n",
       "      <td>0.514153</td>\n",
       "      <td>0.425</td>\n",
       "      <td>0.530303</td>\n",
       "      <td>0.752688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.586624</td>\n",
       "      <td>0.588312</td>\n",
       "      <td>0.425</td>\n",
       "      <td>0.661765</td>\n",
       "      <td>0.420561</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               AUC  Average_Precision  Error_Rate  Precision    Recall\n",
       "Category                                                              \n",
       "0         0.586624           0.514153       0.425   0.530303  0.752688\n",
       "1         0.586624           0.588312       0.425   0.661765  0.420561"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AUC</th>\n",
       "      <th>Average_Precision</th>\n",
       "      <th>Error_Rate</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Category</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.83268</td>\n",
       "      <td>0.744936</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.786408</td>\n",
       "      <td>0.870968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.83268</td>\n",
       "      <td>0.806117</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.876289</td>\n",
       "      <td>0.794393</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              AUC  Average_Precision  Error_Rate  Precision    Recall\n",
       "Category                                                             \n",
       "0         0.83268           0.744936        0.17   0.786408  0.870968\n",
       "1         0.83268           0.806117        0.17   0.876289  0.794393"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AUC</th>\n",
       "      <th>Average_Precision</th>\n",
       "      <th>Error_Rate</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Category</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.854186</td>\n",
       "      <td>0.766058</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.794393</td>\n",
       "      <td>0.913978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.854186</td>\n",
       "      <td>0.836058</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.913978</td>\n",
       "      <td>0.794393</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               AUC  Average_Precision  Error_Rate  Precision    Recall\n",
       "Category                                                              \n",
       "0         0.854186           0.766058        0.15   0.794393  0.913978\n",
       "1         0.854186           0.836058        0.15   0.913978  0.794393"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AUC</th>\n",
       "      <th>Average_Precision</th>\n",
       "      <th>Error_Rate</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Category</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.889006</td>\n",
       "      <td>0.810555</td>\n",
       "      <td>0.115</td>\n",
       "      <td>0.830189</td>\n",
       "      <td>0.946237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.889006</td>\n",
       "      <td>0.877532</td>\n",
       "      <td>0.115</td>\n",
       "      <td>0.946809</td>\n",
       "      <td>0.831776</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               AUC  Average_Precision  Error_Rate  Precision    Recall\n",
       "Category                                                              \n",
       "0         0.889006           0.810555       0.115   0.830189  0.946237\n",
       "1         0.889006           0.877532       0.115   0.946809  0.831776"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AUC</th>\n",
       "      <th>Average_Precision</th>\n",
       "      <th>Error_Rate</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Category</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.858155</td>\n",
       "      <td>0.774529</td>\n",
       "      <td>0.145</td>\n",
       "      <td>0.807692</td>\n",
       "      <td>0.903226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.858155</td>\n",
       "      <td>0.836857</td>\n",
       "      <td>0.145</td>\n",
       "      <td>0.906250</td>\n",
       "      <td>0.813084</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               AUC  Average_Precision  Error_Rate  Precision    Recall\n",
       "Category                                                              \n",
       "0         0.858155           0.774529       0.145   0.807692  0.903226\n",
       "1         0.858155           0.836857       0.145   0.906250  0.813084"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#dataset 4 - targetsplit!\n",
    "\n",
    "clfBayes.fit(np.stack(dfTrain3['vect'], axis=0), dfTrain3['category'])\n",
    "clfLinear.fit(np.stack(dfTrain3['vect'], axis=0), dfTrain3['category'])\n",
    "clfKernel.fit(np.stack(dfTrain3['vect'], axis=0), dfTrain3['category'])\n",
    "clfKNeighbors.fit(np.stack(dfTrain3['vect'], axis=0), dfTrain3['category'])\n",
    "clfReg.fit(np.stack(dfTrain3['vect'], axis=0), dfTrain3['category'])\n",
    "clfTree.fit(np.stack(dfTrain3['vect'], axis=0), dfTrain3['category'])\n",
    "clfForest.fit(np.stack(dfTrain3['vect'], axis=0), dfTrain3['category'])\n",
    "clfNN.fit(np.stack(dfTrain3['vect'], axis=0), dfTrain3['category'])\n",
    "clfEnsem.fit(np.stack(dfTrain3['vect'], axis=0), dfTrain3['category'])\n",
    "\n",
    "display(lucem_illud.evaluateClassifier(clfBayes, dfTest3))\n",
    "display(lucem_illud.evaluateClassifier(clfLinear, dfTest3))\n",
    "display(lucem_illud.evaluateClassifier(clfKernel, dfTest3))\n",
    "display(lucem_illud.evaluateClassifier(clfKNeighbors, dfTest3))\n",
    "display(lucem_illud.evaluateClassifier(clfReg, dfTest3))\n",
    "display(lucem_illud.evaluateClassifier(clfTree, dfTest3))\n",
    "display(lucem_illud.evaluateClassifier(clfForest, dfTest3))\n",
    "display(lucem_illud.evaluateClassifier(clfNN, dfTest3))\n",
    "display(lucem_illud.evaluateClassifier(clfEnsem, dfTest3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AUC</th>\n",
       "      <th>Average_Precision</th>\n",
       "      <th>Error_Rate</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Category</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.996250</td>\n",
       "      <td>0.970874</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.970874</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.985849</td>\n",
       "      <td>0.977698</td>\n",
       "      <td>0.006</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.971698</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               AUC  Average_Precision  Error_Rate  Precision    Recall\n",
       "Category                                                              \n",
       "0         0.996250           0.970874       0.006   0.970874  1.000000\n",
       "1         1.000000           1.000000       0.000   1.000000  1.000000\n",
       "2         1.000000           1.000000       0.000   1.000000  1.000000\n",
       "3         1.000000           1.000000       0.000   1.000000  1.000000\n",
       "4         0.985849           0.977698       0.006   1.000000  0.971698"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AUC</th>\n",
       "      <th>Average_Precision</th>\n",
       "      <th>Error_Rate</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Category</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.997500</td>\n",
       "      <td>0.980392</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.980392</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.997531</td>\n",
       "      <td>0.979381</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.979381</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.981132</td>\n",
       "      <td>0.970264</td>\n",
       "      <td>0.008</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.962264</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               AUC  Average_Precision  Error_Rate  Precision    Recall\n",
       "Category                                                              \n",
       "0         0.997500           0.980392       0.004   0.980392  1.000000\n",
       "1         0.997531           0.979381       0.004   0.979381  1.000000\n",
       "2         1.000000           1.000000       0.000   1.000000  1.000000\n",
       "3         1.000000           1.000000       0.000   1.000000  1.000000\n",
       "4         0.981132           0.970264       0.008   1.000000  0.962264"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AUC</th>\n",
       "      <th>Average_Precision</th>\n",
       "      <th>Error_Rate</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Category</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.997500</td>\n",
       "      <td>0.980392</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.980392</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.998765</td>\n",
       "      <td>0.989583</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.989583</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.985849</td>\n",
       "      <td>0.977698</td>\n",
       "      <td>0.006</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.971698</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               AUC  Average_Precision  Error_Rate  Precision    Recall\n",
       "Category                                                              \n",
       "0         0.997500           0.980392       0.004   0.980392  1.000000\n",
       "1         0.998765           0.989583       0.002   0.989583  1.000000\n",
       "2         1.000000           1.000000       0.000   1.000000  1.000000\n",
       "3         1.000000           1.000000       0.000   1.000000  1.000000\n",
       "4         0.985849           0.977698       0.006   1.000000  0.971698"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AUC</th>\n",
       "      <th>Average_Precision</th>\n",
       "      <th>Error_Rate</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Category</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.997500</td>\n",
       "      <td>0.980392</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.980392</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.998775</td>\n",
       "      <td>0.989247</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.989247</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.995327</td>\n",
       "      <td>0.992654</td>\n",
       "      <td>0.002</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.990654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.990566</td>\n",
       "      <td>0.985132</td>\n",
       "      <td>0.004</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.981132</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               AUC  Average_Precision  Error_Rate  Precision    Recall\n",
       "Category                                                              \n",
       "0         0.997500           0.980392       0.004   0.980392  1.000000\n",
       "1         1.000000           1.000000       0.000   1.000000  1.000000\n",
       "2         0.998775           0.989247       0.002   0.989247  1.000000\n",
       "3         0.995327           0.992654       0.002   1.000000  0.990654\n",
       "4         0.990566           0.985132       0.004   1.000000  0.981132"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AUC</th>\n",
       "      <th>Average_Precision</th>\n",
       "      <th>Error_Rate</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Category</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.991250</td>\n",
       "      <td>0.934579</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.934579</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.997531</td>\n",
       "      <td>0.979381</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.979381</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.998775</td>\n",
       "      <td>0.989247</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.989247</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.995327</td>\n",
       "      <td>0.992654</td>\n",
       "      <td>0.002</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.990654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.957547</td>\n",
       "      <td>0.933094</td>\n",
       "      <td>0.018</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.915094</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               AUC  Average_Precision  Error_Rate  Precision    Recall\n",
       "Category                                                              \n",
       "0         0.991250           0.934579       0.014   0.934579  1.000000\n",
       "1         0.997531           0.979381       0.004   0.979381  1.000000\n",
       "2         0.998775           0.989247       0.002   0.989247  1.000000\n",
       "3         0.995327           0.992654       0.002   1.000000  0.990654\n",
       "4         0.957547           0.933094       0.018   1.000000  0.915094"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AUC</th>\n",
       "      <th>Average_Precision</th>\n",
       "      <th>Error_Rate</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Category</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.995000</td>\n",
       "      <td>0.961538</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.961538</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.994565</td>\n",
       "      <td>0.991130</td>\n",
       "      <td>0.002</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.989130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.998728</td>\n",
       "      <td>0.990741</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.990741</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.981132</td>\n",
       "      <td>0.970264</td>\n",
       "      <td>0.008</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.962264</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               AUC  Average_Precision  Error_Rate  Precision    Recall\n",
       "Category                                                              \n",
       "0         0.995000           0.961538       0.008   0.961538  1.000000\n",
       "1         1.000000           1.000000       0.000   1.000000  1.000000\n",
       "2         0.994565           0.991130       0.002   1.000000  0.989130\n",
       "3         0.998728           0.990741       0.002   0.990741  1.000000\n",
       "4         0.981132           0.970264       0.008   1.000000  0.962264"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AUC</th>\n",
       "      <th>Average_Precision</th>\n",
       "      <th>Error_Rate</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Category</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.993750</td>\n",
       "      <td>0.952381</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.952381</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.994737</td>\n",
       "      <td>0.991474</td>\n",
       "      <td>0.002</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.989474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.981132</td>\n",
       "      <td>0.970264</td>\n",
       "      <td>0.008</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.962264</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               AUC  Average_Precision  Error_Rate  Precision    Recall\n",
       "Category                                                              \n",
       "0         0.993750           0.952381       0.010   0.952381  1.000000\n",
       "1         0.994737           0.991474       0.002   1.000000  0.989474\n",
       "2         1.000000           1.000000       0.000   1.000000  1.000000\n",
       "3         1.000000           1.000000       0.000   1.000000  1.000000\n",
       "4         0.981132           0.970264       0.008   1.000000  0.962264"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AUC</th>\n",
       "      <th>Average_Precision</th>\n",
       "      <th>Error_Rate</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Category</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.99125</td>\n",
       "      <td>0.962882</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.970588</td>\n",
       "      <td>0.990000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.98458</td>\n",
       "      <td>0.968355</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.990385</td>\n",
       "      <td>0.971698</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              AUC  Average_Precision  Error_Rate  Precision    Recall\n",
       "Category                                                             \n",
       "0         0.99125           0.962882       0.008   0.970588  0.990000\n",
       "1         1.00000           1.000000       0.000   1.000000  1.000000\n",
       "2         1.00000           1.000000       0.000   1.000000  1.000000\n",
       "3         1.00000           1.000000       0.000   1.000000  1.000000\n",
       "4         0.98458           0.968355       0.008   0.990385  0.971698"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AUC</th>\n",
       "      <th>Average_Precision</th>\n",
       "      <th>Error_Rate</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Category</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.995000</td>\n",
       "      <td>0.961538</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.961538</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.981132</td>\n",
       "      <td>0.970264</td>\n",
       "      <td>0.008</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.962264</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               AUC  Average_Precision  Error_Rate  Precision    Recall\n",
       "Category                                                              \n",
       "0         0.995000           0.961538       0.008   0.961538  1.000000\n",
       "1         1.000000           1.000000       0.000   1.000000  1.000000\n",
       "2         1.000000           1.000000       0.000   1.000000  1.000000\n",
       "3         1.000000           1.000000       0.000   1.000000  1.000000\n",
       "4         0.981132           0.970264       0.008   1.000000  0.962264"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#dataset 5 - multiBlobs! \n",
    "\n",
    "clfBayes.fit(np.stack(dfTrain4['vect'], axis=0), dfTrain4['category'])\n",
    "clfLinear.fit(np.stack(dfTrain4['vect'], axis=0), dfTrain4['category'])\n",
    "clfKernel.fit(np.stack(dfTrain4['vect'], axis=0), dfTrain4['category'])\n",
    "clfKNeighbors.fit(np.stack(dfTrain4['vect'], axis=0), dfTrain4['category'])\n",
    "clfReg.fit(np.stack(dfTrain4['vect'], axis=0), dfTrain4['category'])\n",
    "clfTree.fit(np.stack(dfTrain4['vect'], axis=0), dfTrain4['category'])\n",
    "clfForest.fit(np.stack(dfTrain4['vect'], axis=0), dfTrain4['category'])\n",
    "clfNN.fit(np.stack(dfTrain4['vect'], axis=0), dfTrain4['category'])\n",
    "clfEnsem.fit(np.stack(dfTrain4['vect'], axis=0), dfTrain4['category'])\n",
    "\n",
    "display(lucem_illud.evaluateClassifier(clfBayes, dfTest4))\n",
    "display(lucem_illud.evaluateClassifier(clfLinear, dfTest4))\n",
    "display(lucem_illud.evaluateClassifier(clfKernel, dfTest4))\n",
    "display(lucem_illud.evaluateClassifier(clfKNeighbors, dfTest4))\n",
    "display(lucem_illud.evaluateClassifier(clfReg, dfTest4))\n",
    "display(lucem_illud.evaluateClassifier(clfTree, dfTest4))\n",
    "display(lucem_illud.evaluateClassifier(clfForest, dfTest4))\n",
    "display(lucem_illud.evaluateClassifier(clfNN, dfTest4))\n",
    "display(lucem_illud.evaluateClassifier(clfEnsem, dfTest4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can easily visualize the rendered datasets because they are generated in two dimensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAmUAAAJCCAYAAACBJrCpAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1f20eaa82e8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lucem_illud.plotter(dfTrain)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training a Machine Learning algorithm\n",
    "\n",
    "We can now pick a model, there are many more options in `scikit-learn`. These are just a few examples, which array along the machine learning \"tribes\" described in Pedro Domingos _The Master Algorithm_.\n",
    "\n",
    "Uncomment (remove the # in front of) each algorithm one at a time, then run the cell and subsequent cells to evaluate how it learns to understand the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Bayes\n",
    "clf = sklearn.naive_bayes.GaussianNB()\n",
    "\n",
    "#Analogizes\n",
    "#clf = sklearn.svm.SVC(kernel = 'linear', probability = True) #slow, set probability = False to speed up\n",
    "#clf = sklearn.svm.SVC(kernel = 'poly', degree = 3, probability = True) #slower\n",
    "#clf = sklearn.neighbors.KNeighborsClassifier(5, weights='distance')# k, 'distance' or 'uniform'\n",
    "\n",
    "#Classical Regression\n",
    "#clf = sklearn.linear_model.LogisticRegression()\n",
    "\n",
    "#Symbolists\n",
    "#clf = sklearn.tree.DecisionTreeClassifier()\n",
    "#clf = sklearn.ensemble.RandomForestClassifier()\n",
    "\n",
    "#Connectionists\n",
    "#clf = sklearn.neural_network.MLPClassifier()\n",
    "\n",
    "#Ensemble\n",
    "#clf = sklearn.ensemble.GradientBoostingClassifier()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we fit the model by giving it our training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianNB(priors=None)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(np.stack(dfTrain['vect'], axis=0), dfTrain['category'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Algorithm evaluation\n",
    "\n",
    "We can look at few measurements of each classifier's performance by using the testing set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AUC</th>\n",
       "      <th>Average_Precision</th>\n",
       "      <th>Error_Rate</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Category</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.464896</td>\n",
       "      <td>0.488646</td>\n",
       "      <td>0.535</td>\n",
       "      <td>0.470588</td>\n",
       "      <td>0.475248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.464896</td>\n",
       "      <td>0.478720</td>\n",
       "      <td>0.535</td>\n",
       "      <td>0.459184</td>\n",
       "      <td>0.454545</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               AUC  Average_Precision  Error_Rate  Precision    Recall\n",
       "Category                                                              \n",
       "0         0.464896           0.488646       0.535   0.470588  0.475248\n",
       "1         0.464896           0.478720       0.535   0.459184  0.454545"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lucem_illud.evaluateClassifier(clf, dfTest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This lets us look at which classes do better:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQoAAAEWCAYAAACe39kpAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4yLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvNQv5yAAAFM9JREFUeJzt3Xm8VWW9x/HP92BMAiqgOBRqzsNL\n82qKE9pgSlnqdUqRUFMzxDLnkgqnBkuvaTjnhClKaak4XhNT0wQUVNLERG+CE2iOKNPv/rHWoe0J\n9rNE9lkL9vf9ep3X2WvYa/02nPM9z7OeNSgiMDOrp6XsAsys+hwUZpbkoDCzJAeFmSU5KMwsyUFh\nZkkOimWcpC6SbpH0pqTRH2M7AyXdtSRrK4Ok2yUNLruOpY2DoiIkHShpvKR3JL2U/0DvsAQ2vQ/Q\nB+gVEfsu7kYi4rcR8aUlUM+HSNpZUki6sc38zfP5YwtuZ7ika1LrRcSAiLhqMcttWg6KCpB0LHAu\n8BOyX+q+wAXAHktg82sCz0TE3CWwrUZ5DdhOUq+aeYOBZ5bUDpTxz/viigh/lfgFrAC8A+xbZ51O\nZEEyPf86F+iUL9sZeBE4DngVeAk4JF92KjAbmJPv45vAcOCamm2vBQSwXD59MPAc8DYwFRhYM/+B\nmvdtB4wD3sy/b1ezbCxwOvBgvp27gN6L+Gyt9V8EHJXP65DP+xEwtmbdXwH/BN4CJgA75vN3a/M5\nJ9XUcWZexyxg3XzeYfnyC4Hf1Wz/58A9gMr+uajalxO2fNsCnYGb6qxzCtAP+AywObA1MKxm+apk\ngbMGWRiMkLRSRPyYrJVyfUR0i4jf1CtE0vLAecCAiOhOFgYTF7JeT2BMvm4v4BxgTJsWwYHAIcAq\nQEfg+Hr7Bq4GvpG/3hWYTBaKtcaR/Rv0BK4FRkvqHBF3tPmcm9e8ZxBwBNAdeKHN9o4DNpN0sKQd\nyf7tBkeeGvZvDory9QJmRP2uwUDgtIh4NSJeI2spDKpZPidfPicibiP7q7rBYtYzH9hUUpeIeCki\nJi9kna8AUyJiZETMjYjrgKeBr9asc0VEPBMRs4AbyH7BFyki/gL0lLQBWWBcvZB1romImfk+zyZr\naaU+55URMTl/z5w223sPOIgs6K4Bjo6IFxPba0oOivLNBHpLWq7OOqvz4b+GL+TzFmyjTdC8B3T7\nqIVExLvA/sCRwEuSxkjasEA9rTWtUTP98mLUMxIYCnyOhbSwJB0n6al8BOdfZK2o3olt/rPewoh4\nhKyrJbJAs4VwUJTvIeB9YM8660wnOyjZqi//2Swv6l2ga830qrULI+LOiNgFWI2slXBpgXpaa5q2\nmDW1GgkMAW7L/9ovkHcNTgL2A1aKiBXJjo+otfRFbLNuN0LSUWQtk+nAiYtf+rLNQVGyiHiT7KDd\nCEl7Suoq6ROSBkg6K1/tOmCYpJUl9c7XTw4FLsJEoL+kvpJWAL7fukBSH0lfy49VfEDWhZm3kG3c\nBqyfD+kuJ2l/YGPg1sWsCYCImArsRHZMpq3uwFyyEZLlJP0I6FGz/BVgrY8ysiFpfeAMsu7HIOBE\nSXW7SM3KQVEBEXEOcCzZAcrXyJrLQ4E/5KucAYwHHgeeAB7N5y3Ovu4Grs+3NYEP/3K3kB3gmw68\nTvZLO2Qh25gJ7J6vO5PsL/HuETFjcWpqs+0HImJhraU7gdvJhkxfIGuF1XYrWk8mmynp0dR+8q7e\nNcDPI2JSREwBfgCMlNTp43yGZZF8gNfMUtyiMLMkB4WZJTkozCzJQWFmSfVO8inVmWsO9FHWpcix\nI3cpuwRbDF36H6z0Wm5RmFkBDgozS3JQmFmSg8LMkhwUZpbkoDCzJAeFmSU5KMwsyUFhZkkOCjNL\nclCYWZKDwsySHBRmluSgMLMkB4WZJTkozCzJQWFmSQ4KM0tyUJhZkoPCzJIcFGaW5KAwsyQHhZkl\nOSjMLMlBYWZJDgozS3JQmFmSg8LMkhwUZpbkoDCzJAeFmSU5KMwsyUFhZkkOCjNLclCYWZKDwsyS\nHBRmluSgMLMkB4WZJTkozCzJQWFmSQ4KM0tyUJhZkoPCzJIcFGaW5KAwsyQHhZklOSjMLMlBYWZJ\nDgozS1qu7AKagVrEobeewdsvv8ENh/6StbbfhC/84ACkFma/9z63HHcxb7zwStllWm7AyRewfOeO\ntEgs16GFa4cdwog/3MfYiVOQRM8eXTntkN1ZZcXuZZfabhwU7eCzh+7GjGen06lbFwB2O+MQRh9+\nDjOfnc6Wg77I9kfvya3HX1xylVbr0uMOZKXuXRdMD961H0ftuRMA194zjktueZBhg3Yrq7x2565H\ng3VftSfrfv4zTBx1779nRiwIjU7du/LOK2+UVJ0V1a1LpwWvZ30wB6nEYkrQ7i0KSYdExBXtvd+y\n7PLjQfzpJ9fRMQ8GgDEnXcb+V57A3Pfn8ME7s7hyzx+XWKG1JeDb545CiL13+gz79N8CgPNvuo9b\nH3qCbl06cenxA8stsp2V0aI4dVELJB0habyk8ePeebY9a2qIdT+/Be/NfJOXn3z+Q/O3PmwA1x/8\nC87vdzSPj76PXX7YXD90VXflyYMY9cNDGfHd/bjh3keZ8Mz/AXD0Xjtx51lD+fI2mzDqT+NLrrJ9\nNSQoJD2+iK8ngD6Lel9EXBIRW0XEVp/ttm4jSmtXn9xqfdb74pYc9cC57HX+UNbabmP2v+J4+mzU\nl+kT/wHA3255mDW2XL/kSq1W60HKnj2W53NbrM+TU1/60PIB22zCPY/+vYzSStOorkcfYFegbedb\nwF8atM/KGXvW9Yw963oA+vbbiH5HfIXRh5/DMeMvoOfaq/L61JdZe8dNmfnstJIrtVazPpjN/AiW\n79yJWR/M5qG/TeVbu2/PC6+8zpp9egJw38QprL1qr5IrbV+NCopbgW4RMbHtAkljG7TPpULMm89t\nJ1/G3hcdQ8yfz/tvvsutJ1xSdlmWm/nWuxx7wY0AzJ03nwHbbMz2m67DcRfeyPMvz6RFYrVeK3DK\nQc0z4gGgiCi7hoU6c82B1SzMFurYkbuUXYIthi79Dy40fuPhUTNLclCYWZKDwsySHBRmluSgMLMk\nB4WZJTkozCzJQWFmSQ4KM0tyUJhZkoPCzJIcFGaW5KAws6RFXmYuqWe9N0bE60u+HDOronr3o5gA\nBNnNZtoK4NMNqcjMKmeRQRERa7dnIWZWXcljFMocJOmH+XRfSVs3vjQzq4oiBzMvALYFDsyn3wZG\nNKwiM6ucIvfM3CYi/kvSYwAR8Yakjg2uy8wqpEiLYo6kDmQHMJG0MjC/oVWZWaUUCYrzgJuAPpLO\nBB4AftLQqsysUpJdj4j4raQJwBfyWXtGxFONLcvMqqTocz26Aq3djy6Jdc1sGVNkePRHwFVAT6A3\ncIWkYY0uzMyqo0iL4gBgi4h4H0DSz4BHgTMaWZiZVUeRg5nPA51rpjsB/2hINWZWSfUuCjuf7JjE\nB8BkSXfn07uQjXyYWZOo1/UYn3+fQDY82mpsw6oxs0qqd1HYVe1ZiJlVV/JgpqT1gJ8CG1NzrCIi\nfJm5WZMocjDzCuBCYC7wOeBqYGQjizKzaikSFF0i4h5AEfFCRAwHPt/YssysSoqcR/G+pBZgiqSh\nwDRglcaWZWZVUqRFcQzZKdzfAbYEBgGDG1mUmVVLkYvCxuUv3wEOaWw5ZlZF9U64uoX8HhQLExFf\na0hFZlY59VoUv2y3Ksys0uqdcHVfexZiZtXlJ4WZWZKDwsySHBRmluRRDzNLKjLq8d/AqsA1+fQB\nZDezMbMmkRz1kHR6RPSvWXSLpD83vDIzq4wixyhWlrTgknJJawMrN64kM6uaIheFfQ8YK+m5fHot\n4FsNq8jMKqfItR535Dev2TCf9XREfNDYssysSoo816MrcAIwNCImAX0l7d7wysysMore4Wo2sG0+\n/SJ+podZU1HEIk+VyFaQxkfEVpIei4gt8nmTImLzRhY2Z8Zz9QuzSumy+o5ll2CLYe7saSqyXpEW\nxWxJXchPvpK0DtmzPsysSRQZ9RgO3AF8StJvge3xDWzMmkqRUY+7JE0A+gECvhsRMxpemZlVRpFR\nj3siYmZEjImIWyNihqR72qM4M6uGeheFdSa7qW5vSSuRtSYAegCrt0NtZlYR9boe3yK7A/fqZM8f\nbQ2Kt4ARDa7LzCqkyPDo0RFxfjvVs4CHR5cuHh5dOi3J4dH5klZsnZC0kqQhi12ZmS11igTF4RHx\nr9aJiHgDOLxxJZlZ1RQJihZJC5onkjoAHRtXkplVTZETru4EbpB0EdnZmUeSnYBlZk2iSFCcRDYC\n8m2ykY+7gMsaWZSZVUty1KMsHvVYunjUY+lUdNSj3glXN0TEfpKeYCF3446IzT5GfWa2FKnX9fhu\n/t03qTFrcvXuwv1S/v2F9ivHzKqoXtfjbeo/AKhHQyoys8qp16LoDiDpNOBlYCTZqMdAoHu7VGdm\nlVDkhKtdI+KCiHg7It6KiAuBvRtdmJlVR5GgmCdpoKQOklokDQTmNbowM6uOIkFxILAf8Er+tW8+\nz8yaRJFb4T0P7NH4UsysqorcCm99SfdIejKf3kzSsMaXZmZVUaTrcSnwfWAOQEQ8Dny9kUWZWbUU\nCYquEfFIm3lzG1GMmVVTkaCYkT/0p/UBQPsALzW0KjOrlCKXmR8FXAJsKGkaMJXspCszaxJ1g0JS\nC7BVRHxR0vJAS0S83T6lmVlV1O16RMR8YGj++l2HhFlzKnKM4m5Jx0v6lKSerV8Nr8zMKqPIMYpD\n8+9H1cwL4NNLvhwzq6IiZ2au3R6FmFl1JYMifwbpEGAHspbE/cBFEfF+g2szs4oo0vW4GngbaH2s\n4AFk96bYt1FFmVm1FAmKDSJi85rpeyVNalRBZlY9RUY9HpPUr3VC0jbAg40rycyqpkiLYhvgG5L+\nL5/uCzzVeht/37bfbNlXJCh2a3gVZlZpRYZHfbt+syZX5BiFmTU5B4WZJTkozCzJQWFmSQ4KM0ty\nUJhZkoPCzJIcFGaW5KAwsyQHhZklFbnWwz6GL+09mOW7dqWlpYUOHTpww+XnLVh2xbW/4+wRv+H+\nMaNYacUVSqzSarW0tPDXh29n+rSX2WOvwfzmsv+h/479ePOt7N7S3zzse0yaNLnkKtuXg6IdXH7+\nz/4jCF565TUeGvcYq/VZpaSqbFG+c/RhPP30FHp0775g3knfP4MbbxxTYlXlctejJGeddzHHDvkm\nUtmVWK011liNLw/4Apdffl3ZpVRKw4JC0oaSTpJ0nqRf5a83atT+qkoSR3zvFPY79GhG//E2AO69\n/2FWWbk3G67nG5lXzTlnn8rJ3z+D+fPnf2j+6aedxKMT7ubsXwynY8eOJVVXnoYEhaSTgFGAgEeA\ncfnr6ySdXOd9R0gaL2n8ZVcvG4k+8sKzGX3Fr7nw7NO57sZbGT/xCS65ehRDDxtUdmnWxle+/EVe\nfXUGjz72xIfmnzLsp2yyaX/6bfsVVuq5IieeMKSkCsujiFjyG5WeATaJiDlt5ncEJkfEeqltzJnx\n3JIvrGQjfnMNHVpauPZ3N9O5cycAXnltBiv37sWoS8+ld6+l97lKXVbfsewSPrYzzziZgQfuw9y5\nc+ncuRM9enTnpj/cxuCDv7NgnZ36b8ux3zuSPfYaXGKlS87c2dMKdX4b1fWYD6y+kPmr5cuawnuz\n3ufdd99b8PovjzzKphutz5/HjOKu31/FXb+/ij4r92b05ecv1SGxrDhl2M9Y69Nbse76/Rh40BDu\nvfdBBh/8HVZd9d8HnL/2td2Y/LenS6yyHI0a9TgGuEfSFOCf+by+wLrkzzJtBjNff4Pv/uB0AObN\nnceXv7QzO/TbquSq7KMaedWv6b1yTyQxadJkhhy1yN7zMqshXQ9Y8CT0rYE1yI5PvAiMi4h5Rd6/\nLHY9lmXLQtejGRXtejTsPIr8SegPN2r7ZtZ+fB6FmSU5KMwsyUFhZkkOCjNLclCYWZKDwsySHBRm\nluSgMLMkB4WZJTkozCzJQWFmSQ4KM0tyUJhZkoPCzJIcFGaW5KAwsyQHhZklOSjMLMlBYWZJDgoz\nS3JQmFmSg8LMkhwUZpbkoDCzJAeFmSU5KMwsyUFhZkkOCjNLclCYWZKDwsySHBRmluSgMLMkB4WZ\nJTkozCzJQWFmSQ4KM0tyUJhZkoPCzJIcFGaW5KAwsyQHhZklOSjMLMlBYWZJDgozS3JQmFmSg8LM\nkhwUZpbkoDCzJAeFmSUpIsquoelIOiIiLim7DivG/19uUZTliLILsI+k6f+/HBRmluSgMLMkB0U5\nmrq/uxRq+v8vH8w0syS3KMwsyUFhZkkOinYi6XJJr0p6suxarDhJu0n6u6RnJZ1cdj1lcVC0nyuB\n3couwoqT1AEYAQwANgYOkLRxuVWVw0HRTiLiz8DrZddhH8nWwLMR8VxEzAZGAXuUXFMpHBRmi7YG\n8M+a6RfzeU3HQWG2aFrIvKY8n8BBYbZoLwKfqpn+JDC9pFpK5aAwW7RxwHqS1pbUEfg6cHPJNZXC\nQdFOJF0HPARsIOlFSd8suyarLyLmAkOBO4GngBsiYnK5VZXDp3CbWZJbFGaW5KAwsyQHhZklOSjM\nLMlBYWZJDoomImlFSUMauP2DJf06sc5wScd/xO2+8/Eqs4/LQdFcVgQWGhT5lZJmC+WgaC4/A9aR\nNFHSLyTtLOleSdcCT0haq/Z+GZKOlzQ8f72OpDskTZB0v6QN6+1I0lcl/VXSY5L+V1KfmsWbS/qT\npCmSDq95zwmSxkl6XNKpS/aj28exXNkFWLs6Gdg0Ij4DIGlnskupN42IqZLWqvPeS4AjI2KKpG2A\nC4DP11n/AaBfRISkw4ATgePyZZsB/YDlgcckjQE2BdbL6xFws6T++eX5VjIHhT0SEVPrrSCpG7Ad\nMFpacEFlp8R2PwlcL2k1oCNQu48/RsQsYJake8nCYQfgS8Bj+TrdyILDQVEBDgp7t+b1XD7cHe2c\nf28B/tXaEinofOCciLg5b7kMr1nW9rqBIGtF/DQiLv4I+7B24mMUzeVtoHud5a8Aq0jqJakTsDtA\nRLwFTJW0L4Aymyf2tQIwLX89uM2yPSR1ltQL2JnsKs07gUPz1guS1pC0SvGPZo3kFkUTiYiZkh7M\nD1jeDoxps3yOpNOAv5J1FZ6uWTwQuFDSMOATZLeFm1Rnd8PJuirTgIeBtWuWPZLvuy9wekRMB6ZL\n2gh4KO/evAMcBLy6mB/XliBfPWpmSe56mFmSg8LMkhwUZpbkoDCzJAeFmSU5KMwsyUFhZkn/Dwdd\no8xprvcbAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1f2437c3438>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lucem_illud.plotConfusionMatrix(clf, dfTest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The greater the area under the curve the better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAmQAAAJcCAYAAABXOLh8AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nCZmIiIhIiP0/wZLJSVpdWM8AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1f2437d2e80>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lucem_illud.plotMultiROC(clf, dfTest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also look at the regions the classifer identifies as one class or the other:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAmUAAAJCCAYAAACBJrCpAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1f243bd46d8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lucem_illud.plotregions(clf, dfTrain)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now we do the same for real data\n",
    "\n",
    "Available data sets include:\n",
    "+ Reddit threads \"classified\" by thread topic\n",
    "+ 20 newsgroups \"classified\" by group topic\n",
    "+ Senate press releases \"classified\" by Senator (2 senators)\n",
    "+ Senate press releases \"classified\" by Senator (5 senators)\n",
    "+ Emails classified as Spam or Ham"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Reddit data\n",
      "Converting to vectors\n",
      "Loading data for: comp.sys.mac.hardware\n",
      "Loading data for: comp.windows.x\n",
      "Loading data for: misc.forsale\n",
      "Loading data for: rec.autos\n",
      "Converting to vectors\n",
      "Loading senate data\n",
      "Converting to vectors\n",
      "Loading senator: Kennedy\n",
      "Loading senator: Kerry\n",
      "Loading senator: Klobuchar\n",
      "Loading senator: Kohl\n",
      "Loading senator: Kyl\n",
      "Converting to vectors\n",
      "Loading Spam\n",
      "Loading Ham\n",
      "Converting to vectors\n"
     ]
    }
   ],
   "source": [
    "redditTrain, redditTest = lucem_illud.trainTestSplit(lucem_illud.loadReddit())\n",
    "newsTrain, newsTest = lucem_illud.trainTestSplit(lucem_illud.loadNewsGroups())\n",
    "senSmTrain, senSmTest = lucem_illud.trainTestSplit(lucem_illud.loadSenateSmall())\n",
    "senLgTrain, senLgTest = lucem_illud.trainTestSplit(lucem_illud.loadSenateLarge())\n",
    "spamTrain, spamTest = lucem_illud.trainTestSplit(lucem_illud.loadSpam())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below, I pull each dataset through each classification method. Again, in the interest of time, I'm only going to run them through the evaluateClassifier function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AUC</th>\n",
       "      <th>Average_Precision</th>\n",
       "      <th>Error_Rate</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Category</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Bad Roommates</th>\n",
       "      <td>0.761612</td>\n",
       "      <td>0.466731</td>\n",
       "      <td>0.178683</td>\n",
       "      <td>0.594937</td>\n",
       "      <td>0.652778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Weeaboo Tales</th>\n",
       "      <td>0.852125</td>\n",
       "      <td>0.536841</td>\n",
       "      <td>0.197492</td>\n",
       "      <td>0.553030</td>\n",
       "      <td>0.948052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Relationships</th>\n",
       "      <td>0.633621</td>\n",
       "      <td>0.414556</td>\n",
       "      <td>0.219436</td>\n",
       "      <td>0.729730</td>\n",
       "      <td>0.310345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tales From Tech Support</th>\n",
       "      <td>0.903283</td>\n",
       "      <td>0.831682</td>\n",
       "      <td>0.056426</td>\n",
       "      <td>0.957746</td>\n",
       "      <td>0.819277</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              AUC  Average_Precision  Error_Rate  Precision  \\\n",
       "Category                                                                      \n",
       "Bad Roommates            0.761612           0.466731    0.178683   0.594937   \n",
       "Weeaboo Tales            0.852125           0.536841    0.197492   0.553030   \n",
       "Relationships            0.633621           0.414556    0.219436   0.729730   \n",
       "Tales From Tech Support  0.903283           0.831682    0.056426   0.957746   \n",
       "\n",
       "                           Recall  \n",
       "Category                           \n",
       "Bad Roommates            0.652778  \n",
       "Weeaboo Tales            0.948052  \n",
       "Relationships            0.310345  \n",
       "Tales From Tech Support  0.819277  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AUC</th>\n",
       "      <th>Average_Precision</th>\n",
       "      <th>Error_Rate</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Category</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Bad Roommates</th>\n",
       "      <td>0.969917</td>\n",
       "      <td>0.878777</td>\n",
       "      <td>0.031348</td>\n",
       "      <td>0.897436</td>\n",
       "      <td>0.972222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Weeaboo Tales</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Relationships</th>\n",
       "      <td>0.943247</td>\n",
       "      <td>0.879074</td>\n",
       "      <td>0.040752</td>\n",
       "      <td>0.940476</td>\n",
       "      <td>0.908046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tales From Tech Support</th>\n",
       "      <td>0.973785</td>\n",
       "      <td>0.952449</td>\n",
       "      <td>0.015674</td>\n",
       "      <td>0.987500</td>\n",
       "      <td>0.951807</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              AUC  Average_Precision  Error_Rate  Precision  \\\n",
       "Category                                                                      \n",
       "Bad Roommates            0.969917           0.878777    0.031348   0.897436   \n",
       "Weeaboo Tales            1.000000           1.000000    0.000000   1.000000   \n",
       "Relationships            0.943247           0.879074    0.040752   0.940476   \n",
       "Tales From Tech Support  0.973785           0.952449    0.015674   0.987500   \n",
       "\n",
       "                           Recall  \n",
       "Category                           \n",
       "Bad Roommates            0.972222  \n",
       "Weeaboo Tales            1.000000  \n",
       "Relationships            0.908046  \n",
       "Tales From Tech Support  0.951807  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\computation\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AUC</th>\n",
       "      <th>Average_Precision</th>\n",
       "      <th>Error_Rate</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Category</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Bad Roommates</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.225705</td>\n",
       "      <td>0.774295</td>\n",
       "      <td>0.225705</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Weeaboo Tales</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.241379</td>\n",
       "      <td>0.241379</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Relationships</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tales From Tech Support</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.260188</td>\n",
       "      <td>0.260188</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         AUC  Average_Precision  Error_Rate  Precision  Recall\n",
       "Category                                                                      \n",
       "Bad Roommates            0.5           0.225705    0.774295   0.225705     1.0\n",
       "Weeaboo Tales            0.5           0.241379    0.241379   0.000000     0.0\n",
       "Relationships            0.5           0.272727    0.272727   0.000000     0.0\n",
       "Tales From Tech Support  0.5           0.260188    0.260188   0.000000     0.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AUC</th>\n",
       "      <th>Average_Precision</th>\n",
       "      <th>Error_Rate</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Category</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Bad Roommates</th>\n",
       "      <td>0.917848</td>\n",
       "      <td>0.722297</td>\n",
       "      <td>0.081505</td>\n",
       "      <td>0.767442</td>\n",
       "      <td>0.916667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Weeaboo Tales</th>\n",
       "      <td>0.925030</td>\n",
       "      <td>0.818370</td>\n",
       "      <td>0.053292</td>\n",
       "      <td>0.894737</td>\n",
       "      <td>0.883117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Relationships</th>\n",
       "      <td>0.859195</td>\n",
       "      <td>0.715831</td>\n",
       "      <td>0.100313</td>\n",
       "      <td>0.848101</td>\n",
       "      <td>0.770115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tales From Tech Support</th>\n",
       "      <td>0.937309</td>\n",
       "      <td>0.874058</td>\n",
       "      <td>0.040752</td>\n",
       "      <td>0.948718</td>\n",
       "      <td>0.891566</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              AUC  Average_Precision  Error_Rate  Precision  \\\n",
       "Category                                                                      \n",
       "Bad Roommates            0.917848           0.722297    0.081505   0.767442   \n",
       "Weeaboo Tales            0.925030           0.818370    0.053292   0.894737   \n",
       "Relationships            0.859195           0.715831    0.100313   0.848101   \n",
       "Tales From Tech Support  0.937309           0.874058    0.040752   0.948718   \n",
       "\n",
       "                           Recall  \n",
       "Category                           \n",
       "Bad Roommates            0.916667  \n",
       "Weeaboo Tales            0.883117  \n",
       "Relationships            0.770115  \n",
       "Tales From Tech Support  0.891566  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AUC</th>\n",
       "      <th>Average_Precision</th>\n",
       "      <th>Error_Rate</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Category</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Bad Roommates</th>\n",
       "      <td>0.960948</td>\n",
       "      <td>0.857161</td>\n",
       "      <td>0.037618</td>\n",
       "      <td>0.884615</td>\n",
       "      <td>0.958333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Weeaboo Tales</th>\n",
       "      <td>0.978453</td>\n",
       "      <td>0.957629</td>\n",
       "      <td>0.012539</td>\n",
       "      <td>0.986667</td>\n",
       "      <td>0.961039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Relationships</th>\n",
       "      <td>0.941092</td>\n",
       "      <td>0.869027</td>\n",
       "      <td>0.043887</td>\n",
       "      <td>0.929412</td>\n",
       "      <td>0.908046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tales From Tech Support</th>\n",
       "      <td>0.979809</td>\n",
       "      <td>0.961360</td>\n",
       "      <td>0.012539</td>\n",
       "      <td>0.987654</td>\n",
       "      <td>0.963855</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              AUC  Average_Precision  Error_Rate  Precision  \\\n",
       "Category                                                                      \n",
       "Bad Roommates            0.960948           0.857161    0.037618   0.884615   \n",
       "Weeaboo Tales            0.978453           0.957629    0.012539   0.986667   \n",
       "Relationships            0.941092           0.869027    0.043887   0.929412   \n",
       "Tales From Tech Support  0.979809           0.961360    0.012539   0.987654   \n",
       "\n",
       "                           Recall  \n",
       "Category                           \n",
       "Bad Roommates            0.958333  \n",
       "Weeaboo Tales            0.961039  \n",
       "Relationships            0.908046  \n",
       "Tales From Tech Support  0.963855  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AUC</th>\n",
       "      <th>Average_Precision</th>\n",
       "      <th>Error_Rate</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Category</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Bad Roommates</th>\n",
       "      <td>0.887455</td>\n",
       "      <td>0.731427</td>\n",
       "      <td>0.075235</td>\n",
       "      <td>0.842857</td>\n",
       "      <td>0.819444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Weeaboo Tales</th>\n",
       "      <td>0.902007</td>\n",
       "      <td>0.733742</td>\n",
       "      <td>0.081505</td>\n",
       "      <td>0.807229</td>\n",
       "      <td>0.870130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Relationships</th>\n",
       "      <td>0.835489</td>\n",
       "      <td>0.668056</td>\n",
       "      <td>0.119122</td>\n",
       "      <td>0.810127</td>\n",
       "      <td>0.735632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tales From Tech Support</th>\n",
       "      <td>0.934526</td>\n",
       "      <td>0.821833</td>\n",
       "      <td>0.056426</td>\n",
       "      <td>0.873563</td>\n",
       "      <td>0.915663</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              AUC  Average_Precision  Error_Rate  Precision  \\\n",
       "Category                                                                      \n",
       "Bad Roommates            0.887455           0.731427    0.075235   0.842857   \n",
       "Weeaboo Tales            0.902007           0.733742    0.081505   0.807229   \n",
       "Relationships            0.835489           0.668056    0.119122   0.810127   \n",
       "Tales From Tech Support  0.934526           0.821833    0.056426   0.873563   \n",
       "\n",
       "                           Recall  \n",
       "Category                           \n",
       "Bad Roommates            0.819444  \n",
       "Weeaboo Tales            0.870130  \n",
       "Relationships            0.735632  \n",
       "Tales From Tech Support  0.915663  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AUC</th>\n",
       "      <th>Average_Precision</th>\n",
       "      <th>Error_Rate</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Category</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Bad Roommates</th>\n",
       "      <td>0.903087</td>\n",
       "      <td>0.717276</td>\n",
       "      <td>0.081505</td>\n",
       "      <td>0.787500</td>\n",
       "      <td>0.875000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Weeaboo Tales</th>\n",
       "      <td>0.950708</td>\n",
       "      <td>0.880224</td>\n",
       "      <td>0.034483</td>\n",
       "      <td>0.934211</td>\n",
       "      <td>0.922078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Relationships</th>\n",
       "      <td>0.859195</td>\n",
       "      <td>0.715831</td>\n",
       "      <td>0.100313</td>\n",
       "      <td>0.848101</td>\n",
       "      <td>0.770115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tales From Tech Support</th>\n",
       "      <td>0.949025</td>\n",
       "      <td>0.869210</td>\n",
       "      <td>0.040752</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>0.927711</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              AUC  Average_Precision  Error_Rate  Precision  \\\n",
       "Category                                                                      \n",
       "Bad Roommates            0.903087           0.717276    0.081505   0.787500   \n",
       "Weeaboo Tales            0.950708           0.880224    0.034483   0.934211   \n",
       "Relationships            0.859195           0.715831    0.100313   0.848101   \n",
       "Tales From Tech Support  0.949025           0.869210    0.040752   0.916667   \n",
       "\n",
       "                           Recall  \n",
       "Category                           \n",
       "Bad Roommates            0.875000  \n",
       "Weeaboo Tales            0.922078  \n",
       "Relationships            0.770115  \n",
       "Tales From Tech Support  0.927711  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AUC</th>\n",
       "      <th>Average_Precision</th>\n",
       "      <th>Error_Rate</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Category</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Bad Roommates</th>\n",
       "      <td>0.962972</td>\n",
       "      <td>0.868171</td>\n",
       "      <td>0.034483</td>\n",
       "      <td>0.896104</td>\n",
       "      <td>0.958333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Weeaboo Tales</th>\n",
       "      <td>0.991440</td>\n",
       "      <td>0.977329</td>\n",
       "      <td>0.006270</td>\n",
       "      <td>0.987013</td>\n",
       "      <td>0.987013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Relationships</th>\n",
       "      <td>0.953305</td>\n",
       "      <td>0.908247</td>\n",
       "      <td>0.031348</td>\n",
       "      <td>0.963855</td>\n",
       "      <td>0.919540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tales From Tech Support</th>\n",
       "      <td>0.985833</td>\n",
       "      <td>0.970272</td>\n",
       "      <td>0.009404</td>\n",
       "      <td>0.987805</td>\n",
       "      <td>0.975904</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              AUC  Average_Precision  Error_Rate  Precision  \\\n",
       "Category                                                                      \n",
       "Bad Roommates            0.962972           0.868171    0.034483   0.896104   \n",
       "Weeaboo Tales            0.991440           0.977329    0.006270   0.987013   \n",
       "Relationships            0.953305           0.908247    0.031348   0.963855   \n",
       "Tales From Tech Support  0.985833           0.970272    0.009404   0.987805   \n",
       "\n",
       "                           Recall  \n",
       "Category                           \n",
       "Bad Roommates            0.958333  \n",
       "Weeaboo Tales            0.987013  \n",
       "Relationships            0.919540  \n",
       "Tales From Tech Support  0.975904  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AUC</th>\n",
       "      <th>Average_Precision</th>\n",
       "      <th>Error_Rate</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Category</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Bad Roommates</th>\n",
       "      <td>0.948212</td>\n",
       "      <td>0.870921</td>\n",
       "      <td>0.034483</td>\n",
       "      <td>0.929577</td>\n",
       "      <td>0.916667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Weeaboo Tales</th>\n",
       "      <td>0.972255</td>\n",
       "      <td>0.921159</td>\n",
       "      <td>0.021944</td>\n",
       "      <td>0.948718</td>\n",
       "      <td>0.961039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Relationships</th>\n",
       "      <td>0.946839</td>\n",
       "      <td>0.877330</td>\n",
       "      <td>0.040752</td>\n",
       "      <td>0.930233</td>\n",
       "      <td>0.919540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tales From Tech Support</th>\n",
       "      <td>0.981596</td>\n",
       "      <td>0.947320</td>\n",
       "      <td>0.015674</td>\n",
       "      <td>0.964286</td>\n",
       "      <td>0.975904</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              AUC  Average_Precision  Error_Rate  Precision  \\\n",
       "Category                                                                      \n",
       "Bad Roommates            0.948212           0.870921    0.034483   0.929577   \n",
       "Weeaboo Tales            0.972255           0.921159    0.021944   0.948718   \n",
       "Relationships            0.946839           0.877330    0.040752   0.930233   \n",
       "Tales From Tech Support  0.981596           0.947320    0.015674   0.964286   \n",
       "\n",
       "                           Recall  \n",
       "Category                           \n",
       "Bad Roommates            0.916667  \n",
       "Weeaboo Tales            0.961039  \n",
       "Relationships            0.919540  \n",
       "Tales From Tech Support  0.975904  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# reddit\n",
    "\n",
    "clfBayes.fit(np.stack(redditTrain['vect'], axis=0), redditTrain['category'])\n",
    "clfLinear.fit(np.stack(redditTrain['vect'], axis=0), redditTrain['category'])\n",
    "clfKernel.fit(np.stack(redditTrain['vect'], axis=0), redditTrain['category'])\n",
    "clfKNeighbors.fit(np.stack(redditTrain['vect'], axis=0), redditTrain['category'])\n",
    "clfReg.fit(np.stack(redditTrain['vect'], axis=0), redditTrain['category'])\n",
    "clfTree.fit(np.stack(redditTrain['vect'], axis=0), redditTrain['category'])\n",
    "clfForest.fit(np.stack(redditTrain['vect'], axis=0), redditTrain['category'])\n",
    "clfNN.fit(np.stack(redditTrain['vect'], axis=0), redditTrain['category'])\n",
    "clfEnsem.fit(np.stack(redditTrain['vect'], axis=0), redditTrain['category'])\n",
    "\n",
    "display(lucem_illud.evaluateClassifier(clfBayes, redditTest))\n",
    "display(lucem_illud.evaluateClassifier(clfLinear, redditTest))\n",
    "display(lucem_illud.evaluateClassifier(clfKernel, redditTest))\n",
    "display(lucem_illud.evaluateClassifier(clfKNeighbors, redditTest))\n",
    "display(lucem_illud.evaluateClassifier(clfReg, redditTest))\n",
    "display(lucem_illud.evaluateClassifier(clfTree, redditTest))\n",
    "display(lucem_illud.evaluateClassifier(clfForest, redditTest))\n",
    "display(lucem_illud.evaluateClassifier(clfNN, redditTest))\n",
    "display(lucem_illud.evaluateClassifier(clfEnsem, redditTest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AUC</th>\n",
       "      <th>Average_Precision</th>\n",
       "      <th>Error_Rate</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Category</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>comp.windows.x</th>\n",
       "      <td>0.906100</td>\n",
       "      <td>0.811300</td>\n",
       "      <td>0.063830</td>\n",
       "      <td>0.913793</td>\n",
       "      <td>0.841270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>comp.sys.mac.hardware</th>\n",
       "      <td>0.829447</td>\n",
       "      <td>0.575341</td>\n",
       "      <td>0.153191</td>\n",
       "      <td>0.659574</td>\n",
       "      <td>0.794872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>misc.forsale</th>\n",
       "      <td>0.778400</td>\n",
       "      <td>0.514718</td>\n",
       "      <td>0.146809</td>\n",
       "      <td>0.676768</td>\n",
       "      <td>0.644231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rec.autos</th>\n",
       "      <td>0.853295</td>\n",
       "      <td>0.691855</td>\n",
       "      <td>0.104255</td>\n",
       "      <td>0.824561</td>\n",
       "      <td>0.764228</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            AUC  Average_Precision  Error_Rate  Precision  \\\n",
       "Category                                                                    \n",
       "comp.windows.x         0.906100           0.811300    0.063830   0.913793   \n",
       "comp.sys.mac.hardware  0.829447           0.575341    0.153191   0.659574   \n",
       "misc.forsale           0.778400           0.514718    0.146809   0.676768   \n",
       "rec.autos              0.853295           0.691855    0.104255   0.824561   \n",
       "\n",
       "                         Recall  \n",
       "Category                         \n",
       "comp.windows.x         0.841270  \n",
       "comp.sys.mac.hardware  0.794872  \n",
       "misc.forsale           0.644231  \n",
       "rec.autos              0.764228  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AUC</th>\n",
       "      <th>Average_Precision</th>\n",
       "      <th>Error_Rate</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Category</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>comp.windows.x</th>\n",
       "      <td>0.928848</td>\n",
       "      <td>0.853644</td>\n",
       "      <td>0.048936</td>\n",
       "      <td>0.932773</td>\n",
       "      <td>0.880952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>comp.sys.mac.hardware</th>\n",
       "      <td>0.894700</td>\n",
       "      <td>0.767047</td>\n",
       "      <td>0.072340</td>\n",
       "      <td>0.873874</td>\n",
       "      <td>0.829060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>misc.forsale</th>\n",
       "      <td>0.908759</td>\n",
       "      <td>0.771366</td>\n",
       "      <td>0.061702</td>\n",
       "      <td>0.864078</td>\n",
       "      <td>0.855769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rec.autos</th>\n",
       "      <td>0.930273</td>\n",
       "      <td>0.790379</td>\n",
       "      <td>0.068085</td>\n",
       "      <td>0.832117</td>\n",
       "      <td>0.926829</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            AUC  Average_Precision  Error_Rate  Precision  \\\n",
       "Category                                                                    \n",
       "comp.windows.x         0.928848           0.853644    0.048936   0.932773   \n",
       "comp.sys.mac.hardware  0.894700           0.767047    0.072340   0.873874   \n",
       "misc.forsale           0.908759           0.771366    0.061702   0.864078   \n",
       "rec.autos              0.930273           0.790379    0.068085   0.832117   \n",
       "\n",
       "                         Recall  \n",
       "Category                         \n",
       "comp.windows.x         0.880952  \n",
       "comp.sys.mac.hardware  0.829060  \n",
       "misc.forsale           0.855769  \n",
       "rec.autos              0.926829  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\computation\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AUC</th>\n",
       "      <th>Average_Precision</th>\n",
       "      <th>Error_Rate</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Category</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>comp.windows.x</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.268085</td>\n",
       "      <td>0.268085</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>comp.sys.mac.hardware</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.248936</td>\n",
       "      <td>0.248936</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>misc.forsale</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.221277</td>\n",
       "      <td>0.778723</td>\n",
       "      <td>0.221277</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rec.autos</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.261702</td>\n",
       "      <td>0.261702</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       AUC  Average_Precision  Error_Rate  Precision  Recall\n",
       "Category                                                                    \n",
       "comp.windows.x         0.5           0.268085    0.268085   0.000000     0.0\n",
       "comp.sys.mac.hardware  0.5           0.248936    0.248936   0.000000     0.0\n",
       "misc.forsale           0.5           0.221277    0.778723   0.221277     1.0\n",
       "rec.autos              0.5           0.261702    0.261702   0.000000     0.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AUC</th>\n",
       "      <th>Average_Precision</th>\n",
       "      <th>Error_Rate</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Category</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>comp.windows.x</th>\n",
       "      <td>0.563492</td>\n",
       "      <td>0.361027</td>\n",
       "      <td>0.234043</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.126984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>comp.sys.mac.hardware</th>\n",
       "      <td>0.511053</td>\n",
       "      <td>0.253247</td>\n",
       "      <td>0.434043</td>\n",
       "      <td>0.259669</td>\n",
       "      <td>0.401709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>misc.forsale</th>\n",
       "      <td>0.535992</td>\n",
       "      <td>0.239622</td>\n",
       "      <td>0.261702</td>\n",
       "      <td>0.327273</td>\n",
       "      <td>0.173077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rec.autos</th>\n",
       "      <td>0.505225</td>\n",
       "      <td>0.263755</td>\n",
       "      <td>0.478723</td>\n",
       "      <td>0.266055</td>\n",
       "      <td>0.471545</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            AUC  Average_Precision  Error_Rate  Precision  \\\n",
       "Category                                                                    \n",
       "comp.windows.x         0.563492           0.361027    0.234043   1.000000   \n",
       "comp.sys.mac.hardware  0.511053           0.253247    0.434043   0.259669   \n",
       "misc.forsale           0.535992           0.239622    0.261702   0.327273   \n",
       "rec.autos              0.505225           0.263755    0.478723   0.266055   \n",
       "\n",
       "                         Recall  \n",
       "Category                         \n",
       "comp.windows.x         0.126984  \n",
       "comp.sys.mac.hardware  0.401709  \n",
       "misc.forsale           0.173077  \n",
       "rec.autos              0.471545  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AUC</th>\n",
       "      <th>Average_Precision</th>\n",
       "      <th>Error_Rate</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Category</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>comp.windows.x</th>\n",
       "      <td>0.939300</td>\n",
       "      <td>0.864092</td>\n",
       "      <td>0.044681</td>\n",
       "      <td>0.926829</td>\n",
       "      <td>0.904762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>comp.sys.mac.hardware</th>\n",
       "      <td>0.904639</td>\n",
       "      <td>0.800476</td>\n",
       "      <td>0.061702</td>\n",
       "      <td>0.907407</td>\n",
       "      <td>0.837607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>misc.forsale</th>\n",
       "      <td>0.905317</td>\n",
       "      <td>0.771286</td>\n",
       "      <td>0.061702</td>\n",
       "      <td>0.871287</td>\n",
       "      <td>0.846154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rec.autos</th>\n",
       "      <td>0.939844</td>\n",
       "      <td>0.807635</td>\n",
       "      <td>0.061702</td>\n",
       "      <td>0.840580</td>\n",
       "      <td>0.943089</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            AUC  Average_Precision  Error_Rate  Precision  \\\n",
       "Category                                                                    \n",
       "comp.windows.x         0.939300           0.864092    0.044681   0.926829   \n",
       "comp.sys.mac.hardware  0.904639           0.800476    0.061702   0.907407   \n",
       "misc.forsale           0.905317           0.771286    0.061702   0.871287   \n",
       "rec.autos              0.939844           0.807635    0.061702   0.840580   \n",
       "\n",
       "                         Recall  \n",
       "Category                         \n",
       "comp.windows.x         0.904762  \n",
       "comp.sys.mac.hardware  0.837607  \n",
       "misc.forsale           0.846154  \n",
       "rec.autos              0.943089  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AUC</th>\n",
       "      <th>Average_Precision</th>\n",
       "      <th>Error_Rate</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Category</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>comp.windows.x</th>\n",
       "      <td>0.849368</td>\n",
       "      <td>0.694264</td>\n",
       "      <td>0.106383</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.753968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>comp.sys.mac.hardware</th>\n",
       "      <td>0.779509</td>\n",
       "      <td>0.531255</td>\n",
       "      <td>0.163830</td>\n",
       "      <td>0.672414</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>misc.forsale</th>\n",
       "      <td>0.803752</td>\n",
       "      <td>0.573568</td>\n",
       "      <td>0.123404</td>\n",
       "      <td>0.744681</td>\n",
       "      <td>0.673077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rec.autos</th>\n",
       "      <td>0.823704</td>\n",
       "      <td>0.579264</td>\n",
       "      <td>0.159574</td>\n",
       "      <td>0.664384</td>\n",
       "      <td>0.788618</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            AUC  Average_Precision  Error_Rate  Precision  \\\n",
       "Category                                                                    \n",
       "comp.windows.x         0.849368           0.694264    0.106383   0.833333   \n",
       "comp.sys.mac.hardware  0.779509           0.531255    0.163830   0.672414   \n",
       "misc.forsale           0.803752           0.573568    0.123404   0.744681   \n",
       "rec.autos              0.823704           0.579264    0.159574   0.664384   \n",
       "\n",
       "                         Recall  \n",
       "Category                         \n",
       "comp.windows.x         0.753968  \n",
       "comp.sys.mac.hardware  0.666667  \n",
       "misc.forsale           0.673077  \n",
       "rec.autos              0.788618  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AUC</th>\n",
       "      <th>Average_Precision</th>\n",
       "      <th>Error_Rate</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Category</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>comp.windows.x</th>\n",
       "      <td>0.905316</td>\n",
       "      <td>0.784842</td>\n",
       "      <td>0.072340</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.857143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>comp.sys.mac.hardware</th>\n",
       "      <td>0.823588</td>\n",
       "      <td>0.614564</td>\n",
       "      <td>0.127660</td>\n",
       "      <td>0.752212</td>\n",
       "      <td>0.726496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>misc.forsale</th>\n",
       "      <td>0.882645</td>\n",
       "      <td>0.741948</td>\n",
       "      <td>0.070213</td>\n",
       "      <td>0.873684</td>\n",
       "      <td>0.798077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rec.autos</th>\n",
       "      <td>0.846243</td>\n",
       "      <td>0.628476</td>\n",
       "      <td>0.134043</td>\n",
       "      <td>0.717391</td>\n",
       "      <td>0.804878</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            AUC  Average_Precision  Error_Rate  Precision  \\\n",
       "Category                                                                    \n",
       "comp.windows.x         0.905316           0.784842    0.072340   0.870968   \n",
       "comp.sys.mac.hardware  0.823588           0.614564    0.127660   0.752212   \n",
       "misc.forsale           0.882645           0.741948    0.070213   0.873684   \n",
       "rec.autos              0.846243           0.628476    0.134043   0.717391   \n",
       "\n",
       "                         Recall  \n",
       "Category                         \n",
       "comp.windows.x         0.857143  \n",
       "comp.sys.mac.hardware  0.726496  \n",
       "misc.forsale           0.798077  \n",
       "rec.autos              0.804878  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AUC</th>\n",
       "      <th>Average_Precision</th>\n",
       "      <th>Error_Rate</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Category</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>comp.windows.x</th>\n",
       "      <td>0.946175</td>\n",
       "      <td>0.883735</td>\n",
       "      <td>0.038298</td>\n",
       "      <td>0.942623</td>\n",
       "      <td>0.912698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>comp.sys.mac.hardware</th>\n",
       "      <td>0.891867</td>\n",
       "      <td>0.754224</td>\n",
       "      <td>0.076596</td>\n",
       "      <td>0.858407</td>\n",
       "      <td>0.829060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>misc.forsale</th>\n",
       "      <td>0.899144</td>\n",
       "      <td>0.756753</td>\n",
       "      <td>0.065957</td>\n",
       "      <td>0.861386</td>\n",
       "      <td>0.836538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rec.autos</th>\n",
       "      <td>0.929090</td>\n",
       "      <td>0.796001</td>\n",
       "      <td>0.065957</td>\n",
       "      <td>0.843284</td>\n",
       "      <td>0.918699</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            AUC  Average_Precision  Error_Rate  Precision  \\\n",
       "Category                                                                    \n",
       "comp.windows.x         0.946175           0.883735    0.038298   0.942623   \n",
       "comp.sys.mac.hardware  0.891867           0.754224    0.076596   0.858407   \n",
       "misc.forsale           0.899144           0.756753    0.065957   0.861386   \n",
       "rec.autos              0.929090           0.796001    0.065957   0.843284   \n",
       "\n",
       "                         Recall  \n",
       "Category                         \n",
       "comp.windows.x         0.912698  \n",
       "comp.sys.mac.hardware  0.829060  \n",
       "misc.forsale           0.836538  \n",
       "rec.autos              0.918699  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AUC</th>\n",
       "      <th>Average_Precision</th>\n",
       "      <th>Error_Rate</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Category</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>comp.windows.x</th>\n",
       "      <td>0.898440</td>\n",
       "      <td>0.767346</td>\n",
       "      <td>0.078723</td>\n",
       "      <td>0.856000</td>\n",
       "      <td>0.849206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>comp.sys.mac.hardware</th>\n",
       "      <td>0.843515</td>\n",
       "      <td>0.648278</td>\n",
       "      <td>0.114894</td>\n",
       "      <td>0.773913</td>\n",
       "      <td>0.760684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>misc.forsale</th>\n",
       "      <td>0.873082</td>\n",
       "      <td>0.694096</td>\n",
       "      <td>0.085106</td>\n",
       "      <td>0.813725</td>\n",
       "      <td>0.798077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rec.autos</th>\n",
       "      <td>0.882676</td>\n",
       "      <td>0.716397</td>\n",
       "      <td>0.095745</td>\n",
       "      <td>0.804688</td>\n",
       "      <td>0.837398</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            AUC  Average_Precision  Error_Rate  Precision  \\\n",
       "Category                                                                    \n",
       "comp.windows.x         0.898440           0.767346    0.078723   0.856000   \n",
       "comp.sys.mac.hardware  0.843515           0.648278    0.114894   0.773913   \n",
       "misc.forsale           0.873082           0.694096    0.085106   0.813725   \n",
       "rec.autos              0.882676           0.716397    0.095745   0.804688   \n",
       "\n",
       "                         Recall  \n",
       "Category                         \n",
       "comp.windows.x         0.849206  \n",
       "comp.sys.mac.hardware  0.760684  \n",
       "misc.forsale           0.798077  \n",
       "rec.autos              0.837398  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# news \n",
    "\n",
    "clfBayes.fit(np.stack(newsTrain['vect'], axis=0), newsTrain['category'])\n",
    "clfLinear.fit(np.stack(newsTrain['vect'], axis=0), newsTrain['category'])\n",
    "clfKernel.fit(np.stack(newsTrain['vect'], axis=0), newsTrain['category'])\n",
    "clfKNeighbors.fit(np.stack(newsTrain['vect'], axis=0), newsTrain['category'])\n",
    "clfReg.fit(np.stack(newsTrain['vect'], axis=0), newsTrain['category'])\n",
    "clfTree.fit(np.stack(newsTrain['vect'], axis=0), newsTrain['category'])\n",
    "clfForest.fit(np.stack(newsTrain['vect'], axis=0), newsTrain['category'])\n",
    "clfNN.fit(np.stack(newsTrain['vect'], axis=0), newsTrain['category'])\n",
    "clfEnsem.fit(np.stack(newsTrain['vect'], axis=0), newsTrain['category'])\n",
    "\n",
    "display(lucem_illud.evaluateClassifier(clfBayes, newsTest))\n",
    "display(lucem_illud.evaluateClassifier(clfLinear, newsTest))\n",
    "display(lucem_illud.evaluateClassifier(clfKernel, newsTest))\n",
    "display(lucem_illud.evaluateClassifier(clfKNeighbors, newsTest))\n",
    "display(lucem_illud.evaluateClassifier(clfReg, newsTest))\n",
    "display(lucem_illud.evaluateClassifier(clfTree, newsTest))\n",
    "display(lucem_illud.evaluateClassifier(clfForest, newsTest))\n",
    "display(lucem_illud.evaluateClassifier(clfNN, newsTest))\n",
    "display(lucem_illud.evaluateClassifier(clfEnsem, newsTest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AUC</th>\n",
       "      <th>Average_Precision</th>\n",
       "      <th>Error_Rate</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Category</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Obama</th>\n",
       "      <td>0.821816</td>\n",
       "      <td>0.715715</td>\n",
       "      <td>0.175953</td>\n",
       "      <td>0.785235</td>\n",
       "      <td>0.806897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Clinton</th>\n",
       "      <td>0.821816</td>\n",
       "      <td>0.808553</td>\n",
       "      <td>0.175953</td>\n",
       "      <td>0.854167</td>\n",
       "      <td>0.836735</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               AUC  Average_Precision  Error_Rate  Precision    Recall\n",
       "Category                                                              \n",
       "Obama     0.821816           0.715715    0.175953   0.785235  0.806897\n",
       "Clinton   0.821816           0.808553    0.175953   0.854167  0.836735"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AUC</th>\n",
       "      <th>Average_Precision</th>\n",
       "      <th>Error_Rate</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Category</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Obama</th>\n",
       "      <td>0.983656</td>\n",
       "      <td>0.977296</td>\n",
       "      <td>0.014663</td>\n",
       "      <td>0.992958</td>\n",
       "      <td>0.972414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Clinton</th>\n",
       "      <td>0.983656</td>\n",
       "      <td>0.977833</td>\n",
       "      <td>0.014663</td>\n",
       "      <td>0.979899</td>\n",
       "      <td>0.994898</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               AUC  Average_Precision  Error_Rate  Precision    Recall\n",
       "Category                                                              \n",
       "Obama     0.983656           0.977296    0.014663   0.992958  0.972414\n",
       "Clinton   0.983656           0.977833    0.014663   0.979899  0.994898"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\computation\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AUC</th>\n",
       "      <th>Average_Precision</th>\n",
       "      <th>Error_Rate</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Category</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Obama</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.42522</td>\n",
       "      <td>0.42522</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Clinton</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.57478</td>\n",
       "      <td>0.42522</td>\n",
       "      <td>0.57478</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          AUC  Average_Precision  Error_Rate  Precision  Recall\n",
       "Category                                                       \n",
       "Obama     0.5            0.42522     0.42522    0.00000     0.0\n",
       "Clinton   0.5            0.57478     0.42522    0.57478     1.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AUC</th>\n",
       "      <th>Average_Precision</th>\n",
       "      <th>Error_Rate</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Category</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Obama</th>\n",
       "      <td>0.870567</td>\n",
       "      <td>0.789085</td>\n",
       "      <td>0.1261</td>\n",
       "      <td>0.854167</td>\n",
       "      <td>0.848276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Clinton</th>\n",
       "      <td>0.870567</td>\n",
       "      <td>0.854731</td>\n",
       "      <td>0.1261</td>\n",
       "      <td>0.888325</td>\n",
       "      <td>0.892857</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               AUC  Average_Precision  Error_Rate  Precision    Recall\n",
       "Category                                                              \n",
       "Obama     0.870567           0.789085      0.1261   0.854167  0.848276\n",
       "Clinton   0.870567           0.854731      0.1261   0.888325  0.892857"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AUC</th>\n",
       "      <th>Average_Precision</th>\n",
       "      <th>Error_Rate</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Category</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Obama</th>\n",
       "      <td>0.975862</td>\n",
       "      <td>0.972252</td>\n",
       "      <td>0.020528</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.951724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Clinton</th>\n",
       "      <td>0.975862</td>\n",
       "      <td>0.965517</td>\n",
       "      <td>0.020528</td>\n",
       "      <td>0.965517</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               AUC  Average_Precision  Error_Rate  Precision    Recall\n",
       "Category                                                              \n",
       "Obama     0.975862           0.972252    0.020528   1.000000  0.951724\n",
       "Clinton   0.975862           0.965517    0.020528   0.965517  1.000000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AUC</th>\n",
       "      <th>Average_Precision</th>\n",
       "      <th>Error_Rate</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Category</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Obama</th>\n",
       "      <td>0.981105</td>\n",
       "      <td>0.970544</td>\n",
       "      <td>0.017595</td>\n",
       "      <td>0.986014</td>\n",
       "      <td>0.972414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Clinton</th>\n",
       "      <td>0.981105</td>\n",
       "      <td>0.975665</td>\n",
       "      <td>0.017595</td>\n",
       "      <td>0.979798</td>\n",
       "      <td>0.989796</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               AUC  Average_Precision  Error_Rate  Precision    Recall\n",
       "Category                                                              \n",
       "Obama     0.981105           0.970544    0.017595   0.986014  0.972414\n",
       "Clinton   0.981105           0.975665    0.017595   0.979798  0.989796"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AUC</th>\n",
       "      <th>Average_Precision</th>\n",
       "      <th>Error_Rate</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Category</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Obama</th>\n",
       "      <td>0.986207</td>\n",
       "      <td>0.984144</td>\n",
       "      <td>0.01173</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.972414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Clinton</th>\n",
       "      <td>0.986207</td>\n",
       "      <td>0.980000</td>\n",
       "      <td>0.01173</td>\n",
       "      <td>0.98</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               AUC  Average_Precision  Error_Rate  Precision    Recall\n",
       "Category                                                              \n",
       "Obama     0.986207           0.984144     0.01173       1.00  0.972414\n",
       "Clinton   0.986207           0.980000     0.01173       0.98  1.000000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AUC</th>\n",
       "      <th>Average_Precision</th>\n",
       "      <th>Error_Rate</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Category</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Obama</th>\n",
       "      <td>0.961312</td>\n",
       "      <td>0.944081</td>\n",
       "      <td>0.035191</td>\n",
       "      <td>0.978417</td>\n",
       "      <td>0.937931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Clinton</th>\n",
       "      <td>0.961312</td>\n",
       "      <td>0.949619</td>\n",
       "      <td>0.035191</td>\n",
       "      <td>0.955446</td>\n",
       "      <td>0.984694</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               AUC  Average_Precision  Error_Rate  Precision    Recall\n",
       "Category                                                              \n",
       "Obama     0.961312           0.944081    0.035191   0.978417  0.937931\n",
       "Clinton   0.961312           0.949619    0.035191   0.955446  0.984694"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AUC</th>\n",
       "      <th>Average_Precision</th>\n",
       "      <th>Error_Rate</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Category</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Obama</th>\n",
       "      <td>0.994898</td>\n",
       "      <td>0.986395</td>\n",
       "      <td>0.005865</td>\n",
       "      <td>0.986395</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Clinton</th>\n",
       "      <td>0.994898</td>\n",
       "      <td>0.995661</td>\n",
       "      <td>0.005865</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.989796</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               AUC  Average_Precision  Error_Rate  Precision    Recall\n",
       "Category                                                              \n",
       "Obama     0.994898           0.986395    0.005865   0.986395  1.000000\n",
       "Clinton   0.994898           0.995661    0.005865   1.000000  0.989796"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Senate Small \n",
    "\n",
    "clfBayes.fit(np.stack(senSmTrain['vect'], axis=0), senSmTrain['category'])\n",
    "clfLinear.fit(np.stack(senSmTrain['vect'], axis=0), senSmTrain['category'])\n",
    "clfKernel.fit(np.stack(senSmTrain['vect'], axis=0), senSmTrain['category'])\n",
    "clfKNeighbors.fit(np.stack(senSmTrain['vect'], axis=0), senSmTrain['category'])\n",
    "clfReg.fit(np.stack(senSmTrain['vect'], axis=0), senSmTrain['category'])\n",
    "clfTree.fit(np.stack(senSmTrain['vect'], axis=0), senSmTrain['category'])\n",
    "clfForest.fit(np.stack(senSmTrain['vect'], axis=0), senSmTrain['category'])\n",
    "clfNN.fit(np.stack(senSmTrain['vect'], axis=0), senSmTrain['category'])\n",
    "clfEnsem.fit(np.stack(senSmTrain['vect'], axis=0), senSmTrain['category'])\n",
    "\n",
    "display(lucem_illud.evaluateClassifier(clfBayes, senSmTest))\n",
    "display(lucem_illud.evaluateClassifier(clfLinear, senSmTest))\n",
    "display(lucem_illud.evaluateClassifier(clfKernel, senSmTest))\n",
    "display(lucem_illud.evaluateClassifier(clfKNeighbors, senSmTest))\n",
    "display(lucem_illud.evaluateClassifier(clfReg, senSmTest))\n",
    "display(lucem_illud.evaluateClassifier(clfTree, senSmTest))\n",
    "display(lucem_illud.evaluateClassifier(clfForest, senSmTest))\n",
    "display(lucem_illud.evaluateClassifier(clfNN, senSmTest))\n",
    "display(lucem_illud.evaluateClassifier(clfEnsem, senSmTest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-54-ee5b5faeff71>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[0mclfForest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msenLgTrain\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'vect'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msenLgTrain\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'category'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[0mclfNN\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msenLgTrain\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'vect'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msenLgTrain\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'category'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m \u001b[0mclfEnsem\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msenLgTrain\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'vect'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msenLgTrain\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'category'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[0mdisplay\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlucem_illud\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluateClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclfBayes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msenLgTest\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\computation\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\gradient_boosting.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, monitor)\u001b[0m\n\u001b[0;32m   1032\u001b[0m         \u001b[1;31m# fit the boosting stages\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1033\u001b[0m         n_stages = self._fit_stages(X, y, y_pred, sample_weight, random_state,\n\u001b[1;32m-> 1034\u001b[1;33m                                     begin_at_stage, monitor, X_idx_sorted)\n\u001b[0m\u001b[0;32m   1035\u001b[0m         \u001b[1;31m# change shape of arrays after fit (early-stopping or additional ests)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1036\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mn_stages\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mestimators_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\computation\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\gradient_boosting.py\u001b[0m in \u001b[0;36m_fit_stages\u001b[1;34m(self, X, y, y_pred, sample_weight, random_state, begin_at_stage, monitor, X_idx_sorted)\u001b[0m\n\u001b[0;32m   1087\u001b[0m             y_pred = self._fit_stage(i, X, y, y_pred, sample_weight,\n\u001b[0;32m   1088\u001b[0m                                      \u001b[0msample_mask\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_idx_sorted\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1089\u001b[1;33m                                      X_csc, X_csr)\n\u001b[0m\u001b[0;32m   1090\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1091\u001b[0m             \u001b[1;31m# track deviance (= loss)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\computation\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\gradient_boosting.py\u001b[0m in \u001b[0;36m_fit_stage\u001b[1;34m(self, i, X, y, y_pred, sample_weight, sample_mask, random_state, X_idx_sorted, X_csc, X_csr)\u001b[0m\n\u001b[0;32m    786\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    787\u001b[0m                 tree.fit(X, residual, sample_weight=sample_weight,\n\u001b[1;32m--> 788\u001b[1;33m                          check_input=False, X_idx_sorted=X_idx_sorted)\n\u001b[0m\u001b[0;32m    789\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    790\u001b[0m             \u001b[1;31m# update tree leaves\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\computation\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\tree.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[0;32m   1122\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1123\u001b[0m             \u001b[0mcheck_input\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcheck_input\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1124\u001b[1;33m             X_idx_sorted=X_idx_sorted)\n\u001b[0m\u001b[0;32m   1125\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1126\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\computation\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\tree.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[0;32m    360\u001b[0m                                            min_impurity_split)\n\u001b[0;32m    361\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 362\u001b[1;33m         \u001b[0mbuilder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtree_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_idx_sorted\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    363\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    364\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Senate Large \n",
    "\n",
    "clfBayes.fit(np.stack(senLgTrain['vect'], axis=0), senLgTrain['category'])\n",
    "clfLinear.fit(np.stack(senLgTrain['vect'], axis=0), senLgTrain['category'])\n",
    "clfKernel.fit(np.stack(senLgTrain['vect'], axis=0), senLgTrain['category'])\n",
    "clfKNeighbors.fit(np.stack(senLgTrain['vect'], axis=0), senLgTrain['category'])\n",
    "clfReg.fit(np.stack(senLgTrain['vect'], axis=0), senLgTrain['category'])\n",
    "clfTree.fit(np.stack(senLgTrain['vect'], axis=0), senLgTrain['category'])\n",
    "clfForest.fit(np.stack(senLgTrain['vect'], axis=0), senLgTrain['category'])\n",
    "clfNN.fit(np.stack(senLgTrain['vect'], axis=0), senLgTrain['category'])\n",
    "clfEnsem.fit(np.stack(senLgTrain['vect'], axis=0), senLgTrain['category'])\n",
    "\n",
    "display(lucem_illud.evaluateClassifier(clfBayes, senLgTest))\n",
    "display(lucem_illud.evaluateClassifier(clfLinear, senLgTest))\n",
    "display(lucem_illud.evaluateClassifier(clfKernel, senLgTest))\n",
    "display(lucem_illud.evaluateClassifier(clfKNeighbors, senLgTest))\n",
    "display(lucem_illud.evaluateClassifier(clfReg, senLgTest))\n",
    "display(lucem_illud.evaluateClassifier(clfTree, senLgTest))\n",
    "display(lucem_illud.evaluateClassifier(clfForest, senLgTest))\n",
    "display(lucem_illud.evaluateClassifier(clfNN, senLgTest))\n",
    "display(lucem_illud.evaluateClassifier(clfEnsem, senLgTest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# spam \n",
    "\n",
    "clfBayes.fit(np.stack(spamTrain['vect'], axis=0), spamTrain['category'])\n",
    "clfLinear.fit(np.stack(spamTrain['vect'], axis=0), spamTrain['category'])\n",
    "clfKernel.fit(np.stack(spamTrain['vect'], axis=0), spamTrain['category'])\n",
    "clfKNeighbors.fit(np.stack(spamTrain['vect'], axis=0), spamTrain['category'])\n",
    "clfReg.fit(np.stack(spamTrain['vect'], axis=0), spamTrain['category'])\n",
    "clfTree.fit(np.stack(spamTrain['vect'], axis=0), spamTrain['category'])\n",
    "clfForest.fit(np.stack(spamTrain['vect'], axis=0), spamTrain['category'])\n",
    "clfNN.fit(np.stack(spamTrain['vect'], axis=0), spamTrain['category'])\n",
    "clfEnsem.fit(np.stack(spamTrain['vect'], axis=0), spamTrain['category'])\n",
    "\n",
    "display(lucem_illud.evaluateClassifier(clfBayes, spamTest))\n",
    "display(lucem_illud.evaluateClassifier(clfLinear, spamTest))\n",
    "display(lucem_illud.evaluateClassifier(clfKernel, spamTest))\n",
    "display(lucem_illud.evaluateClassifier(clfKNeighbors, spamTest))\n",
    "display(lucem_illud.evaluateClassifier(clfReg, spamTest))\n",
    "display(lucem_illud.evaluateClassifier(clfTree, spamTest))\n",
    "display(lucem_illud.evaluateClassifier(clfForest, spamTest))\n",
    "display(lucem_illud.evaluateClassifier(clfNN, spamTest))\n",
    "display(lucem_illud.evaluateClassifier(clfEnsem, spamTest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Bayes\n",
    "#clf = sklearn.naive_bayes.GaussianNB()\n",
    "\n",
    "#Analogizes\n",
    "#clf = sklearn.svm.SVC(kernel = 'linear', probability = True) #slow, set probability = False to speed up, but lose ROC\n",
    "#clf = sklearn.svm.SVC(kernel = 'poly', degree = 3, probability = True) #slower\n",
    "#clf = sklearn.neighbors.KNeighborsClassifier(5, weights='distance')# k, 'distance' or 'uniform'\n",
    "\n",
    "#Classical Regression\n",
    "#clf = sklearn.linear_model.LogisticRegression()\n",
    "\n",
    "#Symbolists\n",
    "#clf = sklearn.tree.DecisionTreeClassifier()\n",
    "#clf = sklearn.ensemble.RandomForestClassifier()\n",
    "\n",
    "#Connectionists\n",
    "#clf = sklearn.neural_network.MLPClassifier()\n",
    "\n",
    "#Ensemble\n",
    "#clf = sklearn.ensemble.GradientBoostingClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf.fit(np.stack(dfTrain['vect'], axis=0), dfTrain['category'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lucem_illud.evaluateClassifier(clf, dfTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lucem_illud.plotConfusionMatrix(clf, dfTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lucem_illud.plotMultiROC(clf, dfTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lucem_illud.plotregions(clf, dfTrain)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:red\">*Exercise 1*</span>\n",
    "\n",
    "<span style=\"color:red\">Go back through all of the cells above and generate 10 distinct artificial datasets and classify them with all of the available methods. Add a cell immediately below and describe which classifier(s) worked best with which artificially constructed data source and why. Then go through all of the empirical datasets (i.e., Newsgroups, Senate Small, Senate Large, Email Spam) and classify them with all available methods. Add a second cell immediately below and describe which classifier(s) worked best with which data set and why.\n",
    "\n",
    "<span style=\"color:red\">***Stretch*** (but also required) Wander through the SKLearn documentation available [here](http://scikit-learn.org/stable/), particularly perusing the classifiers. In cells following, identify and implement a new classifier that we have not yet used (e.g., AdaBoost, CART) on one artificial dataset and one real dataset (used above). Then, in the next cell describe the classifier, detail how it compares with the approaches above, and why it performed better or worse than others."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Artificial Data\n",
    "\n",
    "The biggest takeaway from running my five distinct datasets through each classification method is that data structure definitely matters! (No surprise there.) For example: the multiBlobs data is the 'easiest' to classify, considering that there is already some kind of underlying structure (compare this especially to the random data). \n",
    "\n",
    "Zooming out, it seems to be the case that, in general, more 'traditional' (for lack of a better term) classification methods like bayes and regression do well at classifying data that is separated along different dimensions, while 'newer' methods like the neural net and ensemble are better at picking out classifications that are nested within the same or similar dimensions. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Real Data\n",
    "\n",
    "For the reddit data, many worked well, and the regression categorization worked particularly well, leading me to believe that there are not classes nested within dimensions. This is true for the newsgroup data as well.\n",
    "\n",
    "The senate data gives us an interesting chance to look at random forest and decision trees side-by-side. As we can see above, the decision trees classification works better for the large set than it does for the small set, which makes sense considering that any small iteration made at the base of the tree could lead to drastically different results in later iterations. \n",
    "\n",
    "As for spam - spam is hard!! It turns out plain old bayes works pretty well, probably because the 'ground truth' for spam is harder to pick out than Senate office press release style. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clinton / Obama Press Releases\n",
    "\n",
    "We often will not have nicely prepared data, so we will work though the proccess of cleaning and structuring in more detail here:\n",
    "\n",
    "While the Clinton and Obama Senatorial Press Releases are not hand-coded, we can imagine that we have been given a stack of such press releases, but lost the metadata associated with which senatorial office issued which. If we label a few of them, how well can our classifier do at recovering the rest? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ObamaClintonReleases = pandas.read_csv('../data/ObamaClintonReleases.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's turn the 'targetSenator' column into a binary category variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ObamaClintonReleases['category'] = [s == 'Obama' for s in ObamaClintonReleases['targetSenator']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                           download_url  \\\n",
      "0     https://raw.githubusercontent.com/lintool/Grim...   \n",
      "1     https://raw.githubusercontent.com/lintool/Grim...   \n",
      "2     https://raw.githubusercontent.com/lintool/Grim...   \n",
      "3     https://raw.githubusercontent.com/lintool/Grim...   \n",
      "4     https://raw.githubusercontent.com/lintool/Grim...   \n",
      "5     https://raw.githubusercontent.com/lintool/Grim...   \n",
      "6     https://raw.githubusercontent.com/lintool/Grim...   \n",
      "7     https://raw.githubusercontent.com/lintool/Grim...   \n",
      "8     https://raw.githubusercontent.com/lintool/Grim...   \n",
      "9     https://raw.githubusercontent.com/lintool/Grim...   \n",
      "10    https://raw.githubusercontent.com/lintool/Grim...   \n",
      "11    https://raw.githubusercontent.com/lintool/Grim...   \n",
      "12    https://raw.githubusercontent.com/lintool/Grim...   \n",
      "13    https://raw.githubusercontent.com/lintool/Grim...   \n",
      "14    https://raw.githubusercontent.com/lintool/Grim...   \n",
      "15    https://raw.githubusercontent.com/lintool/Grim...   \n",
      "16    https://raw.githubusercontent.com/lintool/Grim...   \n",
      "17    https://raw.githubusercontent.com/lintool/Grim...   \n",
      "18    https://raw.githubusercontent.com/lintool/Grim...   \n",
      "19    https://raw.githubusercontent.com/lintool/Grim...   \n",
      "20    https://raw.githubusercontent.com/lintool/Grim...   \n",
      "21    https://raw.githubusercontent.com/lintool/Grim...   \n",
      "22    https://raw.githubusercontent.com/lintool/Grim...   \n",
      "23    https://raw.githubusercontent.com/lintool/Grim...   \n",
      "24    https://raw.githubusercontent.com/lintool/Grim...   \n",
      "25    https://raw.githubusercontent.com/lintool/Grim...   \n",
      "26    https://raw.githubusercontent.com/lintool/Grim...   \n",
      "27    https://raw.githubusercontent.com/lintool/Grim...   \n",
      "28    https://raw.githubusercontent.com/lintool/Grim...   \n",
      "29    https://raw.githubusercontent.com/lintool/Grim...   \n",
      "...                                                 ...   \n",
      "1679  https://raw.githubusercontent.com/lintool/Grim...   \n",
      "1680  https://raw.githubusercontent.com/lintool/Grim...   \n",
      "1681  https://raw.githubusercontent.com/lintool/Grim...   \n",
      "1682  https://raw.githubusercontent.com/lintool/Grim...   \n",
      "1683  https://raw.githubusercontent.com/lintool/Grim...   \n",
      "1684  https://raw.githubusercontent.com/lintool/Grim...   \n",
      "1685  https://raw.githubusercontent.com/lintool/Grim...   \n",
      "1686  https://raw.githubusercontent.com/lintool/Grim...   \n",
      "1687  https://raw.githubusercontent.com/lintool/Grim...   \n",
      "1688  https://raw.githubusercontent.com/lintool/Grim...   \n",
      "1689  https://raw.githubusercontent.com/lintool/Grim...   \n",
      "1690  https://raw.githubusercontent.com/lintool/Grim...   \n",
      "1691  https://raw.githubusercontent.com/lintool/Grim...   \n",
      "1692  https://raw.githubusercontent.com/lintool/Grim...   \n",
      "1693  https://raw.githubusercontent.com/lintool/Grim...   \n",
      "1694  https://raw.githubusercontent.com/lintool/Grim...   \n",
      "1695  https://raw.githubusercontent.com/lintool/Grim...   \n",
      "1696  https://raw.githubusercontent.com/lintool/Grim...   \n",
      "1697  https://raw.githubusercontent.com/lintool/Grim...   \n",
      "1698  https://raw.githubusercontent.com/lintool/Grim...   \n",
      "1699  https://raw.githubusercontent.com/lintool/Grim...   \n",
      "1700  https://raw.githubusercontent.com/lintool/Grim...   \n",
      "1701  https://raw.githubusercontent.com/lintool/Grim...   \n",
      "1702  https://raw.githubusercontent.com/lintool/Grim...   \n",
      "1703  https://raw.githubusercontent.com/lintool/Grim...   \n",
      "1704  https://raw.githubusercontent.com/lintool/Grim...   \n",
      "1705  https://raw.githubusercontent.com/lintool/Grim...   \n",
      "1706  https://raw.githubusercontent.com/lintool/Grim...   \n",
      "1707  https://raw.githubusercontent.com/lintool/Grim...   \n",
      "1708  https://raw.githubusercontent.com/lintool/Grim...   \n",
      "\n",
      "                                               html_url  \\\n",
      "0     https://github.com/lintool/GrimmerSenatePressR...   \n",
      "1     https://github.com/lintool/GrimmerSenatePressR...   \n",
      "2     https://github.com/lintool/GrimmerSenatePressR...   \n",
      "3     https://github.com/lintool/GrimmerSenatePressR...   \n",
      "4     https://github.com/lintool/GrimmerSenatePressR...   \n",
      "5     https://github.com/lintool/GrimmerSenatePressR...   \n",
      "6     https://github.com/lintool/GrimmerSenatePressR...   \n",
      "7     https://github.com/lintool/GrimmerSenatePressR...   \n",
      "8     https://github.com/lintool/GrimmerSenatePressR...   \n",
      "9     https://github.com/lintool/GrimmerSenatePressR...   \n",
      "10    https://github.com/lintool/GrimmerSenatePressR...   \n",
      "11    https://github.com/lintool/GrimmerSenatePressR...   \n",
      "12    https://github.com/lintool/GrimmerSenatePressR...   \n",
      "13    https://github.com/lintool/GrimmerSenatePressR...   \n",
      "14    https://github.com/lintool/GrimmerSenatePressR...   \n",
      "15    https://github.com/lintool/GrimmerSenatePressR...   \n",
      "16    https://github.com/lintool/GrimmerSenatePressR...   \n",
      "17    https://github.com/lintool/GrimmerSenatePressR...   \n",
      "18    https://github.com/lintool/GrimmerSenatePressR...   \n",
      "19    https://github.com/lintool/GrimmerSenatePressR...   \n",
      "20    https://github.com/lintool/GrimmerSenatePressR...   \n",
      "21    https://github.com/lintool/GrimmerSenatePressR...   \n",
      "22    https://github.com/lintool/GrimmerSenatePressR...   \n",
      "23    https://github.com/lintool/GrimmerSenatePressR...   \n",
      "24    https://github.com/lintool/GrimmerSenatePressR...   \n",
      "25    https://github.com/lintool/GrimmerSenatePressR...   \n",
      "26    https://github.com/lintool/GrimmerSenatePressR...   \n",
      "27    https://github.com/lintool/GrimmerSenatePressR...   \n",
      "28    https://github.com/lintool/GrimmerSenatePressR...   \n",
      "29    https://github.com/lintool/GrimmerSenatePressR...   \n",
      "...                                                 ...   \n",
      "1679  https://github.com/lintool/GrimmerSenatePressR...   \n",
      "1680  https://github.com/lintool/GrimmerSenatePressR...   \n",
      "1681  https://github.com/lintool/GrimmerSenatePressR...   \n",
      "1682  https://github.com/lintool/GrimmerSenatePressR...   \n",
      "1683  https://github.com/lintool/GrimmerSenatePressR...   \n",
      "1684  https://github.com/lintool/GrimmerSenatePressR...   \n",
      "1685  https://github.com/lintool/GrimmerSenatePressR...   \n",
      "1686  https://github.com/lintool/GrimmerSenatePressR...   \n",
      "1687  https://github.com/lintool/GrimmerSenatePressR...   \n",
      "1688  https://github.com/lintool/GrimmerSenatePressR...   \n",
      "1689  https://github.com/lintool/GrimmerSenatePressR...   \n",
      "1690  https://github.com/lintool/GrimmerSenatePressR...   \n",
      "1691  https://github.com/lintool/GrimmerSenatePressR...   \n",
      "1692  https://github.com/lintool/GrimmerSenatePressR...   \n",
      "1693  https://github.com/lintool/GrimmerSenatePressR...   \n",
      "1694  https://github.com/lintool/GrimmerSenatePressR...   \n",
      "1695  https://github.com/lintool/GrimmerSenatePressR...   \n",
      "1696  https://github.com/lintool/GrimmerSenatePressR...   \n",
      "1697  https://github.com/lintool/GrimmerSenatePressR...   \n",
      "1698  https://github.com/lintool/GrimmerSenatePressR...   \n",
      "1699  https://github.com/lintool/GrimmerSenatePressR...   \n",
      "1700  https://github.com/lintool/GrimmerSenatePressR...   \n",
      "1701  https://github.com/lintool/GrimmerSenatePressR...   \n",
      "1702  https://github.com/lintool/GrimmerSenatePressR...   \n",
      "1703  https://github.com/lintool/GrimmerSenatePressR...   \n",
      "1704  https://github.com/lintool/GrimmerSenatePressR...   \n",
      "1705  https://github.com/lintool/GrimmerSenatePressR...   \n",
      "1706  https://github.com/lintool/GrimmerSenatePressR...   \n",
      "1707  https://github.com/lintool/GrimmerSenatePressR...   \n",
      "1708  https://github.com/lintool/GrimmerSenatePressR...   \n",
      "\n",
      "                         name                                 path  \\\n",
      "0       10Apr2007Obama430.txt      raw/Obama/10Apr2007Obama430.txt   \n",
      "1       10Apr2008Obama108.txt      raw/Obama/10Apr2008Obama108.txt   \n",
      "2       10Aug2005Obama674.txt      raw/Obama/10Aug2005Obama674.txt   \n",
      "3       10Aug2005Obama675.txt      raw/Obama/10Aug2005Obama675.txt   \n",
      "4       10Aug2006Obama508.txt      raw/Obama/10Aug2006Obama508.txt   \n",
      "5       10Dec2007Obama192.txt      raw/Obama/10Dec2007Obama192.txt   \n",
      "6       10Jan2007Obama472.txt      raw/Obama/10Jan2007Obama472.txt   \n",
      "7       10Jan2008Obama165.txt      raw/Obama/10Jan2008Obama165.txt   \n",
      "8        10Jul2008Obama28.txt       raw/Obama/10Jul2008Obama28.txt   \n",
      "9        10Jul2008Obama29.txt       raw/Obama/10Jul2008Obama29.txt   \n",
      "10       10Jun2008Obama63.txt       raw/Obama/10Jun2008Obama63.txt   \n",
      "11       10Jun2008Obama64.txt       raw/Obama/10Jun2008Obama64.txt   \n",
      "12      10Mar2007Obama453.txt      raw/Obama/10Mar2007Obama453.txt   \n",
      "13      10Mar2008Obama134.txt      raw/Obama/10Mar2008Obama134.txt   \n",
      "14      10May2007Obama408.txt      raw/Obama/10May2007Obama408.txt   \n",
      "15      10May2007Obama409.txt      raw/Obama/10May2007Obama409.txt   \n",
      "16      10Nov2005Obama622.txt      raw/Obama/10Nov2005Obama622.txt   \n",
      "17      10Oct2006Obama490.txt      raw/Obama/10Oct2006Obama490.txt   \n",
      "18      10Oct2007Obama255.txt      raw/Obama/10Oct2007Obama255.txt   \n",
      "19      11Apr2007Obama429.txt      raw/Obama/11Apr2007Obama429.txt   \n",
      "20      11Dec2006Obama477.txt      raw/Obama/11Dec2006Obama477.txt   \n",
      "21      11Dec2007Obama191.txt      raw/Obama/11Dec2007Obama191.txt   \n",
      "22      11Feb2008Obama151.txt      raw/Obama/11Feb2008Obama151.txt   \n",
      "23      11Feb2008Obama152.txt      raw/Obama/11Feb2008Obama152.txt   \n",
      "24      11Jan2007Obama471.txt      raw/Obama/11Jan2007Obama471.txt   \n",
      "25      11Jan2008Obama164.txt      raw/Obama/11Jan2008Obama164.txt   \n",
      "26      11Jul2007Obama348.txt      raw/Obama/11Jul2007Obama348.txt   \n",
      "27      11Jul2007Obama349.txt      raw/Obama/11Jul2007Obama349.txt   \n",
      "28      11Oct2007Obama253.txt      raw/Obama/11Oct2007Obama253.txt   \n",
      "29      11Oct2007Obama254.txt      raw/Obama/11Oct2007Obama254.txt   \n",
      "...                       ...                                  ...   \n",
      "1679   1Mar2006Clinton630.txt   raw/Clinton/1Mar2006Clinton630.txt   \n",
      "1680  1Mar2007Clinton1019.txt  raw/Clinton/1Mar2007Clinton1019.txt   \n",
      "1681  1Mar2007Clinton1020.txt  raw/Clinton/1Mar2007Clinton1020.txt   \n",
      "1682  1Mar2007Clinton1021.txt  raw/Clinton/1Mar2007Clinton1021.txt   \n",
      "1683  1Mar2007Clinton1022.txt  raw/Clinton/1Mar2007Clinton1022.txt   \n",
      "1684  1Mar2007Clinton1023.txt  raw/Clinton/1Mar2007Clinton1023.txt   \n",
      "1685  1Mar2007Clinton1024.txt  raw/Clinton/1Mar2007Clinton1024.txt   \n",
      "1686  1Mar2007Clinton1025.txt  raw/Clinton/1Mar2007Clinton1025.txt   \n",
      "1687  1Mar2007Clinton1026.txt  raw/Clinton/1Mar2007Clinton1026.txt   \n",
      "1688   1May2006Clinton549.txt   raw/Clinton/1May2006Clinton549.txt   \n",
      "1689   1May2007Clinton859.txt   raw/Clinton/1May2007Clinton859.txt   \n",
      "1690   1May2007Clinton860.txt   raw/Clinton/1May2007Clinton860.txt   \n",
      "1691   1May2007Clinton861.txt   raw/Clinton/1May2007Clinton861.txt   \n",
      "1692   1May2007Clinton862.txt   raw/Clinton/1May2007Clinton862.txt   \n",
      "1693   1Nov2005Clinton137.txt   raw/Clinton/1Nov2005Clinton137.txt   \n",
      "1694   1Nov2005Clinton138.txt   raw/Clinton/1Nov2005Clinton138.txt   \n",
      "1695   1Nov2005Clinton139.txt   raw/Clinton/1Nov2005Clinton139.txt   \n",
      "1696   1Nov2007Clinton212.txt   raw/Clinton/1Nov2007Clinton212.txt   \n",
      "1697   1Nov2007Clinton213.txt   raw/Clinton/1Nov2007Clinton213.txt   \n",
      "1698   1Nov2007Clinton214.txt   raw/Clinton/1Nov2007Clinton214.txt   \n",
      "1699   1Oct2006Clinton121.txt   raw/Clinton/1Oct2006Clinton121.txt   \n",
      "1700   1Oct2007Clinton289.txt   raw/Clinton/1Oct2007Clinton289.txt   \n",
      "1701   1Oct2007Clinton290.txt   raw/Clinton/1Oct2007Clinton290.txt   \n",
      "1702   1Sep2005Clinton283.txt   raw/Clinton/1Sep2005Clinton283.txt   \n",
      "1703   1Sep2005Clinton284.txt   raw/Clinton/1Sep2005Clinton284.txt   \n",
      "1704   1Sep2005Clinton285.txt   raw/Clinton/1Sep2005Clinton285.txt   \n",
      "1705   1Sep2005Clinton286.txt   raw/Clinton/1Sep2005Clinton286.txt   \n",
      "1706   1Sep2005Clinton287.txt   raw/Clinton/1Sep2005Clinton287.txt   \n",
      "1707   1Sep2006Clinton207.txt   raw/Clinton/1Sep2006Clinton207.txt   \n",
      "1708   1Sep2006Clinton208.txt   raw/Clinton/1Sep2006Clinton208.txt   \n",
      "\n",
      "                                                   text targetSenator  \\\n",
      "0        Obama Calls on IRS to Protect Taxpayers    ...         Obama   \n",
      "1        Statement from Senator Barack Obama on the ...         Obama   \n",
      "2        Obama Says Bill Will Help Cut Off Supply of...         Obama   \n",
      "3        Obama  Durbin Say Illinois Will Receive 33 ...         Obama   \n",
      "4        Obama Introduces Bill to Help Tap Power of ...         Obama   \n",
      "5        Statement of Senator Barack Obama on Intern...         Obama   \n",
      "6        Legislation to Increase Availability and Us...         Obama   \n",
      "7        Obama Statement on the Flooding in East Cen...         Obama   \n",
      "8        Obama  Green Applaud House Passage of Bill ...         Obama   \n",
      "9        Obama Joins Schumer and McCaskill to Call o...         Obama   \n",
      "10       Statement of Senator Barack Obama on Senate...         Obama   \n",
      "11       Statement of Senators Barack Obama and Dick...         Obama   \n",
      "12       Senate Leadership Adopts Iraq Legislation w...         Obama   \n",
      "13       Obama Cosponsors One Year Moratorium on All...         Obama   \n",
      "14       Durbin  Murray  Obama Introduce Bill to Upd...         Obama   \n",
      "15       Obama Statement on the Resignation of There...         Obama   \n",
      "16       Obama Statement on the Withdrawal of the No...         Obama   \n",
      "17       Obama Again Calls for Independent Ethics Co...         Obama   \n",
      "18       Obama  Rice Must Provide Answers About New ...         Obama   \n",
      "19       Senators Introduce Bill to Provide Housing ...         Obama   \n",
      "20       Obama Statement on Arrest of Man Planning T...         Obama   \n",
      "21       Obama  Hagel  Cantwell Introduce Bill to Fi...         Obama   \n",
      "22       Obama Statement on the Attempted Assassinat...         Obama   \n",
      "23       Obama Demands Pentagon Release Unclassified...         Obama   \n",
      "24       Obama Statement on President s Call for Tro...         Obama   \n",
      "25       Obama Demands Gates Address Contractor   s ...         Obama   \n",
      "26       Obama Statement on President Bush   s Threa...         Obama   \n",
      "27       Obama Secures Funding to Construct Asian Ca...         Obama   \n",
      "28       Obama Asks Rice to Address Violence Against...         Obama   \n",
      "29       Obama Calls for Investigation into Violatio...         Obama   \n",
      "...                                                 ...           ...   \n",
      "1679  March 1  2006 Change of Address Notice For Cli...       Clinton   \n",
      "1680  March 1  2007 Joint Statement of President Bil...       Clinton   \n",
      "1681  March 1  2007 Senator Clinton Presses for Acti...       Clinton   \n",
      "1682  March 1  2007 Senator Clinton Questions Admini...       Clinton   \n",
      "1683  March 1  2007 In CNBC Interview Senator Clinto...       Clinton   \n",
      "1684  March 1  2007 Senators Clinton and Lautenberg ...       Clinton   \n",
      "1685  March 1  2007 Statement of President Clinton a...       Clinton   \n",
      "1686  March 1  2007 Clinton  Voinovich Demand Immedi...       Clinton   \n",
      "1687  March 1  2007 Senator Clinton Calls for Invest...       Clinton   \n",
      "1688  May 1  2006 Senator Clinton Calls On Senators ...       Clinton   \n",
      "1689  May 1  2007 Statement of Senator Hillary Rodha...       Clinton   \n",
      "1690  May 1  2007 Senator Clinton Joins Bipartisan C...       Clinton   \n",
      "1691  May 1  2007 Statement of Senator Hillary Rodha...       Clinton   \n",
      "1692  May 1  2007 Bono Joins Lowey  Clinton  Smith  ...       Clinton   \n",
      "1693  November 1  2005 Statement of Senator Hillary ...       Clinton   \n",
      "1694  November 1  2005 Statement of Senator Hillary ...       Clinton   \n",
      "1695  November 1  2005 Nearly 10 000 Americans Join ...       Clinton   \n",
      "1696  November 1  2007 Dodd  Clinton Praise Passage ...       Clinton   \n",
      "1697  November 1  2007 Statement of Senator Hillary ...       Clinton   \n",
      "1698  November 1  2007 30 Senators Say White House M...       Clinton   \n",
      "1699  October 1  2006 Senator Clinton and Former Buf...       Clinton   \n",
      "1700  October 1  2007 Senator Clinton Welcomes Senat...       Clinton   \n",
      "1701  October 1  2007 Senator Clinton Announces Co S...       Clinton   \n",
      "1702  September 1  2005 Senator Clinton Picks Offici...       Clinton   \n",
      "1703  September 1  2005 Senator Clinton and Foodlink...       Clinton   \n",
      "1704  September 1  2005 Senator Clinton Visit Infoto...       Clinton   \n",
      "1705  September 1  2005 Senator Clinton Announces Ex...       Clinton   \n",
      "1706  September 1  2005 Senator Clinton Joins Local ...       Clinton   \n",
      "1707  September 1  2006 Clintons Meet with Cazenovia...       Clinton   \n",
      "1708  September 1  2006 Al Qaeda Publishes Online  D...       Clinton   \n",
      "\n",
      "      category  \n",
      "0         True  \n",
      "1         True  \n",
      "2         True  \n",
      "3         True  \n",
      "4         True  \n",
      "5         True  \n",
      "6         True  \n",
      "7         True  \n",
      "8         True  \n",
      "9         True  \n",
      "10        True  \n",
      "11        True  \n",
      "12        True  \n",
      "13        True  \n",
      "14        True  \n",
      "15        True  \n",
      "16        True  \n",
      "17        True  \n",
      "18        True  \n",
      "19        True  \n",
      "20        True  \n",
      "21        True  \n",
      "22        True  \n",
      "23        True  \n",
      "24        True  \n",
      "25        True  \n",
      "26        True  \n",
      "27        True  \n",
      "28        True  \n",
      "29        True  \n",
      "...        ...  \n",
      "1679     False  \n",
      "1680     False  \n",
      "1681     False  \n",
      "1682     False  \n",
      "1683     False  \n",
      "1684     False  \n",
      "1685     False  \n",
      "1686     False  \n",
      "1687     False  \n",
      "1688     False  \n",
      "1689     False  \n",
      "1690     False  \n",
      "1691     False  \n",
      "1692     False  \n",
      "1693     False  \n",
      "1694     False  \n",
      "1695     False  \n",
      "1696     False  \n",
      "1697     False  \n",
      "1698     False  \n",
      "1699     False  \n",
      "1700     False  \n",
      "1701     False  \n",
      "1702     False  \n",
      "1703     False  \n",
      "1704     False  \n",
      "1705     False  \n",
      "1706     False  \n",
      "1707     False  \n",
      "1708     False  \n",
      "\n",
      "[1709 rows x 7 columns]\n"
     ]
    }
   ],
   "source": [
    "print(ObamaClintonReleases)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tokenize and normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ObamaClintonReleases['tokenized_text'] = ObamaClintonReleases['text'].apply(lambda x: nltk.word_tokenize(x))\n",
    "ObamaClintonReleases['normalized_text'] = ObamaClintonReleases['tokenized_text'].apply(lambda x: lucem_illud.normalizeTokens(x, stopwordLst = lucem_illud.stop_words_basic, stemmer = lucem_illud.stemmer_basic))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's split the data into training data and testing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "holdBackFraction = .2\n",
    "train_data_df, test_data_df = lucem_illud.trainTestSplit(ObamaClintonReleases, holdBackFraction=holdBackFraction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1368\n",
      "341\n"
     ]
    }
   ],
   "source": [
    "print(len(train_data_df))\n",
    "print(len(test_data_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's try with a logistic regression, which may be familiar to you from statistical methods classes. First, we must turn the training dataset into a tf-idf matrix (`lucem_illud.generateVecs()` will help with this but for now we are doing it the long way):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "TFVectorizer = sklearn.feature_extraction.text.TfidfVectorizer(max_df=100, min_df=2, stop_words='english', norm='l2')\n",
    "TFVects = TFVectorizer.fit_transform(train_data_df['text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that we can use the CountVectorizer instead, which simply produces a matrix of word counts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1368, 11512)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TFVects.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can save this in the dataframe to make things easier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data_df['vect'] = [np.array(v).flatten() for v in TFVects.todense()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In a regression, we cannot have more variables than cases. So, we need to first do a dimension reduction. First, we will approah this with PCA. You have previously seen this in week 3. Here we are not concerned about visualization, but rather classification and so all principal components are calculated. Watch out: we have to use `stack` not `sum` for combining the vectors. We note that you could also use topic loading and embedding dimensions as featured variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pca = sklearn.decomposition.PCA()\n",
    "reduced_data = pca.fit_transform(np.stack(train_data_df['vect'], axis=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can store the PCA space vectors in the dataframe too:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data_df['pca'] = [r for r in reduced_data]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualization in 2D:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAl8AAAJOCAYAAACJNWIjAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nFwBASHwBAITEFwBA6Bu3+MpIPF0egwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x225e130b5c0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(figsize = (10,10))\n",
    "ax.axis('off')\n",
    "pallet = seaborn.color_palette(palette='coolwarm', n_colors = 2)\n",
    "\n",
    "#Plot Obama\n",
    "a = np.stack(train_data_df[train_data_df['category']]['pca'])\n",
    "ax.scatter(a[:,0], a[:, 1], c = pallet[0], label = \"True\")\n",
    "\n",
    "#Plot not Obama\n",
    "a = np.stack(train_data_df[train_data_df['category'].eq(False)]['pca'])\n",
    "ax.scatter(a[:,0], a[:, 1], c = pallet[1], label = \"False\")\n",
    "    \n",
    "ax.legend(loc = 'upper right', title = 'Is Obama')\n",
    "plt.title('True Classes, Training Set')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PCA cannot distinguish Obama very well. Let's perform a screeplot to see how many Principal Components we need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA8AAAAFNCAYAAADPZwa0AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n4ALYzMzMzMzMKuH/AMx4oaOYpAUJAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x225e13297f0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "n = len(train_data_df)\n",
    "\n",
    "fig, (ax1, ax2, ax3) = plt.subplots(ncols=3, figsize = (16, 5), sharey=True)\n",
    "\n",
    "eigen_vals = np.arange(n) + 1\n",
    "ax1.plot(eigen_vals, pca.explained_variance_ratio_, 'ro-', linewidth=1)\n",
    "ax1.set_title('Scree Plot (Full)')\n",
    "ax1.set_xlabel('Principal Component')\n",
    "ax1.set_ylabel('Proportion of Explained Variance')\n",
    "\n",
    "eigen_vals = np.arange(50) + 1\n",
    "ax2.plot(eigen_vals, pca.explained_variance_ratio_[:50], 'ro-', linewidth=1)\n",
    "ax2.set_title('Scree Plot (First 50 Principal Components)')\n",
    "ax2.set_xlabel('Principal Component')\n",
    "ax2.set_ylabel('Proportion of Explained Variance')\n",
    "\n",
    "\n",
    "eigen_vals = np.arange(20) + 1\n",
    "ax3.plot(eigen_vals, pca.explained_variance_ratio_[:20], 'ro-', linewidth=2)\n",
    "ax3.set_title('Scree Plot (First 50 Principal Components)')\n",
    "ax3.set_xlabel('Principal Component')\n",
    "ax3.set_ylabel('Proportion of Explained Variance')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's choose the first 10 pricipal components as our covariates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data_df['pca_reduced_10'] = train_data_df['pca'].apply(lambda x: x[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we fit a logistic regression to our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logistic = sklearn.linear_model.LogisticRegression()\n",
    "logistic.fit(np.stack(train_data_df['pca_reduced_10'], axis=0), train_data_df['category'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see how the logistic regression performs on the training dataset from which we develop the model. Unfortunately, the mean accuracy is only about 64%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.689327485380117"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logistic.score(np.stack(train_data_df['pca_reduced_10'], axis=0), train_data_df['category'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How does it perform on the testing dataset, which we \"held out\" and did not use for model training? We need to repeat all the steps on the testing data, but without retraining:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6070381231671554"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Create vectors\n",
    "TFVects_test = TFVectorizer.transform(test_data_df['text'])\n",
    "test_data_df['vect'] = [np.array(v).flatten() for v in TFVects_test.todense()]\n",
    "\n",
    "#PCA\n",
    "reduced_data_test = pca.transform(np.stack(test_data_df['vect'], axis=0))\n",
    "test_data_df['pca'] = [r for r in reduced_data_test]\n",
    "test_data_df['pca_reduced_10'] = test_data_df['pca'].apply(lambda x: x[:10])\n",
    "\n",
    "#Test\n",
    "logistic.score(np.stack(test_data_df['pca_reduced_10'], axis=0), test_data_df['category'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Slightly poorer. How about using more dimensions (40)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training:\n",
      "0.7404970760233918\n",
      "Testing:\n",
      "0.6627565982404692\n"
     ]
    }
   ],
   "source": [
    "train_data_df['pca_reduced_40'] = train_data_df['pca'].apply(lambda x: x[:40])\n",
    "test_data_df['pca_reduced_40'] = test_data_df['pca'].apply(lambda x: x[:40])\n",
    "\n",
    "logistic.fit(np.stack(train_data_df['pca_reduced_40'], axis=0), train_data_df['category'])\n",
    "\n",
    "print(\"Training:\")\n",
    "print(logistic.score(np.stack(train_data_df['pca_reduced_40'], axis=0), train_data_df['category']))\n",
    "print(\"Testing:\")\n",
    "print(logistic.score(np.stack(test_data_df['pca_reduced_40'], axis=0), test_data_df['category']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or still more (100)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training:\n",
      "0.8399122807017544\n",
      "Testing:\n",
      "0.7448680351906158\n"
     ]
    }
   ],
   "source": [
    "train_data_df['pca_reduced_100'] = train_data_df['pca'].apply(lambda x: x[:100])\n",
    "test_data_df['pca_reduced_100'] = test_data_df['pca'].apply(lambda x: x[:100])\n",
    "\n",
    "logistic.fit(np.stack(train_data_df['pca_reduced_100'], axis=0), train_data_df['category'])\n",
    "\n",
    "print(\"Training:\")\n",
    "print(logistic.score(np.stack(train_data_df['pca_reduced_100'], axis=0), train_data_df['category']))\n",
    "print(\"Testing:\")\n",
    "print(logistic.score(np.stack(test_data_df['pca_reduced_100'], axis=0), test_data_df['category']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or even more (200)!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training:\n",
      "0.881578947368421\n",
      "Testing:\n",
      "0.8035190615835777\n"
     ]
    }
   ],
   "source": [
    "train_data_df['pca_reduced_200'] = train_data_df['pca'].apply(lambda x: x[:200])\n",
    "test_data_df['pca_reduced_200'] = test_data_df['pca'].apply(lambda x: x[:200])\n",
    "\n",
    "logistic.fit(np.stack(train_data_df['pca_reduced_200'], axis=0), train_data_df['category'])\n",
    "\n",
    "print(\"Training:\")\n",
    "print(logistic.score(np.stack(train_data_df['pca_reduced_200'], axis=0), train_data_df['category']))\n",
    "print(\"Testing:\")\n",
    "print(logistic.score(np.stack(test_data_df['pca_reduced_200'], axis=0), test_data_df['category']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is becoming ridiculous (400)!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training:\n",
      "0.9078947368421053\n",
      "Testing:\n",
      "0.8035190615835777\n"
     ]
    }
   ],
   "source": [
    "train_data_df['pca_reduced_400'] = train_data_df['pca'].apply(lambda x: x[:400])\n",
    "test_data_df['pca_reduced_400'] = test_data_df['pca'].apply(lambda x: x[:400])\n",
    "\n",
    "logistic.fit(np.stack(train_data_df['pca_reduced_400'], axis=0), train_data_df['category'])\n",
    "\n",
    "print(\"Training:\")\n",
    "print(logistic.score(np.stack(train_data_df['pca_reduced_400'], axis=0), train_data_df['category']))\n",
    "print(\"Testing:\")\n",
    "print(logistic.score(np.stack(test_data_df['pca_reduced_400'], axis=0), test_data_df['category']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Increasing the number of covariates would overfit our data, and it seems that using a logistic regression, our prediction accuracy is at best about 65%. We can, however, try a logistic regression that uses the TF-IDF scores for each word, but with an L1 regularization or L1-norm loss function, which is also known as least absolute deviations (LAD), least absolute errors (LAE) or L1 penalty. It minimizes the sum of the absolute differences (S) between the target value ($Y_i$) and the estimated values ($f(x_i)$) and prunes all insignificant variables (i.e., word TF-IDF scores):\n",
    "\n",
    "$S=\\sum^n_{i=1}|y_i=f(x_i)|$\n",
    "\n",
    "The result is a model retaining only the most individually significant features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8530701754385965\n"
     ]
    }
   ],
   "source": [
    "logistic_l1= sklearn.linear_model.LogisticRegression(penalty='l1')\n",
    "logistic_l1.fit(np.stack(train_data_df['vect'], axis=0), train_data_df['category'])\n",
    "print(logistic_l1.score(np.stack(train_data_df['vect'], axis=0), train_data_df['category']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the model using training data, and then test it on the testing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8357771260997068\n"
     ]
    }
   ],
   "source": [
    "print(logistic_l1.score(np.stack(test_data_df['vect'], axis=0), test_data_df['category']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "81% accuracy seems like the best we can get by using a logistic regression.\n",
    "\n",
    "Now let's try with Naive Bayes. Classically, it is trained with word counts, but TF-IDF vectors are also quite good:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BernoulliNB(alpha=1.0, binarize=0.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "naiveBayes = sklearn.naive_bayes.BernoulliNB()\n",
    "naiveBayes.fit(np.stack(train_data_df['vect'], axis=0), train_data_df['category'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training:\n",
      "0.9678362573099415\n",
      "Testing:\n",
      "0.8709677419354839\n"
     ]
    }
   ],
   "source": [
    "print(\"Training:\")\n",
    "print(naiveBayes.score(np.stack(train_data_df['vect'], axis=0), train_data_df['category']))\n",
    "print(\"Testing:\")\n",
    "print(naiveBayes.score(np.stack(test_data_df['vect'], axis=0), test_data_df['category']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A bit better than the logit, but that's just looking at the accuracy. What about other measures? Let's first save the predictions in the dataframe to save use rerunning the model every time:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_data_df['nb_predict'] = naiveBayes.predict(np.stack(test_data_df['vect'], axis=0))\n",
    "test_data_df['nb_predict_prob_true'] = naiveBayes.predict_proba(np.stack(test_data_df['vect'], axis=0))[:,0] #other is prop false"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Precision:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>download_url</th>\n",
       "      <th>html_url</th>\n",
       "      <th>name</th>\n",
       "      <th>path</th>\n",
       "      <th>text</th>\n",
       "      <th>targetSenator</th>\n",
       "      <th>category</th>\n",
       "      <th>tokenized_text</th>\n",
       "      <th>normalized_text</th>\n",
       "      <th>vect</th>\n",
       "      <th>pca</th>\n",
       "      <th>pca_reduced_10</th>\n",
       "      <th>pca_reduced_40</th>\n",
       "      <th>pca_reduced_100</th>\n",
       "      <th>pca_reduced_200</th>\n",
       "      <th>pca_reduced_400</th>\n",
       "      <th>nb_predict</th>\n",
       "      <th>nb_predict_prob_true</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>965</th>\n",
       "      <td>https://raw.githubusercontent.com/lintool/Grim...</td>\n",
       "      <td>https://github.com/lintool/GrimmerSenatePressR...</td>\n",
       "      <td>13Dec2007Clinton103.txt</td>\n",
       "      <td>raw/Clinton/13Dec2007Clinton103.txt</td>\n",
       "      <td>December 13  2007 Statement of Senator Clinton...</td>\n",
       "      <td>Clinton</td>\n",
       "      <td>False</td>\n",
       "      <td>[December, 13, 2007, Statement, of, Senator, C...</td>\n",
       "      <td>[decemb, statement, senat, clinton, passag, en...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[-0.07880485792452545, 0.2962065698096317, 0.1...</td>\n",
       "      <td>[-0.07880485792452545, 0.2962065698096317, 0.1...</td>\n",
       "      <td>[-0.07880485792452545, 0.2962065698096317, 0.1...</td>\n",
       "      <td>[-0.07880485792452545, 0.2962065698096317, 0.1...</td>\n",
       "      <td>[-0.07880485792452545, 0.2962065698096317, 0.1...</td>\n",
       "      <td>[-0.07880485792452545, 0.2962065698096317, 0.1...</td>\n",
       "      <td>True</td>\n",
       "      <td>8.836614e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>https://raw.githubusercontent.com/lintool/Grim...</td>\n",
       "      <td>https://github.com/lintool/GrimmerSenatePressR...</td>\n",
       "      <td>18Dec2007Obama174.txt</td>\n",
       "      <td>raw/Obama/18Dec2007Obama174.txt</td>\n",
       "      <td>Obama Statement on the Passage of the Omnib...</td>\n",
       "      <td>Obama</td>\n",
       "      <td>True</td>\n",
       "      <td>[Obama, Statement, on, the, Passage, of, the, ...</td>\n",
       "      <td>[obama, statement, passag, omnibus, spend, pac...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[-0.024600800169206405, -0.015038358533401953,...</td>\n",
       "      <td>[-0.024600800169206405, -0.015038358533401953,...</td>\n",
       "      <td>[-0.024600800169206405, -0.015038358533401953,...</td>\n",
       "      <td>[-0.024600800169206405, -0.015038358533401953,...</td>\n",
       "      <td>[-0.024600800169206405, -0.015038358533401953,...</td>\n",
       "      <td>[-0.024600800169206405, -0.015038358533401953,...</td>\n",
       "      <td>True</td>\n",
       "      <td>1.365890e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1579</th>\n",
       "      <td>https://raw.githubusercontent.com/lintool/Grim...</td>\n",
       "      <td>https://github.com/lintool/GrimmerSenatePressR...</td>\n",
       "      <td>19Dec2007Clinton56.txt</td>\n",
       "      <td>raw/Clinton/19Dec2007Clinton56.txt</td>\n",
       "      <td>December 19  2007 Schumer and Clinton Announce...</td>\n",
       "      <td>Clinton</td>\n",
       "      <td>False</td>\n",
       "      <td>[December, 19, 2007, Schumer, and, Clinton, An...</td>\n",
       "      <td>[decemb, schumer, clinton, announc, final, sen...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[-0.04241421435462785, -0.0002473729913446158,...</td>\n",
       "      <td>[-0.04241421435462785, -0.0002473729913446158,...</td>\n",
       "      <td>[-0.04241421435462785, -0.0002473729913446158,...</td>\n",
       "      <td>[-0.04241421435462785, -0.0002473729913446158,...</td>\n",
       "      <td>[-0.04241421435462785, -0.0002473729913446158,...</td>\n",
       "      <td>[-0.04241421435462785, -0.0002473729913446158,...</td>\n",
       "      <td>False</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>425</th>\n",
       "      <td>https://raw.githubusercontent.com/lintool/Grim...</td>\n",
       "      <td>https://github.com/lintool/GrimmerSenatePressR...</td>\n",
       "      <td>26Feb2008Obama142.txt</td>\n",
       "      <td>raw/Obama/26Feb2008Obama142.txt</td>\n",
       "      <td>Durbin  Obama Call on President to Provide ...</td>\n",
       "      <td>Obama</td>\n",
       "      <td>True</td>\n",
       "      <td>[Durbin, Obama, Call, on, President, to, Provi...</td>\n",
       "      <td>[durbin, obama, call, presid, provid, feder, r...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[-0.05397817153371096, -0.16978467318663334, 0...</td>\n",
       "      <td>[-0.05397817153371096, -0.16978467318663334, 0...</td>\n",
       "      <td>[-0.05397817153371096, -0.16978467318663334, 0...</td>\n",
       "      <td>[-0.05397817153371096, -0.16978467318663334, 0...</td>\n",
       "      <td>[-0.05397817153371096, -0.16978467318663334, 0...</td>\n",
       "      <td>[-0.05397817153371096, -0.16978467318663334, 0...</td>\n",
       "      <td>True</td>\n",
       "      <td>2.491900e-18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1195</th>\n",
       "      <td>https://raw.githubusercontent.com/lintool/Grim...</td>\n",
       "      <td>https://github.com/lintool/GrimmerSenatePressR...</td>\n",
       "      <td>15Mar2005Clinton643.txt</td>\n",
       "      <td>raw/Clinton/15Mar2005Clinton643.txt</td>\n",
       "      <td>March 15  2005 Senator Clinton Meets With New ...</td>\n",
       "      <td>Clinton</td>\n",
       "      <td>False</td>\n",
       "      <td>[March, 15, 2005, Senator, Clinton, Meets, Wit...</td>\n",
       "      <td>[march, senat, clinton, meet, new, york, fire,...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[-0.006640162146886454, -0.014038124905587854,...</td>\n",
       "      <td>[-0.006640162146886454, -0.014038124905587854,...</td>\n",
       "      <td>[-0.006640162146886454, -0.014038124905587854,...</td>\n",
       "      <td>[-0.006640162146886454, -0.014038124905587854,...</td>\n",
       "      <td>[-0.006640162146886454, -0.014038124905587854,...</td>\n",
       "      <td>[-0.006640162146886454, -0.014038124905587854,...</td>\n",
       "      <td>False</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1062</th>\n",
       "      <td>https://raw.githubusercontent.com/lintool/Grim...</td>\n",
       "      <td>https://github.com/lintool/GrimmerSenatePressR...</td>\n",
       "      <td>14Apr2005Clinton590.txt</td>\n",
       "      <td>raw/Clinton/14Apr2005Clinton590.txt</td>\n",
       "      <td>April 14  2005 Clinton Calls on President to A...</td>\n",
       "      <td>Clinton</td>\n",
       "      <td>False</td>\n",
       "      <td>[April, 14, 2005, Clinton, Calls, on, Presiden...</td>\n",
       "      <td>[april, clinton, call, presid, act, immedi, co...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[-0.09518818145333592, -0.3673856346876162, 0....</td>\n",
       "      <td>[-0.09518818145333592, -0.3673856346876162, 0....</td>\n",
       "      <td>[-0.09518818145333592, -0.3673856346876162, 0....</td>\n",
       "      <td>[-0.09518818145333592, -0.3673856346876162, 0....</td>\n",
       "      <td>[-0.09518818145333592, -0.3673856346876162, 0....</td>\n",
       "      <td>[-0.09518818145333592, -0.3673856346876162, 0....</td>\n",
       "      <td>False</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>915</th>\n",
       "      <td>https://raw.githubusercontent.com/lintool/Grim...</td>\n",
       "      <td>https://github.com/lintool/GrimmerSenatePressR...</td>\n",
       "      <td>12May2006Clinton513.txt</td>\n",
       "      <td>raw/Clinton/12May2006Clinton513.txt</td>\n",
       "      <td>May 12  2006 Senator Clinton Calls for Extensi...</td>\n",
       "      <td>Clinton</td>\n",
       "      <td>False</td>\n",
       "      <td>[May, 12, 2006, Senator, Clinton, Calls, for, ...</td>\n",
       "      <td>[may, senat, clinton, call, extens, famili, me...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[-0.0027457360971783074, -0.002164731134080617...</td>\n",
       "      <td>[-0.0027457360971783074, -0.002164731134080617...</td>\n",
       "      <td>[-0.0027457360971783074, -0.002164731134080617...</td>\n",
       "      <td>[-0.0027457360971783074, -0.002164731134080617...</td>\n",
       "      <td>[-0.0027457360971783074, -0.002164731134080617...</td>\n",
       "      <td>[-0.0027457360971783074, -0.002164731134080617...</td>\n",
       "      <td>False</td>\n",
       "      <td>8.719610e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>407</th>\n",
       "      <td>https://raw.githubusercontent.com/lintool/Grim...</td>\n",
       "      <td>https://github.com/lintool/GrimmerSenatePressR...</td>\n",
       "      <td>25Jul2007Obama328.txt</td>\n",
       "      <td>raw/Obama/25Jul2007Obama328.txt</td>\n",
       "      <td>Higher Education Bill Includes Obama Propos...</td>\n",
       "      <td>Obama</td>\n",
       "      <td>True</td>\n",
       "      <td>[Higher, Education, Bill, Includes, Obama, Pro...</td>\n",
       "      <td>[higher, educ, bill, includ, obama, propos, im...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[-0.02809197871967216, 0.012865677283402955, -...</td>\n",
       "      <td>[-0.02809197871967216, 0.012865677283402955, -...</td>\n",
       "      <td>[-0.02809197871967216, 0.012865677283402955, -...</td>\n",
       "      <td>[-0.02809197871967216, 0.012865677283402955, -...</td>\n",
       "      <td>[-0.02809197871967216, 0.012865677283402955, -...</td>\n",
       "      <td>[-0.02809197871967216, 0.012865677283402955, -...</td>\n",
       "      <td>True</td>\n",
       "      <td>2.700985e-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>549</th>\n",
       "      <td>https://raw.githubusercontent.com/lintool/Grim...</td>\n",
       "      <td>https://github.com/lintool/GrimmerSenatePressR...</td>\n",
       "      <td>30Nov2005Obama615.txt</td>\n",
       "      <td>raw/Obama/30Nov2005Obama615.txt</td>\n",
       "      <td>Obama  Kerry and Others Introduce Legislati...</td>\n",
       "      <td>Obama</td>\n",
       "      <td>True</td>\n",
       "      <td>[Obama, Kerry, and, Others, Introduce, Legisla...</td>\n",
       "      <td>[obama, kerri, introduc, legisl, honor, rosa, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[-0.013423887415788099, -0.006647977687400191,...</td>\n",
       "      <td>[-0.013423887415788099, -0.006647977687400191,...</td>\n",
       "      <td>[-0.013423887415788099, -0.006647977687400191,...</td>\n",
       "      <td>[-0.013423887415788099, -0.006647977687400191,...</td>\n",
       "      <td>[-0.013423887415788099, -0.006647977687400191,...</td>\n",
       "      <td>[-0.013423887415788099, -0.006647977687400191,...</td>\n",
       "      <td>True</td>\n",
       "      <td>1.833877e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1545</th>\n",
       "      <td>https://raw.githubusercontent.com/lintool/Grim...</td>\n",
       "      <td>https://github.com/lintool/GrimmerSenatePressR...</td>\n",
       "      <td>19Dec2005Clinton26.txt</td>\n",
       "      <td>raw/Clinton/19Dec2005Clinton26.txt</td>\n",
       "      <td>December 19  2005 Schumer  Clinton and Rep  Ti...</td>\n",
       "      <td>Clinton</td>\n",
       "      <td>False</td>\n",
       "      <td>[December, 19, 2005, Schumer, Clinton, and, Re...</td>\n",
       "      <td>[decemb, schumer, clinton, rep, tim, bishop, u...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[-0.020262643863737266, -0.0051037152565361794...</td>\n",
       "      <td>[-0.020262643863737266, -0.0051037152565361794...</td>\n",
       "      <td>[-0.020262643863737266, -0.0051037152565361794...</td>\n",
       "      <td>[-0.020262643863737266, -0.0051037152565361794...</td>\n",
       "      <td>[-0.020262643863737266, -0.0051037152565361794...</td>\n",
       "      <td>[-0.020262643863737266, -0.0051037152565361794...</td>\n",
       "      <td>False</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1144</th>\n",
       "      <td>https://raw.githubusercontent.com/lintool/Grim...</td>\n",
       "      <td>https://github.com/lintool/GrimmerSenatePressR...</td>\n",
       "      <td>14Sep2005Clinton262.txt</td>\n",
       "      <td>raw/Clinton/14Sep2005Clinton262.txt</td>\n",
       "      <td>September 14  2005 Statement of Senator Hillar...</td>\n",
       "      <td>Clinton</td>\n",
       "      <td>False</td>\n",
       "      <td>[September, 14, 2005, Statement, of, Senator, ...</td>\n",
       "      <td>[septemb, statement, senat, hillari, rodham, c...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[-0.016810679451125875, -0.059383345722471, 0....</td>\n",
       "      <td>[-0.016810679451125875, -0.059383345722471, 0....</td>\n",
       "      <td>[-0.016810679451125875, -0.059383345722471, 0....</td>\n",
       "      <td>[-0.016810679451125875, -0.059383345722471, 0....</td>\n",
       "      <td>[-0.016810679451125875, -0.059383345722471, 0....</td>\n",
       "      <td>[-0.016810679451125875, -0.059383345722471, 0....</td>\n",
       "      <td>True</td>\n",
       "      <td>2.876893e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>282</th>\n",
       "      <td>https://raw.githubusercontent.com/lintool/Grim...</td>\n",
       "      <td>https://github.com/lintool/GrimmerSenatePressR...</td>\n",
       "      <td>20May2008Obama74.txt</td>\n",
       "      <td>raw/Obama/20May2008Obama74.txt</td>\n",
       "      <td>Statement of Senator Barack Obama on the Ba...</td>\n",
       "      <td>Obama</td>\n",
       "      <td>True</td>\n",
       "      <td>[Statement, of, Senator, Barack, Obama, on, th...</td>\n",
       "      <td>[statement, senat, barack, obama, bank, commit...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[-0.0212206320929183, -0.003041230551295724, -...</td>\n",
       "      <td>[-0.0212206320929183, -0.003041230551295724, -...</td>\n",
       "      <td>[-0.0212206320929183, -0.003041230551295724, -...</td>\n",
       "      <td>[-0.0212206320929183, -0.003041230551295724, -...</td>\n",
       "      <td>[-0.0212206320929183, -0.003041230551295724, -...</td>\n",
       "      <td>[-0.0212206320929183, -0.003041230551295724, -...</td>\n",
       "      <td>False</td>\n",
       "      <td>9.903673e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1706</th>\n",
       "      <td>https://raw.githubusercontent.com/lintool/Grim...</td>\n",
       "      <td>https://github.com/lintool/GrimmerSenatePressR...</td>\n",
       "      <td>1Sep2005Clinton287.txt</td>\n",
       "      <td>raw/Clinton/1Sep2005Clinton287.txt</td>\n",
       "      <td>September 1  2005 Senator Clinton Joins Local ...</td>\n",
       "      <td>Clinton</td>\n",
       "      <td>False</td>\n",
       "      <td>[September, 1, 2005, Senator, Clinton, Joins, ...</td>\n",
       "      <td>[septemb, senat, clinton, join, local, communi...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[-0.017807772327600523, -0.002420708134022972,...</td>\n",
       "      <td>[-0.017807772327600523, -0.002420708134022972,...</td>\n",
       "      <td>[-0.017807772327600523, -0.002420708134022972,...</td>\n",
       "      <td>[-0.017807772327600523, -0.002420708134022972,...</td>\n",
       "      <td>[-0.017807772327600523, -0.002420708134022972,...</td>\n",
       "      <td>[-0.017807772327600523, -0.002420708134022972,...</td>\n",
       "      <td>False</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1302</th>\n",
       "      <td>https://raw.githubusercontent.com/lintool/Grim...</td>\n",
       "      <td>https://github.com/lintool/GrimmerSenatePressR...</td>\n",
       "      <td>16Mar2005Clinton640.txt</td>\n",
       "      <td>raw/Clinton/16Mar2005Clinton640.txt</td>\n",
       "      <td>March 16  2005 Senator Clinton  Rochester is O...</td>\n",
       "      <td>Clinton</td>\n",
       "      <td>False</td>\n",
       "      <td>[March, 16, 2005, Senator, Clinton, Rochester,...</td>\n",
       "      <td>[march, senat, clinton, rochest, one, nation, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[-0.02579826268085226, -0.0028445919844463383,...</td>\n",
       "      <td>[-0.02579826268085226, -0.0028445919844463383,...</td>\n",
       "      <td>[-0.02579826268085226, -0.0028445919844463383,...</td>\n",
       "      <td>[-0.02579826268085226, -0.0028445919844463383,...</td>\n",
       "      <td>[-0.02579826268085226, -0.0028445919844463383,...</td>\n",
       "      <td>[-0.02579826268085226, -0.0028445919844463383,...</td>\n",
       "      <td>False</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1344</th>\n",
       "      <td>https://raw.githubusercontent.com/lintool/Grim...</td>\n",
       "      <td>https://github.com/lintool/GrimmerSenatePressR...</td>\n",
       "      <td>17Apr2007Clinton906.txt</td>\n",
       "      <td>raw/Clinton/17Apr2007Clinton906.txt</td>\n",
       "      <td>April 17  2007 Remarks by Senator Hillary Rodh...</td>\n",
       "      <td>Clinton</td>\n",
       "      <td>False</td>\n",
       "      <td>[April, 17, 2007, Remarks, by, Senator, Hillar...</td>\n",
       "      <td>[april, remark, senat, hillari, rodham, clinto...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[-0.014312572837852448, -0.013070932778982785,...</td>\n",
       "      <td>[-0.014312572837852448, -0.013070932778982785,...</td>\n",
       "      <td>[-0.014312572837852448, -0.013070932778982785,...</td>\n",
       "      <td>[-0.014312572837852448, -0.013070932778982785,...</td>\n",
       "      <td>[-0.014312572837852448, -0.013070932778982785,...</td>\n",
       "      <td>[-0.014312572837852448, -0.013070932778982785,...</td>\n",
       "      <td>False</td>\n",
       "      <td>9.997411e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1465</th>\n",
       "      <td>https://raw.githubusercontent.com/lintool/Grim...</td>\n",
       "      <td>https://github.com/lintool/GrimmerSenatePressR...</td>\n",
       "      <td>18Jul2007Clinton560.txt</td>\n",
       "      <td>raw/Clinton/18Jul2007Clinton560.txt</td>\n",
       "      <td>July 18  2007 Senator Clinton Calls on Preside...</td>\n",
       "      <td>Clinton</td>\n",
       "      <td>False</td>\n",
       "      <td>[July, 18, 2007, Senator, Clinton, Calls, on, ...</td>\n",
       "      <td>[juli, senat, clinton, call, presidenti, advis...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.014665738270606299, -0.0019626845340002647,...</td>\n",
       "      <td>[0.014665738270606299, -0.0019626845340002647,...</td>\n",
       "      <td>[0.014665738270606299, -0.0019626845340002647,...</td>\n",
       "      <td>[0.014665738270606299, -0.0019626845340002647,...</td>\n",
       "      <td>[0.014665738270606299, -0.0019626845340002647,...</td>\n",
       "      <td>[0.014665738270606299, -0.0019626845340002647,...</td>\n",
       "      <td>False</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>507</th>\n",
       "      <td>https://raw.githubusercontent.com/lintool/Grim...</td>\n",
       "      <td>https://github.com/lintool/GrimmerSenatePressR...</td>\n",
       "      <td>29Mar2007Obama434.txt</td>\n",
       "      <td>raw/Obama/29Mar2007Obama434.txt</td>\n",
       "      <td>Obama Calls for Investigation of Long Term ...</td>\n",
       "      <td>Obama</td>\n",
       "      <td>True</td>\n",
       "      <td>[Obama, Calls, for, Investigation, of, Long, T...</td>\n",
       "      <td>[obama, call, investig, long, term, care, u, s...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.014143828725217163, 0.0015473802850003394, ...</td>\n",
       "      <td>[0.014143828725217163, 0.0015473802850003394, ...</td>\n",
       "      <td>[0.014143828725217163, 0.0015473802850003394, ...</td>\n",
       "      <td>[0.014143828725217163, 0.0015473802850003394, ...</td>\n",
       "      <td>[0.014143828725217163, 0.0015473802850003394, ...</td>\n",
       "      <td>[0.014143828725217163, 0.0015473802850003394, ...</td>\n",
       "      <td>False</td>\n",
       "      <td>8.258770e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>466</th>\n",
       "      <td>https://raw.githubusercontent.com/lintool/Grim...</td>\n",
       "      <td>https://github.com/lintool/GrimmerSenatePressR...</td>\n",
       "      <td>27Sep2007Obama267.txt</td>\n",
       "      <td>raw/Obama/27Sep2007Obama267.txt</td>\n",
       "      <td>Senator Obama Statement on Burma   U S  Sen...</td>\n",
       "      <td>Obama</td>\n",
       "      <td>True</td>\n",
       "      <td>[Senator, Obama, Statement, on, Burma, U, S, S...</td>\n",
       "      <td>[senat, obama, statement, burma, u, senat, bar...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[-0.014673288010184195, 0.00013211844150439763...</td>\n",
       "      <td>[-0.014673288010184195, 0.00013211844150439763...</td>\n",
       "      <td>[-0.014673288010184195, 0.00013211844150439763...</td>\n",
       "      <td>[-0.014673288010184195, 0.00013211844150439763...</td>\n",
       "      <td>[-0.014673288010184195, 0.00013211844150439763...</td>\n",
       "      <td>[-0.014673288010184195, 0.00013211844150439763...</td>\n",
       "      <td>True</td>\n",
       "      <td>9.729868e-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>https://raw.githubusercontent.com/lintool/Grim...</td>\n",
       "      <td>https://github.com/lintool/GrimmerSenatePressR...</td>\n",
       "      <td>10Mar2007Obama453.txt</td>\n",
       "      <td>raw/Obama/10Mar2007Obama453.txt</td>\n",
       "      <td>Senate Leadership Adopts Iraq Legislation w...</td>\n",
       "      <td>Obama</td>\n",
       "      <td>True</td>\n",
       "      <td>[Senate, Leadership, Adopts, Iraq, Legislation...</td>\n",
       "      <td>[senat, leadership, adopt, iraq, legisl, goal,...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[-0.012175966963025501, 0.009053117031795425, ...</td>\n",
       "      <td>[-0.012175966963025501, 0.009053117031795425, ...</td>\n",
       "      <td>[-0.012175966963025501, 0.009053117031795425, ...</td>\n",
       "      <td>[-0.012175966963025501, 0.009053117031795425, ...</td>\n",
       "      <td>[-0.012175966963025501, 0.009053117031795425, ...</td>\n",
       "      <td>[-0.012175966963025501, 0.009053117031795425, ...</td>\n",
       "      <td>True</td>\n",
       "      <td>1.743111e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>817</th>\n",
       "      <td>https://raw.githubusercontent.com/lintool/Grim...</td>\n",
       "      <td>https://github.com/lintool/GrimmerSenatePressR...</td>\n",
       "      <td>11May2005Clinton543.txt</td>\n",
       "      <td>raw/Clinton/11May2005Clinton543.txt</td>\n",
       "      <td>May 11  2005 Senator Clinton Urges Department ...</td>\n",
       "      <td>Clinton</td>\n",
       "      <td>False</td>\n",
       "      <td>[May, 11, 2005, Senator, Clinton, Urges, Depar...</td>\n",
       "      <td>[may, senat, clinton, urg, depart, veteran, af...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.46137671368544875, 0.039784337998372735, 0....</td>\n",
       "      <td>[0.46137671368544875, 0.039784337998372735, 0....</td>\n",
       "      <td>[0.46137671368544875, 0.039784337998372735, 0....</td>\n",
       "      <td>[0.46137671368544875, 0.039784337998372735, 0....</td>\n",
       "      <td>[0.46137671368544875, 0.039784337998372735, 0....</td>\n",
       "      <td>[0.46137671368544875, 0.039784337998372735, 0....</td>\n",
       "      <td>False</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>253</th>\n",
       "      <td>https://raw.githubusercontent.com/lintool/Grim...</td>\n",
       "      <td>https://github.com/lintool/GrimmerSenatePressR...</td>\n",
       "      <td>1Mar2007Obama460.txt</td>\n",
       "      <td>raw/Obama/1Mar2007Obama460.txt</td>\n",
       "      <td>Obama  McCaskill Introduce Legislation To I...</td>\n",
       "      <td>Obama</td>\n",
       "      <td>True</td>\n",
       "      <td>[Obama, McCaskill, Introduce, Legislation, To,...</td>\n",
       "      <td>[obama, mccaskil, introduc, legisl, improv, mi...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.16397178587832162, -0.015961727903859482, -...</td>\n",
       "      <td>[0.16397178587832162, -0.015961727903859482, -...</td>\n",
       "      <td>[0.16397178587832162, -0.015961727903859482, -...</td>\n",
       "      <td>[0.16397178587832162, -0.015961727903859482, -...</td>\n",
       "      <td>[0.16397178587832162, -0.015961727903859482, -...</td>\n",
       "      <td>[0.16397178587832162, -0.015961727903859482, -...</td>\n",
       "      <td>True</td>\n",
       "      <td>1.018977e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1700</th>\n",
       "      <td>https://raw.githubusercontent.com/lintool/Grim...</td>\n",
       "      <td>https://github.com/lintool/GrimmerSenatePressR...</td>\n",
       "      <td>1Oct2007Clinton289.txt</td>\n",
       "      <td>raw/Clinton/1Oct2007Clinton289.txt</td>\n",
       "      <td>October 1  2007 Senator Clinton Welcomes Senat...</td>\n",
       "      <td>Clinton</td>\n",
       "      <td>False</td>\n",
       "      <td>[October, 1, 2007, Senator, Clinton, Welcomes,...</td>\n",
       "      <td>[octob, senat, clinton, welcom, senat, approv,...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.002255495814047539, -0.008784137429419017, ...</td>\n",
       "      <td>[0.002255495814047539, -0.008784137429419017, ...</td>\n",
       "      <td>[0.002255495814047539, -0.008784137429419017, ...</td>\n",
       "      <td>[0.002255495814047539, -0.008784137429419017, ...</td>\n",
       "      <td>[0.002255495814047539, -0.008784137429419017, ...</td>\n",
       "      <td>[0.002255495814047539, -0.008784137429419017, ...</td>\n",
       "      <td>False</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1253</th>\n",
       "      <td>https://raw.githubusercontent.com/lintool/Grim...</td>\n",
       "      <td>https://github.com/lintool/GrimmerSenatePressR...</td>\n",
       "      <td>16Aug2007Clinton451.txt</td>\n",
       "      <td>raw/Clinton/16Aug2007Clinton451.txt</td>\n",
       "      <td>August 16  2007 Senator Clinton Welcomes Appal...</td>\n",
       "      <td>Clinton</td>\n",
       "      <td>False</td>\n",
       "      <td>[August, 16, 2007, Senator, Clinton, Welcomes,...</td>\n",
       "      <td>[august, senat, clinton, welcom, appalachian, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[-0.023559569763000804, -0.01235284905552529, ...</td>\n",
       "      <td>[-0.023559569763000804, -0.01235284905552529, ...</td>\n",
       "      <td>[-0.023559569763000804, -0.01235284905552529, ...</td>\n",
       "      <td>[-0.023559569763000804, -0.01235284905552529, ...</td>\n",
       "      <td>[-0.023559569763000804, -0.01235284905552529, ...</td>\n",
       "      <td>[-0.023559569763000804, -0.01235284905552529, ...</td>\n",
       "      <td>False</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1163</th>\n",
       "      <td>https://raw.githubusercontent.com/lintool/Grim...</td>\n",
       "      <td>https://github.com/lintool/GrimmerSenatePressR...</td>\n",
       "      <td>15Dec2007Clinton89.txt</td>\n",
       "      <td>raw/Clinton/15Dec2007Clinton89.txt</td>\n",
       "      <td>December 15  2007 Statement of Senator Hillary...</td>\n",
       "      <td>Clinton</td>\n",
       "      <td>False</td>\n",
       "      <td>[December, 15, 2007, Statement, of, Senator, H...</td>\n",
       "      <td>[decemb, statement, senat, hillari, rodham, cl...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[-0.009998919994011939, -0.007075552825230429,...</td>\n",
       "      <td>[-0.009998919994011939, -0.007075552825230429,...</td>\n",
       "      <td>[-0.009998919994011939, -0.007075552825230429,...</td>\n",
       "      <td>[-0.009998919994011939, -0.007075552825230429,...</td>\n",
       "      <td>[-0.009998919994011939, -0.007075552825230429,...</td>\n",
       "      <td>[-0.009998919994011939, -0.007075552825230429,...</td>\n",
       "      <td>False</td>\n",
       "      <td>9.014764e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>553</th>\n",
       "      <td>https://raw.githubusercontent.com/lintool/Grim...</td>\n",
       "      <td>https://github.com/lintool/GrimmerSenatePressR...</td>\n",
       "      <td>30Oct2007Obama228.txt</td>\n",
       "      <td>raw/Obama/30Oct2007Obama228.txt</td>\n",
       "      <td>Obama  Durbin Ask Blackwater for Answers on...</td>\n",
       "      <td>Obama</td>\n",
       "      <td>True</td>\n",
       "      <td>[Obama, Durbin, Ask, Blackwater, for, Answers,...</td>\n",
       "      <td>[obama, durbin, ask, blackwat, answer, classif...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[-0.0002101883800903801, -0.016828614679955084...</td>\n",
       "      <td>[-0.0002101883800903801, -0.016828614679955084...</td>\n",
       "      <td>[-0.0002101883800903801, -0.016828614679955084...</td>\n",
       "      <td>[-0.0002101883800903801, -0.016828614679955084...</td>\n",
       "      <td>[-0.0002101883800903801, -0.016828614679955084...</td>\n",
       "      <td>[-0.0002101883800903801, -0.016828614679955084...</td>\n",
       "      <td>True</td>\n",
       "      <td>8.161032e-33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1704</th>\n",
       "      <td>https://raw.githubusercontent.com/lintool/Grim...</td>\n",
       "      <td>https://github.com/lintool/GrimmerSenatePressR...</td>\n",
       "      <td>1Sep2005Clinton285.txt</td>\n",
       "      <td>raw/Clinton/1Sep2005Clinton285.txt</td>\n",
       "      <td>September 1  2005 Senator Clinton Visit Infoto...</td>\n",
       "      <td>Clinton</td>\n",
       "      <td>False</td>\n",
       "      <td>[September, 1, 2005, Senator, Clinton, Visit, ...</td>\n",
       "      <td>[septemb, senat, clinton, visit, infoton, tech...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[-0.014519551865842535, 0.01875107793912781, -...</td>\n",
       "      <td>[-0.014519551865842535, 0.01875107793912781, -...</td>\n",
       "      <td>[-0.014519551865842535, 0.01875107793912781, -...</td>\n",
       "      <td>[-0.014519551865842535, 0.01875107793912781, -...</td>\n",
       "      <td>[-0.014519551865842535, 0.01875107793912781, -...</td>\n",
       "      <td>[-0.014519551865842535, 0.01875107793912781, -...</td>\n",
       "      <td>False</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1410</th>\n",
       "      <td>https://raw.githubusercontent.com/lintool/Grim...</td>\n",
       "      <td>https://github.com/lintool/GrimmerSenatePressR...</td>\n",
       "      <td>17May2005Clinton515.txt</td>\n",
       "      <td>raw/Clinton/17May2005Clinton515.txt</td>\n",
       "      <td>May 17  2005 Senator Clinton Wins Passage of L...</td>\n",
       "      <td>Clinton</td>\n",
       "      <td>False</td>\n",
       "      <td>[May, 17, 2005, Senator, Clinton, Wins, Passag...</td>\n",
       "      <td>[may, senat, clinton, win, passag, legisl, red...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[-0.03521511813184478, 0.03111774044016608, -0...</td>\n",
       "      <td>[-0.03521511813184478, 0.03111774044016608, -0...</td>\n",
       "      <td>[-0.03521511813184478, 0.03111774044016608, -0...</td>\n",
       "      <td>[-0.03521511813184478, 0.03111774044016608, -0...</td>\n",
       "      <td>[-0.03521511813184478, 0.03111774044016608, -0...</td>\n",
       "      <td>[-0.03521511813184478, 0.03111774044016608, -0...</td>\n",
       "      <td>False</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1371</th>\n",
       "      <td>https://raw.githubusercontent.com/lintool/Grim...</td>\n",
       "      <td>https://github.com/lintool/GrimmerSenatePressR...</td>\n",
       "      <td>17Dec2007Clinton86.txt</td>\n",
       "      <td>raw/Clinton/17Dec2007Clinton86.txt</td>\n",
       "      <td>December 17  2007 Senators Sessions  Clinton a...</td>\n",
       "      <td>Clinton</td>\n",
       "      <td>False</td>\n",
       "      <td>[December, 17, 2007, Senators, Sessions, Clint...</td>\n",
       "      <td>[decemb, senat, session, clinton, casey, appla...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0947118074954807, -0.007830705792655664, -0...</td>\n",
       "      <td>[0.0947118074954807, -0.007830705792655664, -0...</td>\n",
       "      <td>[0.0947118074954807, -0.007830705792655664, -0...</td>\n",
       "      <td>[0.0947118074954807, -0.007830705792655664, -0...</td>\n",
       "      <td>[0.0947118074954807, -0.007830705792655664, -0...</td>\n",
       "      <td>[0.0947118074954807, -0.007830705792655664, -0...</td>\n",
       "      <td>False</td>\n",
       "      <td>9.987136e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1527</th>\n",
       "      <td>https://raw.githubusercontent.com/lintool/Grim...</td>\n",
       "      <td>https://github.com/lintool/GrimmerSenatePressR...</td>\n",
       "      <td>19Apr2005Clinton585.txt</td>\n",
       "      <td>raw/Clinton/19Apr2005Clinton585.txt</td>\n",
       "      <td>April 19  2005 Senator Clinton Calls on Admini...</td>\n",
       "      <td>Clinton</td>\n",
       "      <td>False</td>\n",
       "      <td>[April, 19, 2005, Senator, Clinton, Calls, on,...</td>\n",
       "      <td>[april, senat, clinton, call, administr, overt...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[-0.02526805737695367, 0.024640694334861716, -...</td>\n",
       "      <td>[-0.02526805737695367, 0.024640694334861716, -...</td>\n",
       "      <td>[-0.02526805737695367, 0.024640694334861716, -...</td>\n",
       "      <td>[-0.02526805737695367, 0.024640694334861716, -...</td>\n",
       "      <td>[-0.02526805737695367, 0.024640694334861716, -...</td>\n",
       "      <td>[-0.02526805737695367, 0.024640694334861716, -...</td>\n",
       "      <td>False</td>\n",
       "      <td>9.927159e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>525</th>\n",
       "      <td>https://raw.githubusercontent.com/lintool/Grim...</td>\n",
       "      <td>https://github.com/lintool/GrimmerSenatePressR...</td>\n",
       "      <td>2Feb2006Obama594.txt</td>\n",
       "      <td>raw/Obama/2Feb2006Obama594.txt</td>\n",
       "      <td>Lugar and Obama Press Administration to Sec...</td>\n",
       "      <td>Obama</td>\n",
       "      <td>True</td>\n",
       "      <td>[Lugar, and, Obama, Press, Administration, to,...</td>\n",
       "      <td>[lugar, obama, press, administr, secur, loos, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[-0.038587235297869706, 0.06103548866055492, -...</td>\n",
       "      <td>[-0.038587235297869706, 0.06103548866055492, -...</td>\n",
       "      <td>[-0.038587235297869706, 0.06103548866055492, -...</td>\n",
       "      <td>[-0.038587235297869706, 0.06103548866055492, -...</td>\n",
       "      <td>[-0.038587235297869706, 0.06103548866055492, -...</td>\n",
       "      <td>[-0.038587235297869706, 0.06103548866055492, -...</td>\n",
       "      <td>True</td>\n",
       "      <td>1.402399e-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>502</th>\n",
       "      <td>https://raw.githubusercontent.com/lintool/Grim...</td>\n",
       "      <td>https://github.com/lintool/GrimmerSenatePressR...</td>\n",
       "      <td>29Jun2005Obama696.txt</td>\n",
       "      <td>raw/Obama/29Jun2005Obama696.txt</td>\n",
       "      <td>Transcript of Veterans Town Hall Meeting wi...</td>\n",
       "      <td>Obama</td>\n",
       "      <td>True</td>\n",
       "      <td>[Transcript, of, Veterans, Town, Hall, Meeting...</td>\n",
       "      <td>[transcript, veteran, town, hall, meet, secret...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.011650345355512707, 0.0, 0.0...</td>\n",
       "      <td>[0.3046773854546109, 0.018421263475607696, 0.0...</td>\n",
       "      <td>[0.3046773854546109, 0.018421263475607696, 0.0...</td>\n",
       "      <td>[0.3046773854546109, 0.018421263475607696, 0.0...</td>\n",
       "      <td>[0.3046773854546109, 0.018421263475607696, 0.0...</td>\n",
       "      <td>[0.3046773854546109, 0.018421263475607696, 0.0...</td>\n",
       "      <td>[0.3046773854546109, 0.018421263475607696, 0.0...</td>\n",
       "      <td>True</td>\n",
       "      <td>1.849914e-23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>336</th>\n",
       "      <td>https://raw.githubusercontent.com/lintool/Grim...</td>\n",
       "      <td>https://github.com/lintool/GrimmerSenatePressR...</td>\n",
       "      <td>23Aug2007Obama298.txt</td>\n",
       "      <td>raw/Obama/23Aug2007Obama298.txt</td>\n",
       "      <td>Obama Statement on the Release of Haleh Esf...</td>\n",
       "      <td>Obama</td>\n",
       "      <td>True</td>\n",
       "      <td>[Obama, Statement, on, the, Release, of, Haleh...</td>\n",
       "      <td>[obama, statement, releas, haleh, esfandiari, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[-0.009979654612290292, -0.00474076366257926, ...</td>\n",
       "      <td>[-0.009979654612290292, -0.00474076366257926, ...</td>\n",
       "      <td>[-0.009979654612290292, -0.00474076366257926, ...</td>\n",
       "      <td>[-0.009979654612290292, -0.00474076366257926, ...</td>\n",
       "      <td>[-0.009979654612290292, -0.00474076366257926, ...</td>\n",
       "      <td>[-0.009979654612290292, -0.00474076366257926, ...</td>\n",
       "      <td>False</td>\n",
       "      <td>7.239003e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1691</th>\n",
       "      <td>https://raw.githubusercontent.com/lintool/Grim...</td>\n",
       "      <td>https://github.com/lintool/GrimmerSenatePressR...</td>\n",
       "      <td>1May2007Clinton861.txt</td>\n",
       "      <td>raw/Clinton/1May2007Clinton861.txt</td>\n",
       "      <td>May 1  2007 Statement of Senator Hillary Rodha...</td>\n",
       "      <td>Clinton</td>\n",
       "      <td>False</td>\n",
       "      <td>[May, 1, 2007, Statement, of, Senator, Hillary...</td>\n",
       "      <td>[may, statement, senat, hillari, rodham, clint...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[-0.018967019114041393, 0.004851962820685902, ...</td>\n",
       "      <td>[-0.018967019114041393, 0.004851962820685902, ...</td>\n",
       "      <td>[-0.018967019114041393, 0.004851962820685902, ...</td>\n",
       "      <td>[-0.018967019114041393, 0.004851962820685902, ...</td>\n",
       "      <td>[-0.018967019114041393, 0.004851962820685902, ...</td>\n",
       "      <td>[-0.018967019114041393, 0.004851962820685902, ...</td>\n",
       "      <td>True</td>\n",
       "      <td>5.037537e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>https://raw.githubusercontent.com/lintool/Grim...</td>\n",
       "      <td>https://github.com/lintool/GrimmerSenatePressR...</td>\n",
       "      <td>12Oct2007Obama251.txt</td>\n",
       "      <td>raw/Obama/12Oct2007Obama251.txt</td>\n",
       "      <td>Durbin  Obama  Emanuel  Illinois Members As...</td>\n",
       "      <td>Obama</td>\n",
       "      <td>True</td>\n",
       "      <td>[Durbin, Obama, Emanuel, Illinois, Members, As...</td>\n",
       "      <td>[durbin, obama, emanuel, illinoi, member, ask,...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[-0.0332586565540872, -0.02325774360527418, 0....</td>\n",
       "      <td>[-0.0332586565540872, -0.02325774360527418, 0....</td>\n",
       "      <td>[-0.0332586565540872, -0.02325774360527418, 0....</td>\n",
       "      <td>[-0.0332586565540872, -0.02325774360527418, 0....</td>\n",
       "      <td>[-0.0332586565540872, -0.02325774360527418, 0....</td>\n",
       "      <td>[-0.0332586565540872, -0.02325774360527418, 0....</td>\n",
       "      <td>True</td>\n",
       "      <td>2.399951e-28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1620</th>\n",
       "      <td>https://raw.githubusercontent.com/lintool/Grim...</td>\n",
       "      <td>https://github.com/lintool/GrimmerSenatePressR...</td>\n",
       "      <td>19Oct2007Clinton245.txt</td>\n",
       "      <td>raw/Clinton/19Oct2007Clinton245.txt</td>\n",
       "      <td>October 19  2007 Statement of Senator Hillary ...</td>\n",
       "      <td>Clinton</td>\n",
       "      <td>False</td>\n",
       "      <td>[October, 19, 2007, Statement, of, Senator, Hi...</td>\n",
       "      <td>[octob, statement, senat, hillari, rodham, cli...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[-0.012104247231406955, 0.0006829389379369812,...</td>\n",
       "      <td>[-0.012104247231406955, 0.0006829389379369812,...</td>\n",
       "      <td>[-0.012104247231406955, 0.0006829389379369812,...</td>\n",
       "      <td>[-0.012104247231406955, 0.0006829389379369812,...</td>\n",
       "      <td>[-0.012104247231406955, 0.0006829389379369812,...</td>\n",
       "      <td>[-0.012104247231406955, 0.0006829389379369812,...</td>\n",
       "      <td>False</td>\n",
       "      <td>8.981094e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1146</th>\n",
       "      <td>https://raw.githubusercontent.com/lintool/Grim...</td>\n",
       "      <td>https://github.com/lintool/GrimmerSenatePressR...</td>\n",
       "      <td>14Sep2005Clinton264.txt</td>\n",
       "      <td>raw/Clinton/14Sep2005Clinton264.txt</td>\n",
       "      <td>September 14  2005 Key Senate Panel Acts to Ma...</td>\n",
       "      <td>Clinton</td>\n",
       "      <td>False</td>\n",
       "      <td>[September, 14, 2005, Key, Senate, Panel, Acts...</td>\n",
       "      <td>[septemb, key, senat, panel, act, make, colleg...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[-0.03847708773220129, 0.003721180665874216, -...</td>\n",
       "      <td>[-0.03847708773220129, 0.003721180665874216, -...</td>\n",
       "      <td>[-0.03847708773220129, 0.003721180665874216, -...</td>\n",
       "      <td>[-0.03847708773220129, 0.003721180665874216, -...</td>\n",
       "      <td>[-0.03847708773220129, 0.003721180665874216, -...</td>\n",
       "      <td>[-0.03847708773220129, 0.003721180665874216, -...</td>\n",
       "      <td>False</td>\n",
       "      <td>9.999764e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>542</th>\n",
       "      <td>https://raw.githubusercontent.com/lintool/Grim...</td>\n",
       "      <td>https://github.com/lintool/GrimmerSenatePressR...</td>\n",
       "      <td>30Jul2008Obama1.txt</td>\n",
       "      <td>raw/Obama/30Jul2008Obama1.txt</td>\n",
       "      <td>Statement of Senator Barack Obama on the Pr...</td>\n",
       "      <td>Obama</td>\n",
       "      <td>True</td>\n",
       "      <td>[Statement, of, Senator, Barack, Obama, on, th...</td>\n",
       "      <td>[statement, senat, barack, obama, presid, sign...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[-0.031195560040563394, -0.012524476728128283,...</td>\n",
       "      <td>[-0.031195560040563394, -0.012524476728128283,...</td>\n",
       "      <td>[-0.031195560040563394, -0.012524476728128283,...</td>\n",
       "      <td>[-0.031195560040563394, -0.012524476728128283,...</td>\n",
       "      <td>[-0.031195560040563394, -0.012524476728128283,...</td>\n",
       "      <td>[-0.031195560040563394, -0.012524476728128283,...</td>\n",
       "      <td>True</td>\n",
       "      <td>8.797848e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>650</th>\n",
       "      <td>https://raw.githubusercontent.com/lintool/Grim...</td>\n",
       "      <td>https://github.com/lintool/GrimmerSenatePressR...</td>\n",
       "      <td>7Jun2006Obama537.txt</td>\n",
       "      <td>raw/Obama/7Jun2006Obama537.txt</td>\n",
       "      <td>Obama Statement on Senate Passage of Immigr...</td>\n",
       "      <td>Obama</td>\n",
       "      <td>True</td>\n",
       "      <td>[Obama, Statement, on, Senate, Passage, of, Im...</td>\n",
       "      <td>[obama, statement, senat, passag, immigr, refo...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[-0.017650939571225387, 0.014307716101505703, ...</td>\n",
       "      <td>[-0.017650939571225387, 0.014307716101505703, ...</td>\n",
       "      <td>[-0.017650939571225387, 0.014307716101505703, ...</td>\n",
       "      <td>[-0.017650939571225387, 0.014307716101505703, ...</td>\n",
       "      <td>[-0.017650939571225387, 0.014307716101505703, ...</td>\n",
       "      <td>[-0.017650939571225387, 0.014307716101505703, ...</td>\n",
       "      <td>True</td>\n",
       "      <td>4.592486e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>830</th>\n",
       "      <td>https://raw.githubusercontent.com/lintool/Grim...</td>\n",
       "      <td>https://github.com/lintool/GrimmerSenatePressR...</td>\n",
       "      <td>11May2007Clinton821.txt</td>\n",
       "      <td>raw/Clinton/11May2007Clinton821.txt</td>\n",
       "      <td>May 11  2007 Schumer  Clinton Announce Over  2...</td>\n",
       "      <td>Clinton</td>\n",
       "      <td>False</td>\n",
       "      <td>[May, 11, 2007, Schumer, Clinton, Announce, Ov...</td>\n",
       "      <td>[may, schumer, clinton, announc, million, nort...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[-0.05482089815924892, -0.04598969713081243, -...</td>\n",
       "      <td>[-0.05482089815924892, -0.04598969713081243, -...</td>\n",
       "      <td>[-0.05482089815924892, -0.04598969713081243, -...</td>\n",
       "      <td>[-0.05482089815924892, -0.04598969713081243, -...</td>\n",
       "      <td>[-0.05482089815924892, -0.04598969713081243, -...</td>\n",
       "      <td>[-0.05482089815924892, -0.04598969713081243, -...</td>\n",
       "      <td>False</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1532</th>\n",
       "      <td>https://raw.githubusercontent.com/lintool/Grim...</td>\n",
       "      <td>https://github.com/lintool/GrimmerSenatePressR...</td>\n",
       "      <td>19Apr2007Clinton893.txt</td>\n",
       "      <td>raw/Clinton/19Apr2007Clinton893.txt</td>\n",
       "      <td>April 19  2007 Clinton Supports Spitzer Call f...</td>\n",
       "      <td>Clinton</td>\n",
       "      <td>False</td>\n",
       "      <td>[April, 19, 2007, Clinton, Supports, Spitzer, ...</td>\n",
       "      <td>[april, clinton, support, spitzer, call, presi...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[-0.09139537243632438, -0.3198260274409709, 0....</td>\n",
       "      <td>[-0.09139537243632438, -0.3198260274409709, 0....</td>\n",
       "      <td>[-0.09139537243632438, -0.3198260274409709, 0....</td>\n",
       "      <td>[-0.09139537243632438, -0.3198260274409709, 0....</td>\n",
       "      <td>[-0.09139537243632438, -0.3198260274409709, 0....</td>\n",
       "      <td>[-0.09139537243632438, -0.3198260274409709, 0....</td>\n",
       "      <td>False</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>458</th>\n",
       "      <td>https://raw.githubusercontent.com/lintool/Grim...</td>\n",
       "      <td>https://github.com/lintool/GrimmerSenatePressR...</td>\n",
       "      <td>27Mar2007Obama439.txt</td>\n",
       "      <td>raw/Obama/27Mar2007Obama439.txt</td>\n",
       "      <td>Obama  McCaskill Initiative Would Improve T...</td>\n",
       "      <td>Obama</td>\n",
       "      <td>True</td>\n",
       "      <td>[Obama, McCaskill, Initiative, Would, Improve,...</td>\n",
       "      <td>[obama, mccaskil, initi, would, improv, treatm...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.21580042110499428, -0.0019420794918917309, ...</td>\n",
       "      <td>[0.21580042110499428, -0.0019420794918917309, ...</td>\n",
       "      <td>[0.21580042110499428, -0.0019420794918917309, ...</td>\n",
       "      <td>[0.21580042110499428, -0.0019420794918917309, ...</td>\n",
       "      <td>[0.21580042110499428, -0.0019420794918917309, ...</td>\n",
       "      <td>[0.21580042110499428, -0.0019420794918917309, ...</td>\n",
       "      <td>True</td>\n",
       "      <td>1.668651e-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>474</th>\n",
       "      <td>https://raw.githubusercontent.com/lintool/Grim...</td>\n",
       "      <td>https://github.com/lintool/GrimmerSenatePressR...</td>\n",
       "      <td>28Jan2008Obama157.txt</td>\n",
       "      <td>raw/Obama/28Jan2008Obama157.txt</td>\n",
       "      <td>Obama Statement on Ukraine s Commitment to ...</td>\n",
       "      <td>Obama</td>\n",
       "      <td>True</td>\n",
       "      <td>[Obama, Statement, on, Ukraine, s, Commitment,...</td>\n",
       "      <td>[obama, statement, ukrain, commit, join, nato,...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[-0.017090701061230087, -0.00117693627064119, ...</td>\n",
       "      <td>[-0.017090701061230087, -0.00117693627064119, ...</td>\n",
       "      <td>[-0.017090701061230087, -0.00117693627064119, ...</td>\n",
       "      <td>[-0.017090701061230087, -0.00117693627064119, ...</td>\n",
       "      <td>[-0.017090701061230087, -0.00117693627064119, ...</td>\n",
       "      <td>[-0.017090701061230087, -0.00117693627064119, ...</td>\n",
       "      <td>True</td>\n",
       "      <td>1.212965e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1281</th>\n",
       "      <td>https://raw.githubusercontent.com/lintool/Grim...</td>\n",
       "      <td>https://github.com/lintool/GrimmerSenatePressR...</td>\n",
       "      <td>16Jul2007Clinton572.txt</td>\n",
       "      <td>raw/Clinton/16Jul2007Clinton572.txt</td>\n",
       "      <td>July 16  2007 Schumer  Clinton Announce Over  ...</td>\n",
       "      <td>Clinton</td>\n",
       "      <td>False</td>\n",
       "      <td>[July, 16, 2007, Schumer, Clinton, Announce, O...</td>\n",
       "      <td>[juli, schumer, clinton, announc, million, gre...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[-0.05005478983711987, -0.03455922312046451, -...</td>\n",
       "      <td>[-0.05005478983711987, -0.03455922312046451, -...</td>\n",
       "      <td>[-0.05005478983711987, -0.03455922312046451, -...</td>\n",
       "      <td>[-0.05005478983711987, -0.03455922312046451, -...</td>\n",
       "      <td>[-0.05005478983711987, -0.03455922312046451, -...</td>\n",
       "      <td>[-0.05005478983711987, -0.03455922312046451, -...</td>\n",
       "      <td>False</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1524</th>\n",
       "      <td>https://raw.githubusercontent.com/lintool/Grim...</td>\n",
       "      <td>https://github.com/lintool/GrimmerSenatePressR...</td>\n",
       "      <td>18Sep2007Clinton345.txt</td>\n",
       "      <td>raw/Clinton/18Sep2007Clinton345.txt</td>\n",
       "      <td>September 18  2007 Schumer  Clinton Announce K...</td>\n",
       "      <td>Clinton</td>\n",
       "      <td>False</td>\n",
       "      <td>[September, 18, 2007, Schumer, Clinton, Announ...</td>\n",
       "      <td>[septemb, schumer, clinton, announc, key, sena...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[-0.015550899563499448, 0.002554370553224521, ...</td>\n",
       "      <td>[-0.015550899563499448, 0.002554370553224521, ...</td>\n",
       "      <td>[-0.015550899563499448, 0.002554370553224521, ...</td>\n",
       "      <td>[-0.015550899563499448, 0.002554370553224521, ...</td>\n",
       "      <td>[-0.015550899563499448, 0.002554370553224521, ...</td>\n",
       "      <td>[-0.015550899563499448, 0.002554370553224521, ...</td>\n",
       "      <td>False</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>872</th>\n",
       "      <td>https://raw.githubusercontent.com/lintool/Grim...</td>\n",
       "      <td>https://github.com/lintool/GrimmerSenatePressR...</td>\n",
       "      <td>12Jan2007Clinton1140.txt</td>\n",
       "      <td>raw/Clinton/12Jan2007Clinton1140.txt</td>\n",
       "      <td>January 12  2007 Bishop  Schumer  Clinton Urge...</td>\n",
       "      <td>Clinton</td>\n",
       "      <td>False</td>\n",
       "      <td>[January, 12, 2007, Bishop, Schumer, Clinton, ...</td>\n",
       "      <td>[januari, bishop, schumer, clinton, urg, resto...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[-0.022572942019340556, -0.002919042160454751,...</td>\n",
       "      <td>[-0.022572942019340556, -0.002919042160454751,...</td>\n",
       "      <td>[-0.022572942019340556, -0.002919042160454751,...</td>\n",
       "      <td>[-0.022572942019340556, -0.002919042160454751,...</td>\n",
       "      <td>[-0.022572942019340556, -0.002919042160454751,...</td>\n",
       "      <td>[-0.022572942019340556, -0.002919042160454751,...</td>\n",
       "      <td>False</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td>https://raw.githubusercontent.com/lintool/Grim...</td>\n",
       "      <td>https://github.com/lintool/GrimmerSenatePressR...</td>\n",
       "      <td>21Jul2005Obama689.txt</td>\n",
       "      <td>raw/Obama/21Jul2005Obama689.txt</td>\n",
       "      <td>Obama Says Provision in Energy Bill to Doub...</td>\n",
       "      <td>Obama</td>\n",
       "      <td>True</td>\n",
       "      <td>[Obama, Says, Provision, in, Energy, Bill, to,...</td>\n",
       "      <td>[obama, say, provis, energi, bill, doubl, etha...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[-0.11444654649789042, 0.4534310553459028, 0.2...</td>\n",
       "      <td>[-0.11444654649789042, 0.4534310553459028, 0.2...</td>\n",
       "      <td>[-0.11444654649789042, 0.4534310553459028, 0.2...</td>\n",
       "      <td>[-0.11444654649789042, 0.4534310553459028, 0.2...</td>\n",
       "      <td>[-0.11444654649789042, 0.4534310553459028, 0.2...</td>\n",
       "      <td>[-0.11444654649789042, 0.4534310553459028, 0.2...</td>\n",
       "      <td>True</td>\n",
       "      <td>7.344936e-24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>799</th>\n",
       "      <td>https://raw.githubusercontent.com/lintool/Grim...</td>\n",
       "      <td>https://github.com/lintool/GrimmerSenatePressR...</td>\n",
       "      <td>11Jul2005Clinton400.txt</td>\n",
       "      <td>raw/Clinton/11Jul2005Clinton400.txt</td>\n",
       "      <td>July 11  2005 Senator Clinton joins University...</td>\n",
       "      <td>Clinton</td>\n",
       "      <td>False</td>\n",
       "      <td>[July, 11, 2005, Senator, Clinton, joins, Univ...</td>\n",
       "      <td>[juli, senat, clinton, join, univers, rochest,...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[-0.02471783316207382, -0.0014398766337650132,...</td>\n",
       "      <td>[-0.02471783316207382, -0.0014398766337650132,...</td>\n",
       "      <td>[-0.02471783316207382, -0.0014398766337650132,...</td>\n",
       "      <td>[-0.02471783316207382, -0.0014398766337650132,...</td>\n",
       "      <td>[-0.02471783316207382, -0.0014398766337650132,...</td>\n",
       "      <td>[-0.02471783316207382, -0.0014398766337650132,...</td>\n",
       "      <td>False</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1143</th>\n",
       "      <td>https://raw.githubusercontent.com/lintool/Grim...</td>\n",
       "      <td>https://github.com/lintool/GrimmerSenatePressR...</td>\n",
       "      <td>14Sep2005Clinton261.txt</td>\n",
       "      <td>raw/Clinton/14Sep2005Clinton261.txt</td>\n",
       "      <td>September 14  2005 Senator Clinton Highlights ...</td>\n",
       "      <td>Clinton</td>\n",
       "      <td>False</td>\n",
       "      <td>[September, 14, 2005, Senator, Clinton, Highli...</td>\n",
       "      <td>[septemb, senat, clinton, highlight, need, kin...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[-0.013734569272415491, -0.009463771346377903,...</td>\n",
       "      <td>[-0.013734569272415491, -0.009463771346377903,...</td>\n",
       "      <td>[-0.013734569272415491, -0.009463771346377903,...</td>\n",
       "      <td>[-0.013734569272415491, -0.009463771346377903,...</td>\n",
       "      <td>[-0.013734569272415491, -0.009463771346377903,...</td>\n",
       "      <td>[-0.013734569272415491, -0.009463771346377903,...</td>\n",
       "      <td>False</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1217</th>\n",
       "      <td>https://raw.githubusercontent.com/lintool/Grim...</td>\n",
       "      <td>https://github.com/lintool/GrimmerSenatePressR...</td>\n",
       "      <td>15May2007Clinton810.txt</td>\n",
       "      <td>raw/Clinton/15May2007Clinton810.txt</td>\n",
       "      <td>May 15  2007 Clinton  Vitter  King Introduce L...</td>\n",
       "      <td>Clinton</td>\n",
       "      <td>False</td>\n",
       "      <td>[May, 15, 2007, Clinton, Vitter, King, Introdu...</td>\n",
       "      <td>[may, clinton, vitter, king, introduc, legisl,...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.02053822052721931, -0.0036677289814750517, ...</td>\n",
       "      <td>[0.02053822052721931, -0.0036677289814750517, ...</td>\n",
       "      <td>[0.02053822052721931, -0.0036677289814750517, ...</td>\n",
       "      <td>[0.02053822052721931, -0.0036677289814750517, ...</td>\n",
       "      <td>[0.02053822052721931, -0.0036677289814750517, ...</td>\n",
       "      <td>[0.02053822052721931, -0.0036677289814750517, ...</td>\n",
       "      <td>False</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>973</th>\n",
       "      <td>https://raw.githubusercontent.com/lintool/Grim...</td>\n",
       "      <td>https://github.com/lintool/GrimmerSenatePressR...</td>\n",
       "      <td>13Feb2007Clinton1066.txt</td>\n",
       "      <td>raw/Clinton/13Feb2007Clinton1066.txt</td>\n",
       "      <td>February 13  2007 Senators Schumer  Clinton  C...</td>\n",
       "      <td>Clinton</td>\n",
       "      <td>False</td>\n",
       "      <td>[February, 13, 2007, Senators, Schumer, Clinto...</td>\n",
       "      <td>[februari, senat, schumer, clinton, congressma...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[-0.018647713707950125, -0.017676656531202595,...</td>\n",
       "      <td>[-0.018647713707950125, -0.017676656531202595,...</td>\n",
       "      <td>[-0.018647713707950125, -0.017676656531202595,...</td>\n",
       "      <td>[-0.018647713707950125, -0.017676656531202595,...</td>\n",
       "      <td>[-0.018647713707950125, -0.017676656531202595,...</td>\n",
       "      <td>[-0.018647713707950125, -0.017676656531202595,...</td>\n",
       "      <td>False</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1421</th>\n",
       "      <td>https://raw.githubusercontent.com/lintool/Grim...</td>\n",
       "      <td>https://github.com/lintool/GrimmerSenatePressR...</td>\n",
       "      <td>17Nov2005Clinton83.txt</td>\n",
       "      <td>raw/Clinton/17Nov2005Clinton83.txt</td>\n",
       "      <td>November 17  2005 Senator Clinton Calls Upon H...</td>\n",
       "      <td>Clinton</td>\n",
       "      <td>False</td>\n",
       "      <td>[November, 17, 2005, Senator, Clinton, Calls, ...</td>\n",
       "      <td>[novemb, senat, clinton, call, upon, hhs, secr...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[-0.010439703187889731, 0.0014198570632492247,...</td>\n",
       "      <td>[-0.010439703187889731, 0.0014198570632492247,...</td>\n",
       "      <td>[-0.010439703187889731, 0.0014198570632492247,...</td>\n",
       "      <td>[-0.010439703187889731, 0.0014198570632492247,...</td>\n",
       "      <td>[-0.010439703187889731, 0.0014198570632492247,...</td>\n",
       "      <td>[-0.010439703187889731, 0.0014198570632492247,...</td>\n",
       "      <td>False</td>\n",
       "      <td>9.999993e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210</th>\n",
       "      <td>https://raw.githubusercontent.com/lintool/Grim...</td>\n",
       "      <td>https://github.com/lintool/GrimmerSenatePressR...</td>\n",
       "      <td>18Nov2005Obama617.txt</td>\n",
       "      <td>raw/Obama/18Nov2005Obama617.txt</td>\n",
       "      <td>Avian Flu Press Conference   U S  Senator B...</td>\n",
       "      <td>Obama</td>\n",
       "      <td>True</td>\n",
       "      <td>[Avian, Flu, Press, Conference, U, S, Senator,...</td>\n",
       "      <td>[avian, flu, press, confer, u, senat, barack, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[-0.013435336440775684, -0.012017329783956183,...</td>\n",
       "      <td>[-0.013435336440775684, -0.012017329783956183,...</td>\n",
       "      <td>[-0.013435336440775684, -0.012017329783956183,...</td>\n",
       "      <td>[-0.013435336440775684, -0.012017329783956183,...</td>\n",
       "      <td>[-0.013435336440775684, -0.012017329783956183,...</td>\n",
       "      <td>[-0.013435336440775684, -0.012017329783956183,...</td>\n",
       "      <td>True</td>\n",
       "      <td>1.702711e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>944</th>\n",
       "      <td>https://raw.githubusercontent.com/lintool/Grim...</td>\n",
       "      <td>https://github.com/lintool/GrimmerSenatePressR...</td>\n",
       "      <td>12Sep2007Clinton371.txt</td>\n",
       "      <td>raw/Clinton/12Sep2007Clinton371.txt</td>\n",
       "      <td>September 12  2007 Senator Clinton Calls on Fe...</td>\n",
       "      <td>Clinton</td>\n",
       "      <td>False</td>\n",
       "      <td>[September, 12, 2007, Senator, Clinton, Calls,...</td>\n",
       "      <td>[septemb, senat, clinton, call, fed, provid, f...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[-0.03384943157932835, 0.00015894231348201235,...</td>\n",
       "      <td>[-0.03384943157932835, 0.00015894231348201235,...</td>\n",
       "      <td>[-0.03384943157932835, 0.00015894231348201235,...</td>\n",
       "      <td>[-0.03384943157932835, 0.00015894231348201235,...</td>\n",
       "      <td>[-0.03384943157932835, 0.00015894231348201235,...</td>\n",
       "      <td>[-0.03384943157932835, 0.00015894231348201235,...</td>\n",
       "      <td>False</td>\n",
       "      <td>9.999978e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207</th>\n",
       "      <td>https://raw.githubusercontent.com/lintool/Grim...</td>\n",
       "      <td>https://github.com/lintool/GrimmerSenatePressR...</td>\n",
       "      <td>18Jun2008Obama48.txt</td>\n",
       "      <td>raw/Obama/18Jun2008Obama48.txt</td>\n",
       "      <td>In Wake of Damaging Floods  Durbin and Obam...</td>\n",
       "      <td>Obama</td>\n",
       "      <td>True</td>\n",
       "      <td>[In, Wake, of, Damaging, Floods, Durbin, and, ...</td>\n",
       "      <td>[wake, damag, flood, durbin, obama, ask, meet,...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[-0.08153266251523882, -0.21241908475516857, 0...</td>\n",
       "      <td>[-0.08153266251523882, -0.21241908475516857, 0...</td>\n",
       "      <td>[-0.08153266251523882, -0.21241908475516857, 0...</td>\n",
       "      <td>[-0.08153266251523882, -0.21241908475516857, 0...</td>\n",
       "      <td>[-0.08153266251523882, -0.21241908475516857, 0...</td>\n",
       "      <td>[-0.08153266251523882, -0.21241908475516857, 0...</td>\n",
       "      <td>True</td>\n",
       "      <td>2.119809e-24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202</th>\n",
       "      <td>https://raw.githubusercontent.com/lintool/Grim...</td>\n",
       "      <td>https://github.com/lintool/GrimmerSenatePressR...</td>\n",
       "      <td>18Dec2007Obama176.txt</td>\n",
       "      <td>raw/Obama/18Dec2007Obama176.txt</td>\n",
       "      <td>Obama Calls on President to Protect Afforda...</td>\n",
       "      <td>Obama</td>\n",
       "      <td>True</td>\n",
       "      <td>[Obama, Calls, on, President, to, Protect, Aff...</td>\n",
       "      <td>[obama, call, presid, protect, afford, hous, n...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[-0.019599345317812867, -0.04759847451436449, ...</td>\n",
       "      <td>[-0.019599345317812867, -0.04759847451436449, ...</td>\n",
       "      <td>[-0.019599345317812867, -0.04759847451436449, ...</td>\n",
       "      <td>[-0.019599345317812867, -0.04759847451436449, ...</td>\n",
       "      <td>[-0.019599345317812867, -0.04759847451436449, ...</td>\n",
       "      <td>[-0.019599345317812867, -0.04759847451436449, ...</td>\n",
       "      <td>False</td>\n",
       "      <td>9.603557e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1198</th>\n",
       "      <td>https://raw.githubusercontent.com/lintool/Grim...</td>\n",
       "      <td>https://github.com/lintool/GrimmerSenatePressR...</td>\n",
       "      <td>15Mar2006Clinton601.txt</td>\n",
       "      <td>raw/Clinton/15Mar2006Clinton601.txt</td>\n",
       "      <td>March 15  2006 Statement by Senators Hillary R...</td>\n",
       "      <td>Clinton</td>\n",
       "      <td>False</td>\n",
       "      <td>[March, 15, 2006, Statement, by, Senators, Hil...</td>\n",
       "      <td>[march, statement, senat, hillari, rodham, cli...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[-0.001495798894543893, 0.0033588436419674053,...</td>\n",
       "      <td>[-0.001495798894543893, 0.0033588436419674053,...</td>\n",
       "      <td>[-0.001495798894543893, 0.0033588436419674053,...</td>\n",
       "      <td>[-0.001495798894543893, 0.0033588436419674053,...</td>\n",
       "      <td>[-0.001495798894543893, 0.0033588436419674053,...</td>\n",
       "      <td>[-0.001495798894543893, 0.0033588436419674053,...</td>\n",
       "      <td>False</td>\n",
       "      <td>9.999999e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>341</th>\n",
       "      <td>https://raw.githubusercontent.com/lintool/Grim...</td>\n",
       "      <td>https://github.com/lintool/GrimmerSenatePressR...</td>\n",
       "      <td>23Jul2007Obama331.txt</td>\n",
       "      <td>raw/Obama/23Jul2007Obama331.txt</td>\n",
       "      <td>Kennedy  Specter  Obama  Senators Work to O...</td>\n",
       "      <td>Obama</td>\n",
       "      <td>True</td>\n",
       "      <td>[Kennedy, Specter, Obama, Senators, Work, to, ...</td>\n",
       "      <td>[kennedi, specter, obama, senat, work, overtur...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.009080664541228628, 0.0013374349493499261, ...</td>\n",
       "      <td>[0.009080664541228628, 0.0013374349493499261, ...</td>\n",
       "      <td>[0.009080664541228628, 0.0013374349493499261, ...</td>\n",
       "      <td>[0.009080664541228628, 0.0013374349493499261, ...</td>\n",
       "      <td>[0.009080664541228628, 0.0013374349493499261, ...</td>\n",
       "      <td>[0.009080664541228628, 0.0013374349493499261, ...</td>\n",
       "      <td>True</td>\n",
       "      <td>7.707015e-20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>811</th>\n",
       "      <td>https://raw.githubusercontent.com/lintool/Grim...</td>\n",
       "      <td>https://github.com/lintool/GrimmerSenatePressR...</td>\n",
       "      <td>11Jun2007Clinton709.txt</td>\n",
       "      <td>raw/Clinton/11Jun2007Clinton709.txt</td>\n",
       "      <td>June 11  2007 Statement of Senator Hillary Rod...</td>\n",
       "      <td>Clinton</td>\n",
       "      <td>False</td>\n",
       "      <td>[June, 11, 2007, Statement, of, Senator, Hilla...</td>\n",
       "      <td>[june, statement, senat, hillari, rodham, clin...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[-0.012132330684702805, -0.00476493024990628, ...</td>\n",
       "      <td>[-0.012132330684702805, -0.00476493024990628, ...</td>\n",
       "      <td>[-0.012132330684702805, -0.00476493024990628, ...</td>\n",
       "      <td>[-0.012132330684702805, -0.00476493024990628, ...</td>\n",
       "      <td>[-0.012132330684702805, -0.00476493024990628, ...</td>\n",
       "      <td>[-0.012132330684702805, -0.00476493024990628, ...</td>\n",
       "      <td>True</td>\n",
       "      <td>7.557316e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>https://raw.githubusercontent.com/lintool/Grim...</td>\n",
       "      <td>https://github.com/lintool/GrimmerSenatePressR...</td>\n",
       "      <td>13Dec2006Obama476.txt</td>\n",
       "      <td>raw/Obama/13Dec2006Obama476.txt</td>\n",
       "      <td>Lugar Obama Bill to Keep Weapons Out of Ter...</td>\n",
       "      <td>Obama</td>\n",
       "      <td>True</td>\n",
       "      <td>[Lugar, Obama, Bill, to, Keep, Weapons, Out, o...</td>\n",
       "      <td>[lugar, obama, bill, keep, weapon, terrorist, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[-0.044816001172814854, 0.07450780654411406, -...</td>\n",
       "      <td>[-0.044816001172814854, 0.07450780654411406, -...</td>\n",
       "      <td>[-0.044816001172814854, 0.07450780654411406, -...</td>\n",
       "      <td>[-0.044816001172814854, 0.07450780654411406, -...</td>\n",
       "      <td>[-0.044816001172814854, 0.07450780654411406, -...</td>\n",
       "      <td>[-0.044816001172814854, 0.07450780654411406, -...</td>\n",
       "      <td>True</td>\n",
       "      <td>1.165340e-44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1455</th>\n",
       "      <td>https://raw.githubusercontent.com/lintool/Grim...</td>\n",
       "      <td>https://github.com/lintool/GrimmerSenatePressR...</td>\n",
       "      <td>18Jan2006Clinton700.txt</td>\n",
       "      <td>raw/Clinton/18Jan2006Clinton700.txt</td>\n",
       "      <td>January 18  2006 Statement of Senator Hillary ...</td>\n",
       "      <td>Clinton</td>\n",
       "      <td>False</td>\n",
       "      <td>[January, 18, 2006, Statement, of, Senator, Hi...</td>\n",
       "      <td>[januari, statement, senat, hillari, rodham, c...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[-0.01144109195581697, -0.004248442151896191, ...</td>\n",
       "      <td>[-0.01144109195581697, -0.004248442151896191, ...</td>\n",
       "      <td>[-0.01144109195581697, -0.004248442151896191, ...</td>\n",
       "      <td>[-0.01144109195581697, -0.004248442151896191, ...</td>\n",
       "      <td>[-0.01144109195581697, -0.004248442151896191, ...</td>\n",
       "      <td>[-0.01144109195581697, -0.004248442151896191, ...</td>\n",
       "      <td>False</td>\n",
       "      <td>9.969507e-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>341 rows √ó 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           download_url  \\\n",
       "965   https://raw.githubusercontent.com/lintool/Grim...   \n",
       "200   https://raw.githubusercontent.com/lintool/Grim...   \n",
       "1579  https://raw.githubusercontent.com/lintool/Grim...   \n",
       "425   https://raw.githubusercontent.com/lintool/Grim...   \n",
       "1195  https://raw.githubusercontent.com/lintool/Grim...   \n",
       "1062  https://raw.githubusercontent.com/lintool/Grim...   \n",
       "915   https://raw.githubusercontent.com/lintool/Grim...   \n",
       "407   https://raw.githubusercontent.com/lintool/Grim...   \n",
       "549   https://raw.githubusercontent.com/lintool/Grim...   \n",
       "1545  https://raw.githubusercontent.com/lintool/Grim...   \n",
       "1144  https://raw.githubusercontent.com/lintool/Grim...   \n",
       "282   https://raw.githubusercontent.com/lintool/Grim...   \n",
       "1706  https://raw.githubusercontent.com/lintool/Grim...   \n",
       "1302  https://raw.githubusercontent.com/lintool/Grim...   \n",
       "1344  https://raw.githubusercontent.com/lintool/Grim...   \n",
       "1465  https://raw.githubusercontent.com/lintool/Grim...   \n",
       "507   https://raw.githubusercontent.com/lintool/Grim...   \n",
       "466   https://raw.githubusercontent.com/lintool/Grim...   \n",
       "12    https://raw.githubusercontent.com/lintool/Grim...   \n",
       "817   https://raw.githubusercontent.com/lintool/Grim...   \n",
       "253   https://raw.githubusercontent.com/lintool/Grim...   \n",
       "1700  https://raw.githubusercontent.com/lintool/Grim...   \n",
       "1253  https://raw.githubusercontent.com/lintool/Grim...   \n",
       "1163  https://raw.githubusercontent.com/lintool/Grim...   \n",
       "553   https://raw.githubusercontent.com/lintool/Grim...   \n",
       "1704  https://raw.githubusercontent.com/lintool/Grim...   \n",
       "1410  https://raw.githubusercontent.com/lintool/Grim...   \n",
       "1371  https://raw.githubusercontent.com/lintool/Grim...   \n",
       "1527  https://raw.githubusercontent.com/lintool/Grim...   \n",
       "525   https://raw.githubusercontent.com/lintool/Grim...   \n",
       "...                                                 ...   \n",
       "502   https://raw.githubusercontent.com/lintool/Grim...   \n",
       "336   https://raw.githubusercontent.com/lintool/Grim...   \n",
       "1691  https://raw.githubusercontent.com/lintool/Grim...   \n",
       "49    https://raw.githubusercontent.com/lintool/Grim...   \n",
       "1620  https://raw.githubusercontent.com/lintool/Grim...   \n",
       "1146  https://raw.githubusercontent.com/lintool/Grim...   \n",
       "542   https://raw.githubusercontent.com/lintool/Grim...   \n",
       "650   https://raw.githubusercontent.com/lintool/Grim...   \n",
       "830   https://raw.githubusercontent.com/lintool/Grim...   \n",
       "1532  https://raw.githubusercontent.com/lintool/Grim...   \n",
       "458   https://raw.githubusercontent.com/lintool/Grim...   \n",
       "474   https://raw.githubusercontent.com/lintool/Grim...   \n",
       "1281  https://raw.githubusercontent.com/lintool/Grim...   \n",
       "1524  https://raw.githubusercontent.com/lintool/Grim...   \n",
       "872   https://raw.githubusercontent.com/lintool/Grim...   \n",
       "295   https://raw.githubusercontent.com/lintool/Grim...   \n",
       "799   https://raw.githubusercontent.com/lintool/Grim...   \n",
       "1143  https://raw.githubusercontent.com/lintool/Grim...   \n",
       "1217  https://raw.githubusercontent.com/lintool/Grim...   \n",
       "973   https://raw.githubusercontent.com/lintool/Grim...   \n",
       "1421  https://raw.githubusercontent.com/lintool/Grim...   \n",
       "210   https://raw.githubusercontent.com/lintool/Grim...   \n",
       "944   https://raw.githubusercontent.com/lintool/Grim...   \n",
       "207   https://raw.githubusercontent.com/lintool/Grim...   \n",
       "202   https://raw.githubusercontent.com/lintool/Grim...   \n",
       "1198  https://raw.githubusercontent.com/lintool/Grim...   \n",
       "341   https://raw.githubusercontent.com/lintool/Grim...   \n",
       "811   https://raw.githubusercontent.com/lintool/Grim...   \n",
       "54    https://raw.githubusercontent.com/lintool/Grim...   \n",
       "1455  https://raw.githubusercontent.com/lintool/Grim...   \n",
       "\n",
       "                                               html_url  \\\n",
       "965   https://github.com/lintool/GrimmerSenatePressR...   \n",
       "200   https://github.com/lintool/GrimmerSenatePressR...   \n",
       "1579  https://github.com/lintool/GrimmerSenatePressR...   \n",
       "425   https://github.com/lintool/GrimmerSenatePressR...   \n",
       "1195  https://github.com/lintool/GrimmerSenatePressR...   \n",
       "1062  https://github.com/lintool/GrimmerSenatePressR...   \n",
       "915   https://github.com/lintool/GrimmerSenatePressR...   \n",
       "407   https://github.com/lintool/GrimmerSenatePressR...   \n",
       "549   https://github.com/lintool/GrimmerSenatePressR...   \n",
       "1545  https://github.com/lintool/GrimmerSenatePressR...   \n",
       "1144  https://github.com/lintool/GrimmerSenatePressR...   \n",
       "282   https://github.com/lintool/GrimmerSenatePressR...   \n",
       "1706  https://github.com/lintool/GrimmerSenatePressR...   \n",
       "1302  https://github.com/lintool/GrimmerSenatePressR...   \n",
       "1344  https://github.com/lintool/GrimmerSenatePressR...   \n",
       "1465  https://github.com/lintool/GrimmerSenatePressR...   \n",
       "507   https://github.com/lintool/GrimmerSenatePressR...   \n",
       "466   https://github.com/lintool/GrimmerSenatePressR...   \n",
       "12    https://github.com/lintool/GrimmerSenatePressR...   \n",
       "817   https://github.com/lintool/GrimmerSenatePressR...   \n",
       "253   https://github.com/lintool/GrimmerSenatePressR...   \n",
       "1700  https://github.com/lintool/GrimmerSenatePressR...   \n",
       "1253  https://github.com/lintool/GrimmerSenatePressR...   \n",
       "1163  https://github.com/lintool/GrimmerSenatePressR...   \n",
       "553   https://github.com/lintool/GrimmerSenatePressR...   \n",
       "1704  https://github.com/lintool/GrimmerSenatePressR...   \n",
       "1410  https://github.com/lintool/GrimmerSenatePressR...   \n",
       "1371  https://github.com/lintool/GrimmerSenatePressR...   \n",
       "1527  https://github.com/lintool/GrimmerSenatePressR...   \n",
       "525   https://github.com/lintool/GrimmerSenatePressR...   \n",
       "...                                                 ...   \n",
       "502   https://github.com/lintool/GrimmerSenatePressR...   \n",
       "336   https://github.com/lintool/GrimmerSenatePressR...   \n",
       "1691  https://github.com/lintool/GrimmerSenatePressR...   \n",
       "49    https://github.com/lintool/GrimmerSenatePressR...   \n",
       "1620  https://github.com/lintool/GrimmerSenatePressR...   \n",
       "1146  https://github.com/lintool/GrimmerSenatePressR...   \n",
       "542   https://github.com/lintool/GrimmerSenatePressR...   \n",
       "650   https://github.com/lintool/GrimmerSenatePressR...   \n",
       "830   https://github.com/lintool/GrimmerSenatePressR...   \n",
       "1532  https://github.com/lintool/GrimmerSenatePressR...   \n",
       "458   https://github.com/lintool/GrimmerSenatePressR...   \n",
       "474   https://github.com/lintool/GrimmerSenatePressR...   \n",
       "1281  https://github.com/lintool/GrimmerSenatePressR...   \n",
       "1524  https://github.com/lintool/GrimmerSenatePressR...   \n",
       "872   https://github.com/lintool/GrimmerSenatePressR...   \n",
       "295   https://github.com/lintool/GrimmerSenatePressR...   \n",
       "799   https://github.com/lintool/GrimmerSenatePressR...   \n",
       "1143  https://github.com/lintool/GrimmerSenatePressR...   \n",
       "1217  https://github.com/lintool/GrimmerSenatePressR...   \n",
       "973   https://github.com/lintool/GrimmerSenatePressR...   \n",
       "1421  https://github.com/lintool/GrimmerSenatePressR...   \n",
       "210   https://github.com/lintool/GrimmerSenatePressR...   \n",
       "944   https://github.com/lintool/GrimmerSenatePressR...   \n",
       "207   https://github.com/lintool/GrimmerSenatePressR...   \n",
       "202   https://github.com/lintool/GrimmerSenatePressR...   \n",
       "1198  https://github.com/lintool/GrimmerSenatePressR...   \n",
       "341   https://github.com/lintool/GrimmerSenatePressR...   \n",
       "811   https://github.com/lintool/GrimmerSenatePressR...   \n",
       "54    https://github.com/lintool/GrimmerSenatePressR...   \n",
       "1455  https://github.com/lintool/GrimmerSenatePressR...   \n",
       "\n",
       "                          name                                  path  \\\n",
       "965    13Dec2007Clinton103.txt   raw/Clinton/13Dec2007Clinton103.txt   \n",
       "200      18Dec2007Obama174.txt       raw/Obama/18Dec2007Obama174.txt   \n",
       "1579    19Dec2007Clinton56.txt    raw/Clinton/19Dec2007Clinton56.txt   \n",
       "425      26Feb2008Obama142.txt       raw/Obama/26Feb2008Obama142.txt   \n",
       "1195   15Mar2005Clinton643.txt   raw/Clinton/15Mar2005Clinton643.txt   \n",
       "1062   14Apr2005Clinton590.txt   raw/Clinton/14Apr2005Clinton590.txt   \n",
       "915    12May2006Clinton513.txt   raw/Clinton/12May2006Clinton513.txt   \n",
       "407      25Jul2007Obama328.txt       raw/Obama/25Jul2007Obama328.txt   \n",
       "549      30Nov2005Obama615.txt       raw/Obama/30Nov2005Obama615.txt   \n",
       "1545    19Dec2005Clinton26.txt    raw/Clinton/19Dec2005Clinton26.txt   \n",
       "1144   14Sep2005Clinton262.txt   raw/Clinton/14Sep2005Clinton262.txt   \n",
       "282       20May2008Obama74.txt        raw/Obama/20May2008Obama74.txt   \n",
       "1706    1Sep2005Clinton287.txt    raw/Clinton/1Sep2005Clinton287.txt   \n",
       "1302   16Mar2005Clinton640.txt   raw/Clinton/16Mar2005Clinton640.txt   \n",
       "1344   17Apr2007Clinton906.txt   raw/Clinton/17Apr2007Clinton906.txt   \n",
       "1465   18Jul2007Clinton560.txt   raw/Clinton/18Jul2007Clinton560.txt   \n",
       "507      29Mar2007Obama434.txt       raw/Obama/29Mar2007Obama434.txt   \n",
       "466      27Sep2007Obama267.txt       raw/Obama/27Sep2007Obama267.txt   \n",
       "12       10Mar2007Obama453.txt       raw/Obama/10Mar2007Obama453.txt   \n",
       "817    11May2005Clinton543.txt   raw/Clinton/11May2005Clinton543.txt   \n",
       "253       1Mar2007Obama460.txt        raw/Obama/1Mar2007Obama460.txt   \n",
       "1700    1Oct2007Clinton289.txt    raw/Clinton/1Oct2007Clinton289.txt   \n",
       "1253   16Aug2007Clinton451.txt   raw/Clinton/16Aug2007Clinton451.txt   \n",
       "1163    15Dec2007Clinton89.txt    raw/Clinton/15Dec2007Clinton89.txt   \n",
       "553      30Oct2007Obama228.txt       raw/Obama/30Oct2007Obama228.txt   \n",
       "1704    1Sep2005Clinton285.txt    raw/Clinton/1Sep2005Clinton285.txt   \n",
       "1410   17May2005Clinton515.txt   raw/Clinton/17May2005Clinton515.txt   \n",
       "1371    17Dec2007Clinton86.txt    raw/Clinton/17Dec2007Clinton86.txt   \n",
       "1527   19Apr2005Clinton585.txt   raw/Clinton/19Apr2005Clinton585.txt   \n",
       "525       2Feb2006Obama594.txt        raw/Obama/2Feb2006Obama594.txt   \n",
       "...                        ...                                   ...   \n",
       "502      29Jun2005Obama696.txt       raw/Obama/29Jun2005Obama696.txt   \n",
       "336      23Aug2007Obama298.txt       raw/Obama/23Aug2007Obama298.txt   \n",
       "1691    1May2007Clinton861.txt    raw/Clinton/1May2007Clinton861.txt   \n",
       "49       12Oct2007Obama251.txt       raw/Obama/12Oct2007Obama251.txt   \n",
       "1620   19Oct2007Clinton245.txt   raw/Clinton/19Oct2007Clinton245.txt   \n",
       "1146   14Sep2005Clinton264.txt   raw/Clinton/14Sep2005Clinton264.txt   \n",
       "542        30Jul2008Obama1.txt         raw/Obama/30Jul2008Obama1.txt   \n",
       "650       7Jun2006Obama537.txt        raw/Obama/7Jun2006Obama537.txt   \n",
       "830    11May2007Clinton821.txt   raw/Clinton/11May2007Clinton821.txt   \n",
       "1532   19Apr2007Clinton893.txt   raw/Clinton/19Apr2007Clinton893.txt   \n",
       "458      27Mar2007Obama439.txt       raw/Obama/27Mar2007Obama439.txt   \n",
       "474      28Jan2008Obama157.txt       raw/Obama/28Jan2008Obama157.txt   \n",
       "1281   16Jul2007Clinton572.txt   raw/Clinton/16Jul2007Clinton572.txt   \n",
       "1524   18Sep2007Clinton345.txt   raw/Clinton/18Sep2007Clinton345.txt   \n",
       "872   12Jan2007Clinton1140.txt  raw/Clinton/12Jan2007Clinton1140.txt   \n",
       "295      21Jul2005Obama689.txt       raw/Obama/21Jul2005Obama689.txt   \n",
       "799    11Jul2005Clinton400.txt   raw/Clinton/11Jul2005Clinton400.txt   \n",
       "1143   14Sep2005Clinton261.txt   raw/Clinton/14Sep2005Clinton261.txt   \n",
       "1217   15May2007Clinton810.txt   raw/Clinton/15May2007Clinton810.txt   \n",
       "973   13Feb2007Clinton1066.txt  raw/Clinton/13Feb2007Clinton1066.txt   \n",
       "1421    17Nov2005Clinton83.txt    raw/Clinton/17Nov2005Clinton83.txt   \n",
       "210      18Nov2005Obama617.txt       raw/Obama/18Nov2005Obama617.txt   \n",
       "944    12Sep2007Clinton371.txt   raw/Clinton/12Sep2007Clinton371.txt   \n",
       "207       18Jun2008Obama48.txt        raw/Obama/18Jun2008Obama48.txt   \n",
       "202      18Dec2007Obama176.txt       raw/Obama/18Dec2007Obama176.txt   \n",
       "1198   15Mar2006Clinton601.txt   raw/Clinton/15Mar2006Clinton601.txt   \n",
       "341      23Jul2007Obama331.txt       raw/Obama/23Jul2007Obama331.txt   \n",
       "811    11Jun2007Clinton709.txt   raw/Clinton/11Jun2007Clinton709.txt   \n",
       "54       13Dec2006Obama476.txt       raw/Obama/13Dec2006Obama476.txt   \n",
       "1455   18Jan2006Clinton700.txt   raw/Clinton/18Jan2006Clinton700.txt   \n",
       "\n",
       "                                                   text targetSenator  \\\n",
       "965   December 13  2007 Statement of Senator Clinton...       Clinton   \n",
       "200      Obama Statement on the Passage of the Omnib...         Obama   \n",
       "1579  December 19  2007 Schumer and Clinton Announce...       Clinton   \n",
       "425      Durbin  Obama Call on President to Provide ...         Obama   \n",
       "1195  March 15  2005 Senator Clinton Meets With New ...       Clinton   \n",
       "1062  April 14  2005 Clinton Calls on President to A...       Clinton   \n",
       "915   May 12  2006 Senator Clinton Calls for Extensi...       Clinton   \n",
       "407      Higher Education Bill Includes Obama Propos...         Obama   \n",
       "549      Obama  Kerry and Others Introduce Legislati...         Obama   \n",
       "1545  December 19  2005 Schumer  Clinton and Rep  Ti...       Clinton   \n",
       "1144  September 14  2005 Statement of Senator Hillar...       Clinton   \n",
       "282      Statement of Senator Barack Obama on the Ba...         Obama   \n",
       "1706  September 1  2005 Senator Clinton Joins Local ...       Clinton   \n",
       "1302  March 16  2005 Senator Clinton  Rochester is O...       Clinton   \n",
       "1344  April 17  2007 Remarks by Senator Hillary Rodh...       Clinton   \n",
       "1465  July 18  2007 Senator Clinton Calls on Preside...       Clinton   \n",
       "507      Obama Calls for Investigation of Long Term ...         Obama   \n",
       "466      Senator Obama Statement on Burma   U S  Sen...         Obama   \n",
       "12       Senate Leadership Adopts Iraq Legislation w...         Obama   \n",
       "817   May 11  2005 Senator Clinton Urges Department ...       Clinton   \n",
       "253      Obama  McCaskill Introduce Legislation To I...         Obama   \n",
       "1700  October 1  2007 Senator Clinton Welcomes Senat...       Clinton   \n",
       "1253  August 16  2007 Senator Clinton Welcomes Appal...       Clinton   \n",
       "1163  December 15  2007 Statement of Senator Hillary...       Clinton   \n",
       "553      Obama  Durbin Ask Blackwater for Answers on...         Obama   \n",
       "1704  September 1  2005 Senator Clinton Visit Infoto...       Clinton   \n",
       "1410  May 17  2005 Senator Clinton Wins Passage of L...       Clinton   \n",
       "1371  December 17  2007 Senators Sessions  Clinton a...       Clinton   \n",
       "1527  April 19  2005 Senator Clinton Calls on Admini...       Clinton   \n",
       "525      Lugar and Obama Press Administration to Sec...         Obama   \n",
       "...                                                 ...           ...   \n",
       "502      Transcript of Veterans Town Hall Meeting wi...         Obama   \n",
       "336      Obama Statement on the Release of Haleh Esf...         Obama   \n",
       "1691  May 1  2007 Statement of Senator Hillary Rodha...       Clinton   \n",
       "49       Durbin  Obama  Emanuel  Illinois Members As...         Obama   \n",
       "1620  October 19  2007 Statement of Senator Hillary ...       Clinton   \n",
       "1146  September 14  2005 Key Senate Panel Acts to Ma...       Clinton   \n",
       "542      Statement of Senator Barack Obama on the Pr...         Obama   \n",
       "650      Obama Statement on Senate Passage of Immigr...         Obama   \n",
       "830   May 11  2007 Schumer  Clinton Announce Over  2...       Clinton   \n",
       "1532  April 19  2007 Clinton Supports Spitzer Call f...       Clinton   \n",
       "458      Obama  McCaskill Initiative Would Improve T...         Obama   \n",
       "474      Obama Statement on Ukraine s Commitment to ...         Obama   \n",
       "1281  July 16  2007 Schumer  Clinton Announce Over  ...       Clinton   \n",
       "1524  September 18  2007 Schumer  Clinton Announce K...       Clinton   \n",
       "872   January 12  2007 Bishop  Schumer  Clinton Urge...       Clinton   \n",
       "295      Obama Says Provision in Energy Bill to Doub...         Obama   \n",
       "799   July 11  2005 Senator Clinton joins University...       Clinton   \n",
       "1143  September 14  2005 Senator Clinton Highlights ...       Clinton   \n",
       "1217  May 15  2007 Clinton  Vitter  King Introduce L...       Clinton   \n",
       "973   February 13  2007 Senators Schumer  Clinton  C...       Clinton   \n",
       "1421  November 17  2005 Senator Clinton Calls Upon H...       Clinton   \n",
       "210      Avian Flu Press Conference   U S  Senator B...         Obama   \n",
       "944   September 12  2007 Senator Clinton Calls on Fe...       Clinton   \n",
       "207      In Wake of Damaging Floods  Durbin and Obam...         Obama   \n",
       "202      Obama Calls on President to Protect Afforda...         Obama   \n",
       "1198  March 15  2006 Statement by Senators Hillary R...       Clinton   \n",
       "341      Kennedy  Specter  Obama  Senators Work to O...         Obama   \n",
       "811   June 11  2007 Statement of Senator Hillary Rod...       Clinton   \n",
       "54       Lugar Obama Bill to Keep Weapons Out of Ter...         Obama   \n",
       "1455  January 18  2006 Statement of Senator Hillary ...       Clinton   \n",
       "\n",
       "      category                                     tokenized_text  \\\n",
       "965      False  [December, 13, 2007, Statement, of, Senator, C...   \n",
       "200       True  [Obama, Statement, on, the, Passage, of, the, ...   \n",
       "1579     False  [December, 19, 2007, Schumer, and, Clinton, An...   \n",
       "425       True  [Durbin, Obama, Call, on, President, to, Provi...   \n",
       "1195     False  [March, 15, 2005, Senator, Clinton, Meets, Wit...   \n",
       "1062     False  [April, 14, 2005, Clinton, Calls, on, Presiden...   \n",
       "915      False  [May, 12, 2006, Senator, Clinton, Calls, for, ...   \n",
       "407       True  [Higher, Education, Bill, Includes, Obama, Pro...   \n",
       "549       True  [Obama, Kerry, and, Others, Introduce, Legisla...   \n",
       "1545     False  [December, 19, 2005, Schumer, Clinton, and, Re...   \n",
       "1144     False  [September, 14, 2005, Statement, of, Senator, ...   \n",
       "282       True  [Statement, of, Senator, Barack, Obama, on, th...   \n",
       "1706     False  [September, 1, 2005, Senator, Clinton, Joins, ...   \n",
       "1302     False  [March, 16, 2005, Senator, Clinton, Rochester,...   \n",
       "1344     False  [April, 17, 2007, Remarks, by, Senator, Hillar...   \n",
       "1465     False  [July, 18, 2007, Senator, Clinton, Calls, on, ...   \n",
       "507       True  [Obama, Calls, for, Investigation, of, Long, T...   \n",
       "466       True  [Senator, Obama, Statement, on, Burma, U, S, S...   \n",
       "12        True  [Senate, Leadership, Adopts, Iraq, Legislation...   \n",
       "817      False  [May, 11, 2005, Senator, Clinton, Urges, Depar...   \n",
       "253       True  [Obama, McCaskill, Introduce, Legislation, To,...   \n",
       "1700     False  [October, 1, 2007, Senator, Clinton, Welcomes,...   \n",
       "1253     False  [August, 16, 2007, Senator, Clinton, Welcomes,...   \n",
       "1163     False  [December, 15, 2007, Statement, of, Senator, H...   \n",
       "553       True  [Obama, Durbin, Ask, Blackwater, for, Answers,...   \n",
       "1704     False  [September, 1, 2005, Senator, Clinton, Visit, ...   \n",
       "1410     False  [May, 17, 2005, Senator, Clinton, Wins, Passag...   \n",
       "1371     False  [December, 17, 2007, Senators, Sessions, Clint...   \n",
       "1527     False  [April, 19, 2005, Senator, Clinton, Calls, on,...   \n",
       "525       True  [Lugar, and, Obama, Press, Administration, to,...   \n",
       "...        ...                                                ...   \n",
       "502       True  [Transcript, of, Veterans, Town, Hall, Meeting...   \n",
       "336       True  [Obama, Statement, on, the, Release, of, Haleh...   \n",
       "1691     False  [May, 1, 2007, Statement, of, Senator, Hillary...   \n",
       "49        True  [Durbin, Obama, Emanuel, Illinois, Members, As...   \n",
       "1620     False  [October, 19, 2007, Statement, of, Senator, Hi...   \n",
       "1146     False  [September, 14, 2005, Key, Senate, Panel, Acts...   \n",
       "542       True  [Statement, of, Senator, Barack, Obama, on, th...   \n",
       "650       True  [Obama, Statement, on, Senate, Passage, of, Im...   \n",
       "830      False  [May, 11, 2007, Schumer, Clinton, Announce, Ov...   \n",
       "1532     False  [April, 19, 2007, Clinton, Supports, Spitzer, ...   \n",
       "458       True  [Obama, McCaskill, Initiative, Would, Improve,...   \n",
       "474       True  [Obama, Statement, on, Ukraine, s, Commitment,...   \n",
       "1281     False  [July, 16, 2007, Schumer, Clinton, Announce, O...   \n",
       "1524     False  [September, 18, 2007, Schumer, Clinton, Announ...   \n",
       "872      False  [January, 12, 2007, Bishop, Schumer, Clinton, ...   \n",
       "295       True  [Obama, Says, Provision, in, Energy, Bill, to,...   \n",
       "799      False  [July, 11, 2005, Senator, Clinton, joins, Univ...   \n",
       "1143     False  [September, 14, 2005, Senator, Clinton, Highli...   \n",
       "1217     False  [May, 15, 2007, Clinton, Vitter, King, Introdu...   \n",
       "973      False  [February, 13, 2007, Senators, Schumer, Clinto...   \n",
       "1421     False  [November, 17, 2005, Senator, Clinton, Calls, ...   \n",
       "210       True  [Avian, Flu, Press, Conference, U, S, Senator,...   \n",
       "944      False  [September, 12, 2007, Senator, Clinton, Calls,...   \n",
       "207       True  [In, Wake, of, Damaging, Floods, Durbin, and, ...   \n",
       "202       True  [Obama, Calls, on, President, to, Protect, Aff...   \n",
       "1198     False  [March, 15, 2006, Statement, by, Senators, Hil...   \n",
       "341       True  [Kennedy, Specter, Obama, Senators, Work, to, ...   \n",
       "811      False  [June, 11, 2007, Statement, of, Senator, Hilla...   \n",
       "54        True  [Lugar, Obama, Bill, to, Keep, Weapons, Out, o...   \n",
       "1455     False  [January, 18, 2006, Statement, of, Senator, Hi...   \n",
       "\n",
       "                                        normalized_text  \\\n",
       "965   [decemb, statement, senat, clinton, passag, en...   \n",
       "200   [obama, statement, passag, omnibus, spend, pac...   \n",
       "1579  [decemb, schumer, clinton, announc, final, sen...   \n",
       "425   [durbin, obama, call, presid, provid, feder, r...   \n",
       "1195  [march, senat, clinton, meet, new, york, fire,...   \n",
       "1062  [april, clinton, call, presid, act, immedi, co...   \n",
       "915   [may, senat, clinton, call, extens, famili, me...   \n",
       "407   [higher, educ, bill, includ, obama, propos, im...   \n",
       "549   [obama, kerri, introduc, legisl, honor, rosa, ...   \n",
       "1545  [decemb, schumer, clinton, rep, tim, bishop, u...   \n",
       "1144  [septemb, statement, senat, hillari, rodham, c...   \n",
       "282   [statement, senat, barack, obama, bank, commit...   \n",
       "1706  [septemb, senat, clinton, join, local, communi...   \n",
       "1302  [march, senat, clinton, rochest, one, nation, ...   \n",
       "1344  [april, remark, senat, hillari, rodham, clinto...   \n",
       "1465  [juli, senat, clinton, call, presidenti, advis...   \n",
       "507   [obama, call, investig, long, term, care, u, s...   \n",
       "466   [senat, obama, statement, burma, u, senat, bar...   \n",
       "12    [senat, leadership, adopt, iraq, legisl, goal,...   \n",
       "817   [may, senat, clinton, urg, depart, veteran, af...   \n",
       "253   [obama, mccaskil, introduc, legisl, improv, mi...   \n",
       "1700  [octob, senat, clinton, welcom, senat, approv,...   \n",
       "1253  [august, senat, clinton, welcom, appalachian, ...   \n",
       "1163  [decemb, statement, senat, hillari, rodham, cl...   \n",
       "553   [obama, durbin, ask, blackwat, answer, classif...   \n",
       "1704  [septemb, senat, clinton, visit, infoton, tech...   \n",
       "1410  [may, senat, clinton, win, passag, legisl, red...   \n",
       "1371  [decemb, senat, session, clinton, casey, appla...   \n",
       "1527  [april, senat, clinton, call, administr, overt...   \n",
       "525   [lugar, obama, press, administr, secur, loos, ...   \n",
       "...                                                 ...   \n",
       "502   [transcript, veteran, town, hall, meet, secret...   \n",
       "336   [obama, statement, releas, haleh, esfandiari, ...   \n",
       "1691  [may, statement, senat, hillari, rodham, clint...   \n",
       "49    [durbin, obama, emanuel, illinoi, member, ask,...   \n",
       "1620  [octob, statement, senat, hillari, rodham, cli...   \n",
       "1146  [septemb, key, senat, panel, act, make, colleg...   \n",
       "542   [statement, senat, barack, obama, presid, sign...   \n",
       "650   [obama, statement, senat, passag, immigr, refo...   \n",
       "830   [may, schumer, clinton, announc, million, nort...   \n",
       "1532  [april, clinton, support, spitzer, call, presi...   \n",
       "458   [obama, mccaskil, initi, would, improv, treatm...   \n",
       "474   [obama, statement, ukrain, commit, join, nato,...   \n",
       "1281  [juli, schumer, clinton, announc, million, gre...   \n",
       "1524  [septemb, schumer, clinton, announc, key, sena...   \n",
       "872   [januari, bishop, schumer, clinton, urg, resto...   \n",
       "295   [obama, say, provis, energi, bill, doubl, etha...   \n",
       "799   [juli, senat, clinton, join, univers, rochest,...   \n",
       "1143  [septemb, senat, clinton, highlight, need, kin...   \n",
       "1217  [may, clinton, vitter, king, introduc, legisl,...   \n",
       "973   [februari, senat, schumer, clinton, congressma...   \n",
       "1421  [novemb, senat, clinton, call, upon, hhs, secr...   \n",
       "210   [avian, flu, press, confer, u, senat, barack, ...   \n",
       "944   [septemb, senat, clinton, call, fed, provid, f...   \n",
       "207   [wake, damag, flood, durbin, obama, ask, meet,...   \n",
       "202   [obama, call, presid, protect, afford, hous, n...   \n",
       "1198  [march, statement, senat, hillari, rodham, cli...   \n",
       "341   [kennedi, specter, obama, senat, work, overtur...   \n",
       "811   [june, statement, senat, hillari, rodham, clin...   \n",
       "54    [lugar, obama, bill, keep, weapon, terrorist, ...   \n",
       "1455  [januari, statement, senat, hillari, rodham, c...   \n",
       "\n",
       "                                                   vect  \\\n",
       "965   [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "200   [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "1579  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "425   [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "1195  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "1062  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "915   [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "407   [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "549   [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "1545  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "1144  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "282   [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "1706  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "1302  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "1344  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "1465  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "507   [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "466   [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "12    [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "817   [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "253   [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "1700  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "1253  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "1163  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "553   [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "1704  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "1410  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "1371  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "1527  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "525   [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "...                                                 ...   \n",
       "502   [0.0, 0.0, 0.0, 0.011650345355512707, 0.0, 0.0...   \n",
       "336   [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "1691  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "49    [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "1620  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "1146  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "542   [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "650   [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "830   [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "1532  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "458   [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "474   [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "1281  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "1524  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "872   [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "295   [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "799   [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "1143  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "1217  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "973   [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "1421  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "210   [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "944   [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "207   [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "202   [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "1198  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "341   [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "811   [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "54    [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "1455  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "\n",
       "                                                    pca  \\\n",
       "965   [-0.07880485792452545, 0.2962065698096317, 0.1...   \n",
       "200   [-0.024600800169206405, -0.015038358533401953,...   \n",
       "1579  [-0.04241421435462785, -0.0002473729913446158,...   \n",
       "425   [-0.05397817153371096, -0.16978467318663334, 0...   \n",
       "1195  [-0.006640162146886454, -0.014038124905587854,...   \n",
       "1062  [-0.09518818145333592, -0.3673856346876162, 0....   \n",
       "915   [-0.0027457360971783074, -0.002164731134080617...   \n",
       "407   [-0.02809197871967216, 0.012865677283402955, -...   \n",
       "549   [-0.013423887415788099, -0.006647977687400191,...   \n",
       "1545  [-0.020262643863737266, -0.0051037152565361794...   \n",
       "1144  [-0.016810679451125875, -0.059383345722471, 0....   \n",
       "282   [-0.0212206320929183, -0.003041230551295724, -...   \n",
       "1706  [-0.017807772327600523, -0.002420708134022972,...   \n",
       "1302  [-0.02579826268085226, -0.0028445919844463383,...   \n",
       "1344  [-0.014312572837852448, -0.013070932778982785,...   \n",
       "1465  [0.014665738270606299, -0.0019626845340002647,...   \n",
       "507   [0.014143828725217163, 0.0015473802850003394, ...   \n",
       "466   [-0.014673288010184195, 0.00013211844150439763...   \n",
       "12    [-0.012175966963025501, 0.009053117031795425, ...   \n",
       "817   [0.46137671368544875, 0.039784337998372735, 0....   \n",
       "253   [0.16397178587832162, -0.015961727903859482, -...   \n",
       "1700  [0.002255495814047539, -0.008784137429419017, ...   \n",
       "1253  [-0.023559569763000804, -0.01235284905552529, ...   \n",
       "1163  [-0.009998919994011939, -0.007075552825230429,...   \n",
       "553   [-0.0002101883800903801, -0.016828614679955084...   \n",
       "1704  [-0.014519551865842535, 0.01875107793912781, -...   \n",
       "1410  [-0.03521511813184478, 0.03111774044016608, -0...   \n",
       "1371  [0.0947118074954807, -0.007830705792655664, -0...   \n",
       "1527  [-0.02526805737695367, 0.024640694334861716, -...   \n",
       "525   [-0.038587235297869706, 0.06103548866055492, -...   \n",
       "...                                                 ...   \n",
       "502   [0.3046773854546109, 0.018421263475607696, 0.0...   \n",
       "336   [-0.009979654612290292, -0.00474076366257926, ...   \n",
       "1691  [-0.018967019114041393, 0.004851962820685902, ...   \n",
       "49    [-0.0332586565540872, -0.02325774360527418, 0....   \n",
       "1620  [-0.012104247231406955, 0.0006829389379369812,...   \n",
       "1146  [-0.03847708773220129, 0.003721180665874216, -...   \n",
       "542   [-0.031195560040563394, -0.012524476728128283,...   \n",
       "650   [-0.017650939571225387, 0.014307716101505703, ...   \n",
       "830   [-0.05482089815924892, -0.04598969713081243, -...   \n",
       "1532  [-0.09139537243632438, -0.3198260274409709, 0....   \n",
       "458   [0.21580042110499428, -0.0019420794918917309, ...   \n",
       "474   [-0.017090701061230087, -0.00117693627064119, ...   \n",
       "1281  [-0.05005478983711987, -0.03455922312046451, -...   \n",
       "1524  [-0.015550899563499448, 0.002554370553224521, ...   \n",
       "872   [-0.022572942019340556, -0.002919042160454751,...   \n",
       "295   [-0.11444654649789042, 0.4534310553459028, 0.2...   \n",
       "799   [-0.02471783316207382, -0.0014398766337650132,...   \n",
       "1143  [-0.013734569272415491, -0.009463771346377903,...   \n",
       "1217  [0.02053822052721931, -0.0036677289814750517, ...   \n",
       "973   [-0.018647713707950125, -0.017676656531202595,...   \n",
       "1421  [-0.010439703187889731, 0.0014198570632492247,...   \n",
       "210   [-0.013435336440775684, -0.012017329783956183,...   \n",
       "944   [-0.03384943157932835, 0.00015894231348201235,...   \n",
       "207   [-0.08153266251523882, -0.21241908475516857, 0...   \n",
       "202   [-0.019599345317812867, -0.04759847451436449, ...   \n",
       "1198  [-0.001495798894543893, 0.0033588436419674053,...   \n",
       "341   [0.009080664541228628, 0.0013374349493499261, ...   \n",
       "811   [-0.012132330684702805, -0.00476493024990628, ...   \n",
       "54    [-0.044816001172814854, 0.07450780654411406, -...   \n",
       "1455  [-0.01144109195581697, -0.004248442151896191, ...   \n",
       "\n",
       "                                         pca_reduced_10  \\\n",
       "965   [-0.07880485792452545, 0.2962065698096317, 0.1...   \n",
       "200   [-0.024600800169206405, -0.015038358533401953,...   \n",
       "1579  [-0.04241421435462785, -0.0002473729913446158,...   \n",
       "425   [-0.05397817153371096, -0.16978467318663334, 0...   \n",
       "1195  [-0.006640162146886454, -0.014038124905587854,...   \n",
       "1062  [-0.09518818145333592, -0.3673856346876162, 0....   \n",
       "915   [-0.0027457360971783074, -0.002164731134080617...   \n",
       "407   [-0.02809197871967216, 0.012865677283402955, -...   \n",
       "549   [-0.013423887415788099, -0.006647977687400191,...   \n",
       "1545  [-0.020262643863737266, -0.0051037152565361794...   \n",
       "1144  [-0.016810679451125875, -0.059383345722471, 0....   \n",
       "282   [-0.0212206320929183, -0.003041230551295724, -...   \n",
       "1706  [-0.017807772327600523, -0.002420708134022972,...   \n",
       "1302  [-0.02579826268085226, -0.0028445919844463383,...   \n",
       "1344  [-0.014312572837852448, -0.013070932778982785,...   \n",
       "1465  [0.014665738270606299, -0.0019626845340002647,...   \n",
       "507   [0.014143828725217163, 0.0015473802850003394, ...   \n",
       "466   [-0.014673288010184195, 0.00013211844150439763...   \n",
       "12    [-0.012175966963025501, 0.009053117031795425, ...   \n",
       "817   [0.46137671368544875, 0.039784337998372735, 0....   \n",
       "253   [0.16397178587832162, -0.015961727903859482, -...   \n",
       "1700  [0.002255495814047539, -0.008784137429419017, ...   \n",
       "1253  [-0.023559569763000804, -0.01235284905552529, ...   \n",
       "1163  [-0.009998919994011939, -0.007075552825230429,...   \n",
       "553   [-0.0002101883800903801, -0.016828614679955084...   \n",
       "1704  [-0.014519551865842535, 0.01875107793912781, -...   \n",
       "1410  [-0.03521511813184478, 0.03111774044016608, -0...   \n",
       "1371  [0.0947118074954807, -0.007830705792655664, -0...   \n",
       "1527  [-0.02526805737695367, 0.024640694334861716, -...   \n",
       "525   [-0.038587235297869706, 0.06103548866055492, -...   \n",
       "...                                                 ...   \n",
       "502   [0.3046773854546109, 0.018421263475607696, 0.0...   \n",
       "336   [-0.009979654612290292, -0.00474076366257926, ...   \n",
       "1691  [-0.018967019114041393, 0.004851962820685902, ...   \n",
       "49    [-0.0332586565540872, -0.02325774360527418, 0....   \n",
       "1620  [-0.012104247231406955, 0.0006829389379369812,...   \n",
       "1146  [-0.03847708773220129, 0.003721180665874216, -...   \n",
       "542   [-0.031195560040563394, -0.012524476728128283,...   \n",
       "650   [-0.017650939571225387, 0.014307716101505703, ...   \n",
       "830   [-0.05482089815924892, -0.04598969713081243, -...   \n",
       "1532  [-0.09139537243632438, -0.3198260274409709, 0....   \n",
       "458   [0.21580042110499428, -0.0019420794918917309, ...   \n",
       "474   [-0.017090701061230087, -0.00117693627064119, ...   \n",
       "1281  [-0.05005478983711987, -0.03455922312046451, -...   \n",
       "1524  [-0.015550899563499448, 0.002554370553224521, ...   \n",
       "872   [-0.022572942019340556, -0.002919042160454751,...   \n",
       "295   [-0.11444654649789042, 0.4534310553459028, 0.2...   \n",
       "799   [-0.02471783316207382, -0.0014398766337650132,...   \n",
       "1143  [-0.013734569272415491, -0.009463771346377903,...   \n",
       "1217  [0.02053822052721931, -0.0036677289814750517, ...   \n",
       "973   [-0.018647713707950125, -0.017676656531202595,...   \n",
       "1421  [-0.010439703187889731, 0.0014198570632492247,...   \n",
       "210   [-0.013435336440775684, -0.012017329783956183,...   \n",
       "944   [-0.03384943157932835, 0.00015894231348201235,...   \n",
       "207   [-0.08153266251523882, -0.21241908475516857, 0...   \n",
       "202   [-0.019599345317812867, -0.04759847451436449, ...   \n",
       "1198  [-0.001495798894543893, 0.0033588436419674053,...   \n",
       "341   [0.009080664541228628, 0.0013374349493499261, ...   \n",
       "811   [-0.012132330684702805, -0.00476493024990628, ...   \n",
       "54    [-0.044816001172814854, 0.07450780654411406, -...   \n",
       "1455  [-0.01144109195581697, -0.004248442151896191, ...   \n",
       "\n",
       "                                         pca_reduced_40  \\\n",
       "965   [-0.07880485792452545, 0.2962065698096317, 0.1...   \n",
       "200   [-0.024600800169206405, -0.015038358533401953,...   \n",
       "1579  [-0.04241421435462785, -0.0002473729913446158,...   \n",
       "425   [-0.05397817153371096, -0.16978467318663334, 0...   \n",
       "1195  [-0.006640162146886454, -0.014038124905587854,...   \n",
       "1062  [-0.09518818145333592, -0.3673856346876162, 0....   \n",
       "915   [-0.0027457360971783074, -0.002164731134080617...   \n",
       "407   [-0.02809197871967216, 0.012865677283402955, -...   \n",
       "549   [-0.013423887415788099, -0.006647977687400191,...   \n",
       "1545  [-0.020262643863737266, -0.0051037152565361794...   \n",
       "1144  [-0.016810679451125875, -0.059383345722471, 0....   \n",
       "282   [-0.0212206320929183, -0.003041230551295724, -...   \n",
       "1706  [-0.017807772327600523, -0.002420708134022972,...   \n",
       "1302  [-0.02579826268085226, -0.0028445919844463383,...   \n",
       "1344  [-0.014312572837852448, -0.013070932778982785,...   \n",
       "1465  [0.014665738270606299, -0.0019626845340002647,...   \n",
       "507   [0.014143828725217163, 0.0015473802850003394, ...   \n",
       "466   [-0.014673288010184195, 0.00013211844150439763...   \n",
       "12    [-0.012175966963025501, 0.009053117031795425, ...   \n",
       "817   [0.46137671368544875, 0.039784337998372735, 0....   \n",
       "253   [0.16397178587832162, -0.015961727903859482, -...   \n",
       "1700  [0.002255495814047539, -0.008784137429419017, ...   \n",
       "1253  [-0.023559569763000804, -0.01235284905552529, ...   \n",
       "1163  [-0.009998919994011939, -0.007075552825230429,...   \n",
       "553   [-0.0002101883800903801, -0.016828614679955084...   \n",
       "1704  [-0.014519551865842535, 0.01875107793912781, -...   \n",
       "1410  [-0.03521511813184478, 0.03111774044016608, -0...   \n",
       "1371  [0.0947118074954807, -0.007830705792655664, -0...   \n",
       "1527  [-0.02526805737695367, 0.024640694334861716, -...   \n",
       "525   [-0.038587235297869706, 0.06103548866055492, -...   \n",
       "...                                                 ...   \n",
       "502   [0.3046773854546109, 0.018421263475607696, 0.0...   \n",
       "336   [-0.009979654612290292, -0.00474076366257926, ...   \n",
       "1691  [-0.018967019114041393, 0.004851962820685902, ...   \n",
       "49    [-0.0332586565540872, -0.02325774360527418, 0....   \n",
       "1620  [-0.012104247231406955, 0.0006829389379369812,...   \n",
       "1146  [-0.03847708773220129, 0.003721180665874216, -...   \n",
       "542   [-0.031195560040563394, -0.012524476728128283,...   \n",
       "650   [-0.017650939571225387, 0.014307716101505703, ...   \n",
       "830   [-0.05482089815924892, -0.04598969713081243, -...   \n",
       "1532  [-0.09139537243632438, -0.3198260274409709, 0....   \n",
       "458   [0.21580042110499428, -0.0019420794918917309, ...   \n",
       "474   [-0.017090701061230087, -0.00117693627064119, ...   \n",
       "1281  [-0.05005478983711987, -0.03455922312046451, -...   \n",
       "1524  [-0.015550899563499448, 0.002554370553224521, ...   \n",
       "872   [-0.022572942019340556, -0.002919042160454751,...   \n",
       "295   [-0.11444654649789042, 0.4534310553459028, 0.2...   \n",
       "799   [-0.02471783316207382, -0.0014398766337650132,...   \n",
       "1143  [-0.013734569272415491, -0.009463771346377903,...   \n",
       "1217  [0.02053822052721931, -0.0036677289814750517, ...   \n",
       "973   [-0.018647713707950125, -0.017676656531202595,...   \n",
       "1421  [-0.010439703187889731, 0.0014198570632492247,...   \n",
       "210   [-0.013435336440775684, -0.012017329783956183,...   \n",
       "944   [-0.03384943157932835, 0.00015894231348201235,...   \n",
       "207   [-0.08153266251523882, -0.21241908475516857, 0...   \n",
       "202   [-0.019599345317812867, -0.04759847451436449, ...   \n",
       "1198  [-0.001495798894543893, 0.0033588436419674053,...   \n",
       "341   [0.009080664541228628, 0.0013374349493499261, ...   \n",
       "811   [-0.012132330684702805, -0.00476493024990628, ...   \n",
       "54    [-0.044816001172814854, 0.07450780654411406, -...   \n",
       "1455  [-0.01144109195581697, -0.004248442151896191, ...   \n",
       "\n",
       "                                        pca_reduced_100  \\\n",
       "965   [-0.07880485792452545, 0.2962065698096317, 0.1...   \n",
       "200   [-0.024600800169206405, -0.015038358533401953,...   \n",
       "1579  [-0.04241421435462785, -0.0002473729913446158,...   \n",
       "425   [-0.05397817153371096, -0.16978467318663334, 0...   \n",
       "1195  [-0.006640162146886454, -0.014038124905587854,...   \n",
       "1062  [-0.09518818145333592, -0.3673856346876162, 0....   \n",
       "915   [-0.0027457360971783074, -0.002164731134080617...   \n",
       "407   [-0.02809197871967216, 0.012865677283402955, -...   \n",
       "549   [-0.013423887415788099, -0.006647977687400191,...   \n",
       "1545  [-0.020262643863737266, -0.0051037152565361794...   \n",
       "1144  [-0.016810679451125875, -0.059383345722471, 0....   \n",
       "282   [-0.0212206320929183, -0.003041230551295724, -...   \n",
       "1706  [-0.017807772327600523, -0.002420708134022972,...   \n",
       "1302  [-0.02579826268085226, -0.0028445919844463383,...   \n",
       "1344  [-0.014312572837852448, -0.013070932778982785,...   \n",
       "1465  [0.014665738270606299, -0.0019626845340002647,...   \n",
       "507   [0.014143828725217163, 0.0015473802850003394, ...   \n",
       "466   [-0.014673288010184195, 0.00013211844150439763...   \n",
       "12    [-0.012175966963025501, 0.009053117031795425, ...   \n",
       "817   [0.46137671368544875, 0.039784337998372735, 0....   \n",
       "253   [0.16397178587832162, -0.015961727903859482, -...   \n",
       "1700  [0.002255495814047539, -0.008784137429419017, ...   \n",
       "1253  [-0.023559569763000804, -0.01235284905552529, ...   \n",
       "1163  [-0.009998919994011939, -0.007075552825230429,...   \n",
       "553   [-0.0002101883800903801, -0.016828614679955084...   \n",
       "1704  [-0.014519551865842535, 0.01875107793912781, -...   \n",
       "1410  [-0.03521511813184478, 0.03111774044016608, -0...   \n",
       "1371  [0.0947118074954807, -0.007830705792655664, -0...   \n",
       "1527  [-0.02526805737695367, 0.024640694334861716, -...   \n",
       "525   [-0.038587235297869706, 0.06103548866055492, -...   \n",
       "...                                                 ...   \n",
       "502   [0.3046773854546109, 0.018421263475607696, 0.0...   \n",
       "336   [-0.009979654612290292, -0.00474076366257926, ...   \n",
       "1691  [-0.018967019114041393, 0.004851962820685902, ...   \n",
       "49    [-0.0332586565540872, -0.02325774360527418, 0....   \n",
       "1620  [-0.012104247231406955, 0.0006829389379369812,...   \n",
       "1146  [-0.03847708773220129, 0.003721180665874216, -...   \n",
       "542   [-0.031195560040563394, -0.012524476728128283,...   \n",
       "650   [-0.017650939571225387, 0.014307716101505703, ...   \n",
       "830   [-0.05482089815924892, -0.04598969713081243, -...   \n",
       "1532  [-0.09139537243632438, -0.3198260274409709, 0....   \n",
       "458   [0.21580042110499428, -0.0019420794918917309, ...   \n",
       "474   [-0.017090701061230087, -0.00117693627064119, ...   \n",
       "1281  [-0.05005478983711987, -0.03455922312046451, -...   \n",
       "1524  [-0.015550899563499448, 0.002554370553224521, ...   \n",
       "872   [-0.022572942019340556, -0.002919042160454751,...   \n",
       "295   [-0.11444654649789042, 0.4534310553459028, 0.2...   \n",
       "799   [-0.02471783316207382, -0.0014398766337650132,...   \n",
       "1143  [-0.013734569272415491, -0.009463771346377903,...   \n",
       "1217  [0.02053822052721931, -0.0036677289814750517, ...   \n",
       "973   [-0.018647713707950125, -0.017676656531202595,...   \n",
       "1421  [-0.010439703187889731, 0.0014198570632492247,...   \n",
       "210   [-0.013435336440775684, -0.012017329783956183,...   \n",
       "944   [-0.03384943157932835, 0.00015894231348201235,...   \n",
       "207   [-0.08153266251523882, -0.21241908475516857, 0...   \n",
       "202   [-0.019599345317812867, -0.04759847451436449, ...   \n",
       "1198  [-0.001495798894543893, 0.0033588436419674053,...   \n",
       "341   [0.009080664541228628, 0.0013374349493499261, ...   \n",
       "811   [-0.012132330684702805, -0.00476493024990628, ...   \n",
       "54    [-0.044816001172814854, 0.07450780654411406, -...   \n",
       "1455  [-0.01144109195581697, -0.004248442151896191, ...   \n",
       "\n",
       "                                        pca_reduced_200  \\\n",
       "965   [-0.07880485792452545, 0.2962065698096317, 0.1...   \n",
       "200   [-0.024600800169206405, -0.015038358533401953,...   \n",
       "1579  [-0.04241421435462785, -0.0002473729913446158,...   \n",
       "425   [-0.05397817153371096, -0.16978467318663334, 0...   \n",
       "1195  [-0.006640162146886454, -0.014038124905587854,...   \n",
       "1062  [-0.09518818145333592, -0.3673856346876162, 0....   \n",
       "915   [-0.0027457360971783074, -0.002164731134080617...   \n",
       "407   [-0.02809197871967216, 0.012865677283402955, -...   \n",
       "549   [-0.013423887415788099, -0.006647977687400191,...   \n",
       "1545  [-0.020262643863737266, -0.0051037152565361794...   \n",
       "1144  [-0.016810679451125875, -0.059383345722471, 0....   \n",
       "282   [-0.0212206320929183, -0.003041230551295724, -...   \n",
       "1706  [-0.017807772327600523, -0.002420708134022972,...   \n",
       "1302  [-0.02579826268085226, -0.0028445919844463383,...   \n",
       "1344  [-0.014312572837852448, -0.013070932778982785,...   \n",
       "1465  [0.014665738270606299, -0.0019626845340002647,...   \n",
       "507   [0.014143828725217163, 0.0015473802850003394, ...   \n",
       "466   [-0.014673288010184195, 0.00013211844150439763...   \n",
       "12    [-0.012175966963025501, 0.009053117031795425, ...   \n",
       "817   [0.46137671368544875, 0.039784337998372735, 0....   \n",
       "253   [0.16397178587832162, -0.015961727903859482, -...   \n",
       "1700  [0.002255495814047539, -0.008784137429419017, ...   \n",
       "1253  [-0.023559569763000804, -0.01235284905552529, ...   \n",
       "1163  [-0.009998919994011939, -0.007075552825230429,...   \n",
       "553   [-0.0002101883800903801, -0.016828614679955084...   \n",
       "1704  [-0.014519551865842535, 0.01875107793912781, -...   \n",
       "1410  [-0.03521511813184478, 0.03111774044016608, -0...   \n",
       "1371  [0.0947118074954807, -0.007830705792655664, -0...   \n",
       "1527  [-0.02526805737695367, 0.024640694334861716, -...   \n",
       "525   [-0.038587235297869706, 0.06103548866055492, -...   \n",
       "...                                                 ...   \n",
       "502   [0.3046773854546109, 0.018421263475607696, 0.0...   \n",
       "336   [-0.009979654612290292, -0.00474076366257926, ...   \n",
       "1691  [-0.018967019114041393, 0.004851962820685902, ...   \n",
       "49    [-0.0332586565540872, -0.02325774360527418, 0....   \n",
       "1620  [-0.012104247231406955, 0.0006829389379369812,...   \n",
       "1146  [-0.03847708773220129, 0.003721180665874216, -...   \n",
       "542   [-0.031195560040563394, -0.012524476728128283,...   \n",
       "650   [-0.017650939571225387, 0.014307716101505703, ...   \n",
       "830   [-0.05482089815924892, -0.04598969713081243, -...   \n",
       "1532  [-0.09139537243632438, -0.3198260274409709, 0....   \n",
       "458   [0.21580042110499428, -0.0019420794918917309, ...   \n",
       "474   [-0.017090701061230087, -0.00117693627064119, ...   \n",
       "1281  [-0.05005478983711987, -0.03455922312046451, -...   \n",
       "1524  [-0.015550899563499448, 0.002554370553224521, ...   \n",
       "872   [-0.022572942019340556, -0.002919042160454751,...   \n",
       "295   [-0.11444654649789042, 0.4534310553459028, 0.2...   \n",
       "799   [-0.02471783316207382, -0.0014398766337650132,...   \n",
       "1143  [-0.013734569272415491, -0.009463771346377903,...   \n",
       "1217  [0.02053822052721931, -0.0036677289814750517, ...   \n",
       "973   [-0.018647713707950125, -0.017676656531202595,...   \n",
       "1421  [-0.010439703187889731, 0.0014198570632492247,...   \n",
       "210   [-0.013435336440775684, -0.012017329783956183,...   \n",
       "944   [-0.03384943157932835, 0.00015894231348201235,...   \n",
       "207   [-0.08153266251523882, -0.21241908475516857, 0...   \n",
       "202   [-0.019599345317812867, -0.04759847451436449, ...   \n",
       "1198  [-0.001495798894543893, 0.0033588436419674053,...   \n",
       "341   [0.009080664541228628, 0.0013374349493499261, ...   \n",
       "811   [-0.012132330684702805, -0.00476493024990628, ...   \n",
       "54    [-0.044816001172814854, 0.07450780654411406, -...   \n",
       "1455  [-0.01144109195581697, -0.004248442151896191, ...   \n",
       "\n",
       "                                        pca_reduced_400  nb_predict  \\\n",
       "965   [-0.07880485792452545, 0.2962065698096317, 0.1...        True   \n",
       "200   [-0.024600800169206405, -0.015038358533401953,...        True   \n",
       "1579  [-0.04241421435462785, -0.0002473729913446158,...       False   \n",
       "425   [-0.05397817153371096, -0.16978467318663334, 0...        True   \n",
       "1195  [-0.006640162146886454, -0.014038124905587854,...       False   \n",
       "1062  [-0.09518818145333592, -0.3673856346876162, 0....       False   \n",
       "915   [-0.0027457360971783074, -0.002164731134080617...       False   \n",
       "407   [-0.02809197871967216, 0.012865677283402955, -...        True   \n",
       "549   [-0.013423887415788099, -0.006647977687400191,...        True   \n",
       "1545  [-0.020262643863737266, -0.0051037152565361794...       False   \n",
       "1144  [-0.016810679451125875, -0.059383345722471, 0....        True   \n",
       "282   [-0.0212206320929183, -0.003041230551295724, -...       False   \n",
       "1706  [-0.017807772327600523, -0.002420708134022972,...       False   \n",
       "1302  [-0.02579826268085226, -0.0028445919844463383,...       False   \n",
       "1344  [-0.014312572837852448, -0.013070932778982785,...       False   \n",
       "1465  [0.014665738270606299, -0.0019626845340002647,...       False   \n",
       "507   [0.014143828725217163, 0.0015473802850003394, ...       False   \n",
       "466   [-0.014673288010184195, 0.00013211844150439763...        True   \n",
       "12    [-0.012175966963025501, 0.009053117031795425, ...        True   \n",
       "817   [0.46137671368544875, 0.039784337998372735, 0....       False   \n",
       "253   [0.16397178587832162, -0.015961727903859482, -...        True   \n",
       "1700  [0.002255495814047539, -0.008784137429419017, ...       False   \n",
       "1253  [-0.023559569763000804, -0.01235284905552529, ...       False   \n",
       "1163  [-0.009998919994011939, -0.007075552825230429,...       False   \n",
       "553   [-0.0002101883800903801, -0.016828614679955084...        True   \n",
       "1704  [-0.014519551865842535, 0.01875107793912781, -...       False   \n",
       "1410  [-0.03521511813184478, 0.03111774044016608, -0...       False   \n",
       "1371  [0.0947118074954807, -0.007830705792655664, -0...       False   \n",
       "1527  [-0.02526805737695367, 0.024640694334861716, -...       False   \n",
       "525   [-0.038587235297869706, 0.06103548866055492, -...        True   \n",
       "...                                                 ...         ...   \n",
       "502   [0.3046773854546109, 0.018421263475607696, 0.0...        True   \n",
       "336   [-0.009979654612290292, -0.00474076366257926, ...       False   \n",
       "1691  [-0.018967019114041393, 0.004851962820685902, ...        True   \n",
       "49    [-0.0332586565540872, -0.02325774360527418, 0....        True   \n",
       "1620  [-0.012104247231406955, 0.0006829389379369812,...       False   \n",
       "1146  [-0.03847708773220129, 0.003721180665874216, -...       False   \n",
       "542   [-0.031195560040563394, -0.012524476728128283,...        True   \n",
       "650   [-0.017650939571225387, 0.014307716101505703, ...        True   \n",
       "830   [-0.05482089815924892, -0.04598969713081243, -...       False   \n",
       "1532  [-0.09139537243632438, -0.3198260274409709, 0....       False   \n",
       "458   [0.21580042110499428, -0.0019420794918917309, ...        True   \n",
       "474   [-0.017090701061230087, -0.00117693627064119, ...        True   \n",
       "1281  [-0.05005478983711987, -0.03455922312046451, -...       False   \n",
       "1524  [-0.015550899563499448, 0.002554370553224521, ...       False   \n",
       "872   [-0.022572942019340556, -0.002919042160454751,...       False   \n",
       "295   [-0.11444654649789042, 0.4534310553459028, 0.2...        True   \n",
       "799   [-0.02471783316207382, -0.0014398766337650132,...       False   \n",
       "1143  [-0.013734569272415491, -0.009463771346377903,...       False   \n",
       "1217  [0.02053822052721931, -0.0036677289814750517, ...       False   \n",
       "973   [-0.018647713707950125, -0.017676656531202595,...       False   \n",
       "1421  [-0.010439703187889731, 0.0014198570632492247,...       False   \n",
       "210   [-0.013435336440775684, -0.012017329783956183,...        True   \n",
       "944   [-0.03384943157932835, 0.00015894231348201235,...       False   \n",
       "207   [-0.08153266251523882, -0.21241908475516857, 0...        True   \n",
       "202   [-0.019599345317812867, -0.04759847451436449, ...       False   \n",
       "1198  [-0.001495798894543893, 0.0033588436419674053,...       False   \n",
       "341   [0.009080664541228628, 0.0013374349493499261, ...        True   \n",
       "811   [-0.012132330684702805, -0.00476493024990628, ...        True   \n",
       "54    [-0.044816001172814854, 0.07450780654411406, -...        True   \n",
       "1455  [-0.01144109195581697, -0.004248442151896191, ...       False   \n",
       "\n",
       "      nb_predict_prob_true  \n",
       "965           8.836614e-08  \n",
       "200           1.365890e-02  \n",
       "1579          1.000000e+00  \n",
       "425           2.491900e-18  \n",
       "1195          1.000000e+00  \n",
       "1062          1.000000e+00  \n",
       "915           8.719610e-01  \n",
       "407           2.700985e-11  \n",
       "549           1.833877e-04  \n",
       "1545          1.000000e+00  \n",
       "1144          2.876893e-01  \n",
       "282           9.903673e-01  \n",
       "1706          1.000000e+00  \n",
       "1302          1.000000e+00  \n",
       "1344          9.997411e-01  \n",
       "1465          1.000000e+00  \n",
       "507           8.258770e-01  \n",
       "466           9.729868e-14  \n",
       "12            1.743111e-04  \n",
       "817           1.000000e+00  \n",
       "253           1.018977e-10  \n",
       "1700          1.000000e+00  \n",
       "1253          1.000000e+00  \n",
       "1163          9.014764e-01  \n",
       "553           8.161032e-33  \n",
       "1704          1.000000e+00  \n",
       "1410          1.000000e+00  \n",
       "1371          9.987136e-01  \n",
       "1527          9.927159e-01  \n",
       "525           1.402399e-22  \n",
       "...                    ...  \n",
       "502           1.849914e-23  \n",
       "336           7.239003e-01  \n",
       "1691          5.037537e-03  \n",
       "49            2.399951e-28  \n",
       "1620          8.981094e-01  \n",
       "1146          9.999764e-01  \n",
       "542           8.797848e-05  \n",
       "650           4.592486e-10  \n",
       "830           1.000000e+00  \n",
       "1532          1.000000e+00  \n",
       "458           1.668651e-13  \n",
       "474           1.212965e-05  \n",
       "1281          1.000000e+00  \n",
       "1524          1.000000e+00  \n",
       "872           1.000000e+00  \n",
       "295           7.344936e-24  \n",
       "799           1.000000e+00  \n",
       "1143          1.000000e+00  \n",
       "1217          1.000000e+00  \n",
       "973           1.000000e+00  \n",
       "1421          9.999993e-01  \n",
       "210           1.702711e-04  \n",
       "944           9.999978e-01  \n",
       "207           2.119809e-24  \n",
       "202           9.603557e-01  \n",
       "1198          9.999999e-01  \n",
       "341           7.707015e-20  \n",
       "811           7.557316e-06  \n",
       "54            1.165340e-44  \n",
       "1455          9.969507e-01  \n",
       "\n",
       "[341 rows x 18 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(test_data_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8590604026845637"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sklearn.metrics.precision_score(test_data_df['nb_predict'], test_data_df['category'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sklearn.metrics.recall_score(test_data_df['nb_predict'], test_data_df['category'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "F1-measure:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sklearn.metrics.f1_score(test_data_df['nb_predict'], test_data_df['category'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at how well our posterior distribution looks relative to the truth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.grid(False)\n",
    "ax.set_frame_on(False)\n",
    "test_data_df[test_data_df['category'].eq(True)]['nb_predict_prob_true'].hist(alpha = 0.5, ax = ax, bins = 10, label = 'True', color = 'red')\n",
    "test_data_df[test_data_df['category'].eq(False)]['nb_predict_prob_true'].hist(alpha = 0.5, ax = ax, bins = 10, label = 'False', color = 'blue')\n",
    "ax.set_xlim((0,1.1))\n",
    "ax.legend(title = \"Is Obama\")\n",
    "ax.set_xlabel('posterior')\n",
    "ax.set_ylabel('counts')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The classification is suprisingly accurate. We can even look at what words are most influential with a bit of simple math:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Top indices\n",
    "trueVals, falseVals = naiveBayes.feature_log_prob_\n",
    "\n",
    "words_dict = {\n",
    "    'Obama' : [],\n",
    "    'Obama_log_prob' : [],\n",
    "    'Clinton' : [],\n",
    "    'Clinton_log_prob' : [],\n",
    "}\n",
    "\n",
    "for i, prob in sorted(enumerate(trueVals), key = lambda x:x[1], reverse=True)[:15]:\n",
    "    words_dict['Obama'].append(TFVectorizer.get_feature_names()[i])\n",
    "    words_dict['Obama_log_prob'].append(prob)\n",
    "\n",
    "for i, prob in sorted(enumerate(falseVals), key = lambda x:x[1], reverse=True)[:15]:\n",
    "    words_dict['Clinton'].append(TFVectorizer.get_feature_names()[i])\n",
    "    words_dict['Clinton_log_prob'].append(prob)\n",
    "    \n",
    "pandas.DataFrame(words_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multinomial Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What if we want to classify our text into one of *many* classes? The multinomial Naive Bayes generating model assumes that document features (e.g., words) are generated by draws from a multinomial distribution (recall this gives the probability to observe a particular pattern of counts across features). \n",
    "\n",
    "Let's use again the dataset we used in week 3, the 20 newsgroup dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "newsgroups = sklearn.datasets.fetch_20newsgroups(data_home = '../data') #Free data to play with: documents from a newsgroup corpus.\n",
    "newsgroups.target_names #Possible categories, i.e., the newsgroups"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can pick specific categories, and pull the relevant training and testing sets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "target_categories = ['talk.religion.misc', 'soc.religion.christian', 'sci.space', 'comp.graphics'] #Can change these of course\n",
    "\n",
    "newsgroupsDF = pandas.DataFrame(columns = ['text', 'category', 'source_file'])\n",
    "for category in target_categories:\n",
    "    print(\"Loading data for: {}\".format(category))\n",
    "    ng = sklearn.datasets.fetch_20newsgroups(categories = [category], remove=['headers', 'footers', 'quotes'], data_home = '../data')\n",
    "    newsgroupsDF = newsgroupsDF.append(pandas.DataFrame({'text' : ng.data, 'category' : [category] * len(ng.data), 'source_file' : ng.filenames}), ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need to tokenize, and make a training and testing set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "newsgroupsDF['tokenized_text'] = newsgroupsDF['text'].apply(lambda x: nltk.word_tokenize(x))\n",
    "newsgroupsDF['normalized_text'] = newsgroupsDF['tokenized_text'].apply(lambda x: lucem_illud.normalizeTokens(x, stopwordLst = lucem_illud.stop_words_basic, stemmer = lucem_illud.stemmer_basic))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "holdBackFraction = .2\n",
    "train_ng_df, test_ng_df = lucem_illud.trainTestSplit(newsgroupsDF, holdBackFraction=holdBackFraction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(len(train_ng_df))\n",
    "print(len(test_ng_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to extract features from the text. We can use built-in feature extraction to do so. We will use a tf-idf vectorizer, which converts the document into a vector of words with tf-idf weights (term-frequency inverse-document frequency). This gives high weight to words that show up a lot in a given document, but rarely across documents in the corpus (more distinctive). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "TFVectorizer_ng = sklearn.feature_extraction.text.TfidfVectorizer(max_df=100, min_df=2, stop_words='english', norm='l2')\n",
    "TFVects_ng = TFVectorizer_ng.fit_transform(train_ng_df['text'])\n",
    "train_ng_df['vect'] = [np.array(v).flatten() for v in TFVects_ng.todense()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can train the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "MultinomialNB_ng = sklearn.naive_bayes.MultinomialNB()\n",
    "MultinomialNB_ng.fit(np.stack(train_ng_df['vect'], axis = 0), train_ng_df['category'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "...and save predictions to the dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_ng_df['nb_predict'] = MultinomialNB_ng.predict(np.stack(train_ng_df['vect'], axis=0))\n",
    "print(\"Training score:\")\n",
    "print(MultinomialNB_ng.score(np.stack(train_ng_df['vect'], axis=0), train_ng_df['category']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_ng_df[['category', 'nb_predict']][:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks pretty good, lets examine the testing dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Create vectors\n",
    "TFVects_test = TFVectorizer_ng.transform(test_ng_df['text'])\n",
    "test_ng_df['vect'] = [np.array(v).flatten() for v in TFVects_test.todense()]\n",
    "\n",
    "#Add to df\n",
    "test_ng_df['nb_predict'] = MultinomialNB_ng.predict(np.stack(test_ng_df['vect'], axis=0))\n",
    "\n",
    "#Test\n",
    "print(\"Testing score:\")\n",
    "print(MultinomialNB_ng.score(np.stack(test_ng_df['vect'], axis=0), test_ng_df['category']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can even use a confusion matrix, like we used last week for evaluating human coders relative to one another. Now we are evaluating our classifier relative to human coding. We'll just use the one in `lucem_illud`, which requres a classifier and a dataframe with `'vect'` and `'category'` columns, like we have in the examples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lucem_illud.plotConfusionMatrix(MultinomialNB_ng, test_ng_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's calculate the precision, recall, and F-measures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(sklearn.metrics.precision_score(test_ng_df['nb_predict'], test_ng_df['category'], average = 'weighted')) #precision\n",
    "print(sklearn.metrics.recall_score(test_ng_df['nb_predict'], test_ng_df['category'], average = 'weighted')) #recall\n",
    "print(sklearn.metrics.f1_score(test_ng_df['nb_predict'], test_ng_df['category'], average = 'weighted')) #F-1 measure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can evaluate these per catagory. This has the same requiments as `plotConfusionMatrix`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lucem_illud.metrics.evaluateClassifier(MultinomialNB_ng, test_ng_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also plot the ROC curves. This has the same requiments as `plotConfusionMatrix`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lucem_illud.plotMultiROC(MultinomialNB_ng, test_ng_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we can plot the PCA space visualization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lucem_illud.plotregions(MultinomialNB_ng, test_ng_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also give the model a new string, not present in our data, and use the *predict* method to see if it can assign it to a category. Using our model to extend its classifications to new, uncoded data might be the primary purpose of a social science application. The words do have to be in the vocabulary, so don't be too creative :-)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict_category(s, model, tfidf): #We just define a simple function here\n",
    "    a = np.zeros((1, len(tfidf.vocabulary_)))\n",
    "    for w in nltk.word_tokenize(s):\n",
    "        try:\n",
    "            a[:,tfidf.vocabulary_[lucem_illud.stemmer_basic.stem(w.lower())]] = 1\n",
    "        except KeyError:\n",
    "            print(\"Warning: '{}' not in vocabulary\".format(w))\n",
    "    return model.predict(a)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predict_category('rockets are cool', MultinomialNB_ng, TFVectorizer_ng)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:red\">*Exercise 2*</span>\n",
    "\n",
    "<span style=\"color:red\">In the cells immediately following, perform Logistic and Na√Øve Bayes classification (binary or multinomial) using training, testing and extrapolation (uncoded) data from texts and hand-classifications associated with your final project (e.g., these could be crowd-sourced codes gathered through Amazon Mechanical Turk last week). Visualize the confusion matrix for training and testing sets. Calculate precision, recall, the F-measure, and AUC, then perform an ROC visualization. How do these classifiers perform? Exrapolate codes from these models to all uncoded data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# data prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "powMIA = pandas.read_csv(\"../data/powMIA.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create new variable\n",
    "# originally, I created a binomial variable called 'prisoner', but a lot of \n",
    "# the lucem illud functions want a variable called 'category', so we're gonna\n",
    "# make that instead\n",
    "\n",
    "powMIA['prisoner'] = [s == 2 for s in powMIA['cluster']]\n",
    "powMIA['category'] = [s == 2 for s in powMIA['cluster']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# looks like 73/393 of my articles are coded as referencing prisoners. \n",
    "\n",
    "print(len(powMIA))\n",
    "print(powMIA[powMIA == True].count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "powMIA['tokenizedArticle'] = powMIA['article'].apply(lambda x: nltk.word_tokenize(x))\n",
    "powMIA['normalizedArticle'] = powMIA['tokenizedArticle'].apply(lambda x: lucem_illud.normalizeTokens(x, stopwordLst = lucem_illud.stop_words_basic, stemmer = lucem_illud.stemmer_basic))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(powMIA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "holdBackFraction = .2\n",
    "train_data_df, test_data_df = lucem_illud.trainTestSplit(powMIA, holdBackFraction=holdBackFraction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(len(train_data_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(len(test_data_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "TFVectorizer = sklearn.feature_extraction.text.TfidfVectorizer(max_df=100, min_df=2, stop_words='english', norm='l2')\n",
    "\n",
    "TFVects = TFVectorizer.fit_transform(train_data_df['article'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "TFVects.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data_df['vect'] = [np.array(v).flatten() for v in TFVects.todense()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pca = sklearn.decomposition.PCA()\n",
    "reduced_data = pca.fit_transform(np.stack(train_data_df['vect'], axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data_df['pca'] = [r for r in reduced_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Viualize\n",
    "fig, ax = plt.subplots(figsize = (10,10))\n",
    "ax.axis('off')\n",
    "pallet = seaborn.color_palette(n_colors = 2)\n",
    "\n",
    "#plot POW\n",
    "a = np.stack(train_data_df[train_data_df['category']]['pca'])\n",
    "ax.scatter(a[:,0], a[:, 1], c = pallet[0], label = \"True\")\n",
    "\n",
    "#Plot No Social\n",
    "a = np.stack(train_data_df[train_data_df['category'].eq(False)]['pca'])\n",
    "ax.scatter(a[:,0], a[:, 1], c = pallet[1], label = \"False\")\n",
    "    \n",
    "ax.legend(loc = 'upper right', title = 'Mentions POWs')\n",
    "plt.title('True Classes, Training Set')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n = len(train_data_df)\n",
    "\n",
    "fig, (ax1, ax2, ax3) = plt.subplots(ncols=3, figsize = (16, 5), sharey=True)\n",
    "\n",
    "eigen_vals = np.arange(n) + 1\n",
    "ax1.plot(eigen_vals, pca.explained_variance_ratio_, 'ro-', linewidth=1)\n",
    "ax1.set_title('Scree Plot (Full)')\n",
    "ax1.set_xlabel('Principal Component')\n",
    "ax1.set_ylabel('Proportion of Explained Variance')\n",
    "\n",
    "eigen_vals = np.arange(40) + 1\n",
    "ax2.plot(eigen_vals, pca.explained_variance_ratio_[:40], 'ro-', linewidth=1)\n",
    "ax2.set_title('Scree Plot (First 40 Principal Components)')\n",
    "ax2.set_xlabel('Principal Component')\n",
    "ax2.set_ylabel('Proportion of Explained Variance')\n",
    "\n",
    "\n",
    "eigen_vals = np.arange(20) + 1\n",
    "ax3.plot(eigen_vals, pca.explained_variance_ratio_[:20], 'ro-', linewidth=2)\n",
    "ax3.set_title('Scree Plot (First 20 Principal Components)')\n",
    "ax3.set_xlabel('Principal Component')\n",
    "ax3.set_ylabel('Proportion of Explained Variance')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# going to stick to first 10 PCA as covariates\n",
    "train_data_df['pca_reduced_10'] = train_data_df['pca'].apply(lambda x: x[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# and now fit a regression\n",
    "\n",
    "logistic = sklearn.linear_model.LogisticRegression()\n",
    "logistic.fit(np.stack(train_data_df['pca_reduced_10'], axis=0), train_data_df['prisoner'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# not terrible \n",
    "\n",
    "logistic.score(np.stack(train_data_df['pca_reduced_10'], axis=0), train_data_df['prisoner'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# what about on the test data?\n",
    "# about the same\n",
    "\n",
    "#Create vectors\n",
    "TFVects_test = TFVectorizer.transform(test_data_df['article'])\n",
    "test_data_df['vect'] = [np.array(v).flatten() for v in TFVects_test.todense()]\n",
    "\n",
    "#PCA\n",
    "reduced_data_test = pca.transform(np.stack(test_data_df['vect'], axis=0))\n",
    "test_data_df['pca'] = [r for r in reduced_data_test]\n",
    "test_data_df['pca_reduced_10'] = test_data_df['pca'].apply(lambda x: x[:10])\n",
    "\n",
    "#Test\n",
    "logistic.score(np.stack(test_data_df['pca_reduced_10'], axis=0), test_data_df['prisoner'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# on all the data - about as well as the test set. \n",
    "\n",
    "#Create vectors\n",
    "TFVects_test = TFVectorizer.transform(powMIA['article'])\n",
    "powMIA['vect'] = [np.array(v).flatten() for v in TFVects_test.todense()]\n",
    "\n",
    "#PCA\n",
    "reduced_data_test = pca.transform(np.stack(powMIA['vect'], axis=0))\n",
    "powMIA['pca'] = [r for r in reduced_data_test]\n",
    "powMIA['pca_reduced_10'] = powMIA['pca'].apply(lambda x: x[:10])\n",
    "\n",
    "#Test\n",
    "logistic.score(np.stack(powMIA['pca_reduced_10'], axis=0), powMIA['prisoner'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# now with tf-idf, and better!\n",
    "\n",
    "logistic_l1= sklearn.linear_model.LogisticRegression(penalty='l1')\n",
    "logistic_l1.fit(np.stack(train_data_df['vect'], axis=0), train_data_df['prisoner'])\n",
    "print(logistic_l1.score(np.stack(train_data_df['vect'], axis=0), train_data_df['prisoner']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# back to pretty mediocre\n",
    "\n",
    "print(logistic_l1.score(np.stack(test_data_df['vect'], axis=0), test_data_df['prisoner']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "naiveBayes = sklearn.naive_bayes.BernoulliNB()\n",
    "naiveBayes.fit(np.stack(train_data_df['vect'], axis=0), train_data_df['prisoner'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(\"Training:\")\n",
    "print(naiveBayes.score(np.stack(train_data_df['vect'], axis=0), train_data_df['prisoner']))\n",
    "print(\"Testing:\")\n",
    "print(naiveBayes.score(np.stack(test_data_df['vect'], axis=0), test_data_df['prisoner']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_data_df['nb_predict'] = naiveBayes.predict(np.stack(test_data_df['vect'], axis=0))\n",
    "test_data_df['nb_predict_prob_true'] = naiveBayes.predict_proba(np.stack(test_data_df['vect'], axis=0))[:,0] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(\"precision:\")\n",
    "print(sklearn.metrics.precision_score(test_data_df['nb_predict'], test_data_df['prisoner']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(\"recall:\")\n",
    "print(sklearn.metrics.recall_score(test_data_df['nb_predict'], test_data_df['prisoner']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(\"f1:\")\n",
    "print(sklearn.metrics.f1_score(test_data_df['nb_predict'], test_data_df['prisoner'])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#posterior distributions\n",
    "fig, ax = plt.subplots()\n",
    "ax.grid(False)\n",
    "ax.set_frame_on(False)\n",
    "test_data_df[test_data_df['prisoner'].eq(True)]['nb_predict_prob_true'].hist(alpha = 0.5, ax = ax, bins = 10, label = 'True', color = 'red')\n",
    "test_data_df[test_data_df['prisoner'].eq(False)]['nb_predict_prob_true'].hist(alpha = 0.5, ax = ax, bins = 10, label = 'False', color = 'blue')\n",
    "ax.set_xlim((0,1.1))\n",
    "ax.legend(title = \"Mention of POWs\")\n",
    "ax.set_xlabel('posterior')\n",
    "ax.set_ylabel('counts')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# looks like performance is mixed, and maybe overfit considering recall is 1\n",
    "# let's look at some word predictions and see if they make any sense\n",
    "\n",
    "trueVals, falseVals = naiveBayes.feature_log_prob_\n",
    "\n",
    "words_dict = {\n",
    "    'POWs mentioned' : [],\n",
    "    'pow_log_prob' : [],\n",
    "    'No POWs mentioned' : [],\n",
    "    'noPOW_log_prob' : [],\n",
    "}\n",
    "\n",
    "for i, prob in sorted(enumerate(trueVals), key = lambda x:x[1], reverse=True)[:15]:\n",
    "    words_dict['No POWs mentioned'].append(TFVectorizer.get_feature_names()[i])\n",
    "    words_dict['noPOW_log_prob'].append(prob)\n",
    "\n",
    "for i, prob in sorted(enumerate(falseVals), key = lambda x:x[1], reverse=True)[:15]:\n",
    "    words_dict['POWs mentioned'].append(TFVectorizer.get_feature_names()[i])\n",
    "    words_dict['pow_log_prob'].append(prob)\n",
    "    \n",
    "pandas.DataFrame(words_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf_nn = sklearn.neural_network.MLPClassifier()\n",
    "clf_nn.fit(np.stack(train_data_df['vect'], axis=0), train_data_df['category'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lucem_illud.plotConfusionMatrix(naiveBayes, test_data_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lucem_illud.plotMultiROC(naiveBayes, train_data_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Decision Trees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decision trees can be used to predict both categorical/class labels (i.e., classification) and continuous labels (i.e., regression)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "blobs_df = lucem_illud.multiBlobs(noise=.2, centers=[(0,0), (0,5), (5,0), (-5,0), (0,-5)])\n",
    "df_exampleTree_train, df_exampleTree_test = lucem_illud.trainTestSplit(blobs_df)\n",
    "lucem_illud.plotter(df_exampleTree_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we import our Decision Tree classifier from sklearn.tree (familiar syntax) and fit it using the fit method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf_tree = sklearn.tree.DecisionTreeClassifier(max_depth=4,random_state=0)\n",
    "clf_tree.fit(np.stack(df_exampleTree_train['vect'], axis =0), df_exampleTree_train['category'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To see what's going on visually with the classification: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lucem_illud.plotregions(clf_tree, df_exampleTree_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lucem_illud.evaluateClassifier(clf_tree, df_exampleTree_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets look at accuracy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sklearn.metrics.accuracy_score(df_exampleTree_test['category'],clf_tree.predict(np.stack(df_exampleTree_test['vect'], axis = 0)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What happens if we trim the tree?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "depthvec = []\n",
    "scorevec = []\n",
    "for i in range(1,20):\n",
    "    tree2 = sklearn.tree.DecisionTreeClassifier(max_depth=i,random_state=0)\n",
    "    tree2.fit(np.stack(df_exampleTree_train['vect'], axis =0), df_exampleTree_train['category'])\n",
    "    score = sklearn.metrics.accuracy_score(df_exampleTree_test['category'], tree2.predict(np.stack(df_exampleTree_test['vect'], axis = 0)))\n",
    "    depthvec.append(i)\n",
    "    scorevec.append(score)\n",
    "plt.scatter(depthvec,scorevec)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can select different layers of the decision tree or \"prune\" it. At approximately four layers down in the decision tree, the shape is somewhat odd, suggesting that our model is overfitting beyond those four layers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combining multiple overfitting estimators turns out to be a key idea in machine learning. This is called **bagging** and is a type of **ensemble** method. The idea is to make many randomized estimators--each can overfit, as decision trees are wont to do--but then to combine them, ultimately producing a better classification. A **random forest** is produced by bagging decision trees."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tree = sklearn.tree.DecisionTreeClassifier(max_depth=10) #Create an instance of our decision tree classifier.\n",
    "\n",
    "bag = sklearn.ensemble.BaggingClassifier(tree, n_estimators=100, max_samples=0.8, random_state=1) #Each tree uses up to 80% of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bag.fit(np.stack(df_exampleTree_train['vect'], axis =0), df_exampleTree_train['category']) #Fit the bagged classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lucem_illud.plotregions(bag, df_exampleTree_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lucem_illud.evaluateClassifier(bag, df_exampleTree_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lucem_illud.plotConfusionMatrix(bag, df_exampleTree_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:red\">*Exercise 3*</span>\n",
    "\n",
    "<span style=\"color:red\">In the cells immediately following, perform decision tree and random forest classification (binary, multinomial or continuous) using training, testing and extrapolation (uncoded) data from texts and hand-classifications associated with your final project. As with ***Exercise 2***, these could be crowd-sourced codes gathered through Amazon Mechanical Turk last week. Visualize the classification of data points. Calculate relevant metrics (e.g., precision, recall, the F-measure, and AUC). Now build an ensemble classifier by bagging trees into a random forest. Visualize the result. How do these classifiers perform? What does ensemble learning do?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#data prep\n",
    "\n",
    "TFVects = TFVectorizer.transform(powMIA['article'])\n",
    "powMIA['vect'] = [np.array(v).flatten() for v in TFVects.todense()]\n",
    "\n",
    "# split \n",
    "holdBackFraction = .2\n",
    "trainData, testData = lucem_illud.trainTestSplit(powMIA, holdBackFraction=holdBackFraction)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "powTree = sklearn.tree.DecisionTreeClassifier(max_depth=4,random_state=0)\n",
    "powTree.fit(np.stack(trainData['vect'], axis =0), trainData['prisoner'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# not looking too good for me!\n",
    "\n",
    "lucem_illud.plotregions(powTree, train_data_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "testData['category'] = testData['prisoner']\n",
    "lucem_illud.evaluateClassifier(powTree, testData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sklearn.metrics.accuracy_score(testData['category'],powTree.predict(np.stack(testData['vect'], axis = 0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tree = sklearn.tree.DecisionTreeClassifier(max_depth=10)\n",
    "\n",
    "bag = sklearn.ensemble.BaggingClassifier(tree, n_estimators=100, max_samples=0.8, random_state=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# since my original dataset actually has 4 pseudo-topics, let's unleash this thing on all 4\n",
    "\n",
    "bag.fit(np.stack(trainData['vect'], axis =0), trainData['prisoner'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lucem_illud.plotregions(bag, testData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lucem_illud.evaluateClassifier(bag,testData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lucem_illud.plotConfusionMatrix(bag, testData)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# K-Nearest Neighbors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The K-Nearest neighbors classifier takes a simpler premise than those before: Find the closest labeled datapoint in set and \"borrow\" its label.\n",
    "\n",
    "Let's use newsgroup data again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "newsgroupsDF[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make a testing and training set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "holdBackFraction = .2\n",
    "train_ng_df, test_ng_df = lucem_illud.trainTestSplit(newsgroupsDF, holdBackFraction=holdBackFraction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's initialize our k-nearest neighbors classifier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_neighbors = 15\n",
    "weights=\"uniform\"\n",
    "clf_knearest = sklearn.neighbors.KNeighborsClassifier(n_neighbors, weights=weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try to classify using the TF-IDF vectors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "TFVectorizer_ng = sklearn.feature_extraction.text.TfidfVectorizer(max_df=100, min_df=2, stop_words='english', norm='l2')\n",
    "TFVects_ng = TFVectorizer_ng.fit_transform(train_ng_df['text'])\n",
    "train_ng_df['vect'] = [np.array(v).flatten() for v in TFVects_ng.todense()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf_knearest.fit(np.stack(train_ng_df['vect'], axis = 0), train_ng_df['category'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lucem_illud.evaluateClassifier(clf_knearest, train_ng_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And lets look at the testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Create vectors\n",
    "TFVects_test = TFVectorizer_ng.transform(test_ng_df['text'])\n",
    "test_ng_df['vect'] = [np.array(v).flatten() for v in TFVects_test.todense()]\n",
    "\n",
    "#Add to df\n",
    "test_ng_df['nb_predict'] = clf_knearest.predict(np.stack(test_ng_df['vect'], axis=0))\n",
    "\n",
    "#Test\n",
    "print(\"Testing score:\")\n",
    "print(clf_knearest.score(np.stack(test_ng_df['vect'], axis=0), test_ng_df['category']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's produce another confusion matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lucem_illud.plotConfusionMatrix(clf_knearest, test_ng_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can produce the PCA space visual if you want, altough it can take a very long time, so we'll leave it optionally commented out:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#lucem_illud.plotregions(clf_knearest, test_ng_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:red\">*Exercise 4*</span>\n",
    "\n",
    "<span style=\"color:red\">In the cells immediately following, perform and visualize k-nearest neighbor classification using training, testing and extrapolation (uncoded) data from texts and hand-classifications associated with your final project. Visualize the classification of data points and calculate relevant metrics (e.g., precision, recall, the F-measure, and AUC). Articulate how the *k*-nearest neighbor approach relates to *k*-means clustering explored in ***week 3***?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# data...PREP!!\n",
    "\n",
    "holdBackFraction = .2\n",
    "dataTest, dataTrain = lucem_illud.trainTestSplit(powMIA, holdBackFraction=holdBackFraction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# I'll stick with the example n_neighbors (15) and see what comes out\n",
    "\n",
    "n_neighbors = 15\n",
    "weights=\"uniform\"\n",
    "clf_knearest = sklearn.neighbors.KNeighborsClassifier(n_neighbors, weights=weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# a-vect'ing, all over again\n",
    "\n",
    "TFVectorizer = sklearn.feature_extraction.text.TfidfVectorizer(max_df=100, min_df=2, stop_words='english', norm='l2')\n",
    "TFVects = TFVectorizer.fit_transform(dataTrain['article'])\n",
    "dataTrain['vect'] =  [np.array(v).flatten() for v in TFVects.todense()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf_knearest.fit(np.stack(dataTrain['vect'], axis = 0), dataTrain['category'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lucem_illud.evaluateClassifier(clf_knearest, dataTrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# to test\n",
    "\n",
    "TFVects_test = TFVectorizer.transform(dataTest['article'])\n",
    "dataTest['vect'] = [np.array(v).flatten() for v in TFVects_test.todense()]\n",
    "\n",
    "dataTest['nb_predict'] = clf_knearest.predict(np.stack(dataTest['vect'], axis=0))\n",
    "\n",
    "#Test\n",
    "print(\"Testing score:\")\n",
    "print(clf_knearest.score(np.stack(dataTest['vect'], axis=0), dataTest['category']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# let's visualize on my test data\n",
    "\n",
    "lucem_illud.plotConfusionMatrix(clf_knearest, dataTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# SVMs\n",
    "\n",
    "Now we will examine Support Vector Machines, an approach that creates the partition that preserves the \"maximum margin\" between classes.\n",
    "\n",
    "We will use a few sub forums from reddit--which tend to share text rather than memes--namely `talesfromtechsupport`, `badroommates`, `weeabootales` and `relationships`. The top 100 text posts from each have been saved to `data/reddit.csv`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "redditDf = pandas.read_csv('../data/reddit.csv', index_col = 0)\n",
    "\n",
    "#Drop a couple missing values\n",
    "\n",
    "redditDf = redditDf.dropna()\n",
    "\n",
    "#Set category\n",
    "\n",
    "redditDf['category'] = redditDf['subreddit']\n",
    "\n",
    "#tokenize and normalize\n",
    "redditDf['tokenized_text'] = redditDf['text'].apply(lambda x: nltk.word_tokenize(x))\n",
    "redditDf['normalized_text'] = redditDf['tokenized_text'].apply(lambda x: lucem_illud.normalizeTokens(x, stopwordLst = lucem_illud.stop_words_basic, stemmer = lucem_illud.stemmer_basic))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will tf.idf the data to make our vectors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "redditTFVectorizer = sklearn.feature_extraction.text.TfidfVectorizer(max_df=0.5, min_df=3, stop_words='english', norm='l2')\n",
    "redditTFVects = redditTFVectorizer.fit_transform([' '.join(l) for l in redditDf['normalized_text']])\n",
    "redditDf['vect'] = [np.array(v).flatten() for v in redditTFVects.todense()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initilize the model and make a train test split:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "holdBackFraction = .2\n",
    "train_redditDf, test_redditDf = lucem_illud.trainTestSplit(redditDf, holdBackFraction=holdBackFraction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf_svm = sklearn.svm.SVC(kernel='linear', probability = False)\n",
    "#probability = True is slower but  lets you call predict_proba()\n",
    "clf_svm.fit(np.stack(train_redditDf['vect'], axis=0), train_redditDf['category'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "...and consider the results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lucem_illud.evaluateClassifier(clf_svm, test_redditDf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lucem_illud.plotConfusionMatrix(clf_svm, test_redditDf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lucem_illud.plotregions(clf_svm, test_redditDf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Nets\n",
    "\n",
    "We include an example of a simple neural network, the Multi-layer Perceptron (MLP) that learns a function $f(\\cdot): R^m \\rightarrow R^o$ by training on a dataset, where $m$ is the number of dimensions for input and $o$ is the number of dimensions for output. Given a set of features $X = {x_1, x_2, ..., x_m}$ and a target $y$, it can learn a non-linear function approximator for either classification or regression. It is different from logistic regression, in that between the input and the output layer, there can be one or more non-linear layers, called hidden layers. The following figure shows a one hidden layer MLP with scalar output. ![title](../data/multilayerperceptron_network.png) The leftmost layer, known as the input layer, consists of a set of \"neurons\" $\\{x_i | x_1, x_2, ..., x_m\\}$ representing the input features (e.g., weighted words). Each neuron in the hidden layer transforms the values from the previous layer with a weighted linear summation $w_1x_1 + w_2x_2 + ... + w_mx_m$, followed by a non-linear activation function $g(\\cdot):R \\rightarrow R$ - like the logistic or hyperbolic tan function. The output layer receives the values from the last hidden layer and transforms them into output values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf_nn = sklearn.neural_network.MLPClassifier()\n",
    "clf_nn.fit(np.stack(train_redditDf['vect'], axis=0), train_redditDf['category'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lucem_illud.evaluateClassifier(clf_nn, test_redditDf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lucem_illud.plotConfusionMatrix(clf_nn, test_redditDf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lucem_illud.plotregions(clf_nn, test_redditDf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It performs very well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:red\">*Exercise 5*</span>\n",
    "\n",
    "<span style=\"color:red\">In the cells immediately following, perform a neural network classification and calculate relevant metrics (e.g., precision, recall, the F-measure, and AUC). How does this classify relevant to *k*-nearest neighbor, Naive Bayes, logistic and decision-tree approaches?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf_nn.fit(np.stack(dataTrain['vect'], axis=0), dataTrain['category'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataTest['nb_predict'] = clf_nn.predict(np.stack(dataTest['vect'], axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#precision!\n",
    "\n",
    "sklearn.metrics.precision_score(dataTest['nb_predict'], dataTest['category'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# recall!\n",
    "sklearn.metrics.recall_score(dataTest['nb_predict'], dataTest['category'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# f1!\n",
    "\n",
    "sklearn.metrics.f1_score(dataTest['nb_predict'], dataTest['category'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lucem_illud.plotConfusionMatrix(clf_nn, dataTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lucem_illud.plotConfusionMatrix(clf_nn, dataTrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lucem_illud.plotregions(clf_nn, dataTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lucem_illud.plotregions(clf_nn, dataTrain)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
